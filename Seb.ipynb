{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "869bfaa48bc07b43"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:48:11.997040Z",
     "start_time": "2023-11-26T20:48:11.976011Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Input de DataSet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c4c1db19cb01c9b"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "      chroma_stft  chroma_cqt  chroma_cens  melspectogram       rms  \\\n0        0.494262    0.568759     0.267266       3.465249  0.068657   \n1        0.422076    0.556903     0.270826       3.132792  0.076706   \n2        0.575613    0.606710     0.275953       2.257988  0.044251   \n3        0.175040    0.526637     0.258603       1.481219  0.043195   \n4        0.412279    0.608818     0.264944       0.806509  0.035636   \n...           ...         ...          ...            ...       ...   \n8727     0.479371    0.552483     0.266297       2.410669  0.127638   \n8728     0.545358    0.593931     0.273223       2.837043  0.130824   \n8729     0.436206    0.605989     0.275923       5.695730  0.190655   \n8730     0.524807    0.671077     0.277764       3.745609  0.153592   \n8731     0.538737    0.582093     0.271992       5.034693  0.175901   \n\n         centroid    bandwidth   contrast  flatness      rolloff  ...  \\\n0     2177.483658  3649.518344  19.685466  0.002088  4745.917969  ...   \n1     1623.980658  2897.277104  21.508354  0.001123  2743.891814  ...   \n2     2615.200756  4200.855657  18.001559  0.003370  6143.329229  ...   \n3     1223.789196  1367.391253  16.179755  0.583564  2473.821756  ...   \n4     1470.863386  2296.662162  12.349992  0.353831  3264.932914  ...   \n...           ...          ...        ...       ...          ...  ...   \n8727  2431.943128  2504.586835  16.611774  0.000412  4677.947945  ...   \n8728  1979.367181  2215.734460  16.131903  0.000247  3817.306386  ...   \n8729  2192.398026  2140.849300  17.080651  0.000198  4041.189283  ...   \n8730  2187.172172  2190.171430  16.642445  0.000244  4042.500000  ...   \n8731  1962.121130  2124.205226  16.116446  0.000228  3778.796281  ...   \n\n      mcffs_32  mcffs_33  mcffs_34  mcffs_35  mcffs_36  mcffs_37  mcffs_38  \\\n0    -2.700133 -0.350788 -0.123943 -0.308717  0.377525 -0.907509 -0.254973   \n1    -5.048006 -1.626652 -1.303208 -1.028367  0.470883 -2.959822 -1.439514   \n2    -1.015445  0.989107  1.142546  0.407650 -0.166601 -0.859933 -0.637618   \n3     2.447487 -1.956081  0.440909 -1.384400  0.585570 -0.601787 -0.864582   \n4     0.232175  0.326373  0.610677  0.570734  1.030308  0.507107  0.160745   \n...        ...       ...       ...       ...       ...       ...       ...   \n8727  0.199730 -0.839973 -4.665137 -0.551395  0.214190  0.865874  1.078110   \n8728  0.332412  2.602965 -0.238956  2.640356 -0.004591 -0.695137 -0.639137   \n8729  0.285693  1.105075 -2.979676  0.069636  0.038741  0.715938  2.593126   \n8730 -0.099813  0.535876 -0.444768  2.225560  1.202731 -1.514751  1.340369   \n8731  2.109410  0.105799 -3.077201  3.065105 -4.448371 -0.421964  1.611564   \n\n      mcffs_39  mcffs_40             Label  \n0    -1.738416 -1.207377  101415-3-0-2.wav  \n1    -2.282194 -1.155120  101415-3-0-3.wav  \n2    -1.657652 -1.639226  101415-3-0-8.wav  \n3    -0.896903 -0.161344  102106-3-0-0.wav  \n4     0.642600  0.364088  102305-6-0-0.wav  \n...        ...       ...               ...  \n8727 -3.648149  0.705190  99500-2-0-23.wav  \n8728 -2.883146  0.214829  99500-2-0-29.wav  \n8729 -2.714100  1.224722  99500-2-0-39.wav  \n8730 -0.692652  1.283734  99500-2-0-41.wav  \n8731 -1.729048  2.511954  99500-2-0-50.wav  \n\n[8732 rows x 54 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chroma_stft</th>\n      <th>chroma_cqt</th>\n      <th>chroma_cens</th>\n      <th>melspectogram</th>\n      <th>rms</th>\n      <th>centroid</th>\n      <th>bandwidth</th>\n      <th>contrast</th>\n      <th>flatness</th>\n      <th>rolloff</th>\n      <th>...</th>\n      <th>mcffs_32</th>\n      <th>mcffs_33</th>\n      <th>mcffs_34</th>\n      <th>mcffs_35</th>\n      <th>mcffs_36</th>\n      <th>mcffs_37</th>\n      <th>mcffs_38</th>\n      <th>mcffs_39</th>\n      <th>mcffs_40</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.494262</td>\n      <td>0.568759</td>\n      <td>0.267266</td>\n      <td>3.465249</td>\n      <td>0.068657</td>\n      <td>2177.483658</td>\n      <td>3649.518344</td>\n      <td>19.685466</td>\n      <td>0.002088</td>\n      <td>4745.917969</td>\n      <td>...</td>\n      <td>-2.700133</td>\n      <td>-0.350788</td>\n      <td>-0.123943</td>\n      <td>-0.308717</td>\n      <td>0.377525</td>\n      <td>-0.907509</td>\n      <td>-0.254973</td>\n      <td>-1.738416</td>\n      <td>-1.207377</td>\n      <td>101415-3-0-2.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.422076</td>\n      <td>0.556903</td>\n      <td>0.270826</td>\n      <td>3.132792</td>\n      <td>0.076706</td>\n      <td>1623.980658</td>\n      <td>2897.277104</td>\n      <td>21.508354</td>\n      <td>0.001123</td>\n      <td>2743.891814</td>\n      <td>...</td>\n      <td>-5.048006</td>\n      <td>-1.626652</td>\n      <td>-1.303208</td>\n      <td>-1.028367</td>\n      <td>0.470883</td>\n      <td>-2.959822</td>\n      <td>-1.439514</td>\n      <td>-2.282194</td>\n      <td>-1.155120</td>\n      <td>101415-3-0-3.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.575613</td>\n      <td>0.606710</td>\n      <td>0.275953</td>\n      <td>2.257988</td>\n      <td>0.044251</td>\n      <td>2615.200756</td>\n      <td>4200.855657</td>\n      <td>18.001559</td>\n      <td>0.003370</td>\n      <td>6143.329229</td>\n      <td>...</td>\n      <td>-1.015445</td>\n      <td>0.989107</td>\n      <td>1.142546</td>\n      <td>0.407650</td>\n      <td>-0.166601</td>\n      <td>-0.859933</td>\n      <td>-0.637618</td>\n      <td>-1.657652</td>\n      <td>-1.639226</td>\n      <td>101415-3-0-8.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.175040</td>\n      <td>0.526637</td>\n      <td>0.258603</td>\n      <td>1.481219</td>\n      <td>0.043195</td>\n      <td>1223.789196</td>\n      <td>1367.391253</td>\n      <td>16.179755</td>\n      <td>0.583564</td>\n      <td>2473.821756</td>\n      <td>...</td>\n      <td>2.447487</td>\n      <td>-1.956081</td>\n      <td>0.440909</td>\n      <td>-1.384400</td>\n      <td>0.585570</td>\n      <td>-0.601787</td>\n      <td>-0.864582</td>\n      <td>-0.896903</td>\n      <td>-0.161344</td>\n      <td>102106-3-0-0.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.412279</td>\n      <td>0.608818</td>\n      <td>0.264944</td>\n      <td>0.806509</td>\n      <td>0.035636</td>\n      <td>1470.863386</td>\n      <td>2296.662162</td>\n      <td>12.349992</td>\n      <td>0.353831</td>\n      <td>3264.932914</td>\n      <td>...</td>\n      <td>0.232175</td>\n      <td>0.326373</td>\n      <td>0.610677</td>\n      <td>0.570734</td>\n      <td>1.030308</td>\n      <td>0.507107</td>\n      <td>0.160745</td>\n      <td>0.642600</td>\n      <td>0.364088</td>\n      <td>102305-6-0-0.wav</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8727</th>\n      <td>0.479371</td>\n      <td>0.552483</td>\n      <td>0.266297</td>\n      <td>2.410669</td>\n      <td>0.127638</td>\n      <td>2431.943128</td>\n      <td>2504.586835</td>\n      <td>16.611774</td>\n      <td>0.000412</td>\n      <td>4677.947945</td>\n      <td>...</td>\n      <td>0.199730</td>\n      <td>-0.839973</td>\n      <td>-4.665137</td>\n      <td>-0.551395</td>\n      <td>0.214190</td>\n      <td>0.865874</td>\n      <td>1.078110</td>\n      <td>-3.648149</td>\n      <td>0.705190</td>\n      <td>99500-2-0-23.wav</td>\n    </tr>\n    <tr>\n      <th>8728</th>\n      <td>0.545358</td>\n      <td>0.593931</td>\n      <td>0.273223</td>\n      <td>2.837043</td>\n      <td>0.130824</td>\n      <td>1979.367181</td>\n      <td>2215.734460</td>\n      <td>16.131903</td>\n      <td>0.000247</td>\n      <td>3817.306386</td>\n      <td>...</td>\n      <td>0.332412</td>\n      <td>2.602965</td>\n      <td>-0.238956</td>\n      <td>2.640356</td>\n      <td>-0.004591</td>\n      <td>-0.695137</td>\n      <td>-0.639137</td>\n      <td>-2.883146</td>\n      <td>0.214829</td>\n      <td>99500-2-0-29.wav</td>\n    </tr>\n    <tr>\n      <th>8729</th>\n      <td>0.436206</td>\n      <td>0.605989</td>\n      <td>0.275923</td>\n      <td>5.695730</td>\n      <td>0.190655</td>\n      <td>2192.398026</td>\n      <td>2140.849300</td>\n      <td>17.080651</td>\n      <td>0.000198</td>\n      <td>4041.189283</td>\n      <td>...</td>\n      <td>0.285693</td>\n      <td>1.105075</td>\n      <td>-2.979676</td>\n      <td>0.069636</td>\n      <td>0.038741</td>\n      <td>0.715938</td>\n      <td>2.593126</td>\n      <td>-2.714100</td>\n      <td>1.224722</td>\n      <td>99500-2-0-39.wav</td>\n    </tr>\n    <tr>\n      <th>8730</th>\n      <td>0.524807</td>\n      <td>0.671077</td>\n      <td>0.277764</td>\n      <td>3.745609</td>\n      <td>0.153592</td>\n      <td>2187.172172</td>\n      <td>2190.171430</td>\n      <td>16.642445</td>\n      <td>0.000244</td>\n      <td>4042.500000</td>\n      <td>...</td>\n      <td>-0.099813</td>\n      <td>0.535876</td>\n      <td>-0.444768</td>\n      <td>2.225560</td>\n      <td>1.202731</td>\n      <td>-1.514751</td>\n      <td>1.340369</td>\n      <td>-0.692652</td>\n      <td>1.283734</td>\n      <td>99500-2-0-41.wav</td>\n    </tr>\n    <tr>\n      <th>8731</th>\n      <td>0.538737</td>\n      <td>0.582093</td>\n      <td>0.271992</td>\n      <td>5.034693</td>\n      <td>0.175901</td>\n      <td>1962.121130</td>\n      <td>2124.205226</td>\n      <td>16.116446</td>\n      <td>0.000228</td>\n      <td>3778.796281</td>\n      <td>...</td>\n      <td>2.109410</td>\n      <td>0.105799</td>\n      <td>-3.077201</td>\n      <td>3.065105</td>\n      <td>-4.448371</td>\n      <td>-0.421964</td>\n      <td>1.611564</td>\n      <td>-1.729048</td>\n      <td>2.511954</td>\n      <td>99500-2-0-50.wav</td>\n    </tr>\n  </tbody>\n</table>\n<p>8732 rows × 54 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('urbansounds_features.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:48:12.265428Z",
     "start_time": "2023-11-26T20:48:12.202791Z"
    }
   },
   "id": "8b44e345a051e112"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean the DataSet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d210a4e9b159b459"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def calculate_mean_from_string(string):\n",
    "    cleaned_string = string.replace('\\n', '')\n",
    "    numbers = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", cleaned_string)\n",
    "    array = np.array(numbers, dtype=float)\n",
    "    mean_value = np.mean(array)\n",
    "    return mean_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:48:12.471897Z",
     "start_time": "2023-11-26T20:48:12.470011Z"
    }
   },
   "id": "8c658efd7620a805"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "      chroma_stft  chroma_cqt  chroma_cens  melspectogram       rms  \\\n0        0.494262    0.568759     0.267266       3.465249  0.068657   \n1        0.422076    0.556903     0.270826       3.132792  0.076706   \n2        0.575613    0.606710     0.275953       2.257988  0.044251   \n3        0.175040    0.526637     0.258603       1.481219  0.043195   \n4        0.412279    0.608818     0.264944       0.806509  0.035636   \n...           ...         ...          ...            ...       ...   \n8727     0.479371    0.552483     0.266297       2.410669  0.127638   \n8728     0.545358    0.593931     0.273223       2.837043  0.130824   \n8729     0.436206    0.605989     0.275923       5.695730  0.190655   \n8730     0.524807    0.671077     0.277764       3.745609  0.153592   \n8731     0.538737    0.582093     0.271992       5.034693  0.175901   \n\n         centroid    bandwidth   contrast  flatness      rolloff  ...  \\\n0     2177.483658  3649.518344  19.685466  0.002088  4745.917969  ...   \n1     1623.980658  2897.277104  21.508354  0.001123  2743.891814  ...   \n2     2615.200756  4200.855657  18.001559  0.003370  6143.329229  ...   \n3     1223.789196  1367.391253  16.179755  0.583564  2473.821756  ...   \n4     1470.863386  2296.662162  12.349992  0.353831  3264.932914  ...   \n...           ...          ...        ...       ...          ...  ...   \n8727  2431.943128  2504.586835  16.611774  0.000412  4677.947945  ...   \n8728  1979.367181  2215.734460  16.131903  0.000247  3817.306386  ...   \n8729  2192.398026  2140.849300  17.080651  0.000198  4041.189283  ...   \n8730  2187.172172  2190.171430  16.642445  0.000244  4042.500000  ...   \n8731  1962.121130  2124.205226  16.116446  0.000228  3778.796281  ...   \n\n      mcffs_32  mcffs_33  mcffs_34  mcffs_35  mcffs_36  mcffs_37  mcffs_38  \\\n0    -2.700133 -0.350788 -0.123943 -0.308717  0.377525 -0.907509 -0.254973   \n1    -5.048006 -1.626652 -1.303208 -1.028367  0.470883 -2.959822 -1.439514   \n2    -1.015445  0.989107  1.142546  0.407650 -0.166601 -0.859933 -0.637618   \n3     2.447487 -1.956081  0.440909 -1.384400  0.585570 -0.601787 -0.864582   \n4     0.232175  0.326373  0.610677  0.570734  1.030308  0.507107  0.160745   \n...        ...       ...       ...       ...       ...       ...       ...   \n8727  0.199730 -0.839973 -4.665137 -0.551395  0.214190  0.865874  1.078110   \n8728  0.332412  2.602965 -0.238956  2.640356 -0.004591 -0.695137 -0.639137   \n8729  0.285693  1.105075 -2.979676  0.069636  0.038741  0.715938  2.593126   \n8730 -0.099813  0.535876 -0.444768  2.225560  1.202731 -1.514751  1.340369   \n8731  2.109410  0.105799 -3.077201  3.065105 -4.448371 -0.421964  1.611564   \n\n      mcffs_39  mcffs_40  Label  \n0    -1.738416 -1.207377      3  \n1    -2.282194 -1.155120      3  \n2    -1.657652 -1.639226      3  \n3    -0.896903 -0.161344      3  \n4     0.642600  0.364088      6  \n...        ...       ...    ...  \n8727 -3.648149  0.705190      2  \n8728 -2.883146  0.214829      2  \n8729 -2.714100  1.224722      2  \n8730 -0.692652  1.283734      2  \n8731 -1.729048  2.511954      2  \n\n[8732 rows x 54 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chroma_stft</th>\n      <th>chroma_cqt</th>\n      <th>chroma_cens</th>\n      <th>melspectogram</th>\n      <th>rms</th>\n      <th>centroid</th>\n      <th>bandwidth</th>\n      <th>contrast</th>\n      <th>flatness</th>\n      <th>rolloff</th>\n      <th>...</th>\n      <th>mcffs_32</th>\n      <th>mcffs_33</th>\n      <th>mcffs_34</th>\n      <th>mcffs_35</th>\n      <th>mcffs_36</th>\n      <th>mcffs_37</th>\n      <th>mcffs_38</th>\n      <th>mcffs_39</th>\n      <th>mcffs_40</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.494262</td>\n      <td>0.568759</td>\n      <td>0.267266</td>\n      <td>3.465249</td>\n      <td>0.068657</td>\n      <td>2177.483658</td>\n      <td>3649.518344</td>\n      <td>19.685466</td>\n      <td>0.002088</td>\n      <td>4745.917969</td>\n      <td>...</td>\n      <td>-2.700133</td>\n      <td>-0.350788</td>\n      <td>-0.123943</td>\n      <td>-0.308717</td>\n      <td>0.377525</td>\n      <td>-0.907509</td>\n      <td>-0.254973</td>\n      <td>-1.738416</td>\n      <td>-1.207377</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.422076</td>\n      <td>0.556903</td>\n      <td>0.270826</td>\n      <td>3.132792</td>\n      <td>0.076706</td>\n      <td>1623.980658</td>\n      <td>2897.277104</td>\n      <td>21.508354</td>\n      <td>0.001123</td>\n      <td>2743.891814</td>\n      <td>...</td>\n      <td>-5.048006</td>\n      <td>-1.626652</td>\n      <td>-1.303208</td>\n      <td>-1.028367</td>\n      <td>0.470883</td>\n      <td>-2.959822</td>\n      <td>-1.439514</td>\n      <td>-2.282194</td>\n      <td>-1.155120</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.575613</td>\n      <td>0.606710</td>\n      <td>0.275953</td>\n      <td>2.257988</td>\n      <td>0.044251</td>\n      <td>2615.200756</td>\n      <td>4200.855657</td>\n      <td>18.001559</td>\n      <td>0.003370</td>\n      <td>6143.329229</td>\n      <td>...</td>\n      <td>-1.015445</td>\n      <td>0.989107</td>\n      <td>1.142546</td>\n      <td>0.407650</td>\n      <td>-0.166601</td>\n      <td>-0.859933</td>\n      <td>-0.637618</td>\n      <td>-1.657652</td>\n      <td>-1.639226</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.175040</td>\n      <td>0.526637</td>\n      <td>0.258603</td>\n      <td>1.481219</td>\n      <td>0.043195</td>\n      <td>1223.789196</td>\n      <td>1367.391253</td>\n      <td>16.179755</td>\n      <td>0.583564</td>\n      <td>2473.821756</td>\n      <td>...</td>\n      <td>2.447487</td>\n      <td>-1.956081</td>\n      <td>0.440909</td>\n      <td>-1.384400</td>\n      <td>0.585570</td>\n      <td>-0.601787</td>\n      <td>-0.864582</td>\n      <td>-0.896903</td>\n      <td>-0.161344</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.412279</td>\n      <td>0.608818</td>\n      <td>0.264944</td>\n      <td>0.806509</td>\n      <td>0.035636</td>\n      <td>1470.863386</td>\n      <td>2296.662162</td>\n      <td>12.349992</td>\n      <td>0.353831</td>\n      <td>3264.932914</td>\n      <td>...</td>\n      <td>0.232175</td>\n      <td>0.326373</td>\n      <td>0.610677</td>\n      <td>0.570734</td>\n      <td>1.030308</td>\n      <td>0.507107</td>\n      <td>0.160745</td>\n      <td>0.642600</td>\n      <td>0.364088</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8727</th>\n      <td>0.479371</td>\n      <td>0.552483</td>\n      <td>0.266297</td>\n      <td>2.410669</td>\n      <td>0.127638</td>\n      <td>2431.943128</td>\n      <td>2504.586835</td>\n      <td>16.611774</td>\n      <td>0.000412</td>\n      <td>4677.947945</td>\n      <td>...</td>\n      <td>0.199730</td>\n      <td>-0.839973</td>\n      <td>-4.665137</td>\n      <td>-0.551395</td>\n      <td>0.214190</td>\n      <td>0.865874</td>\n      <td>1.078110</td>\n      <td>-3.648149</td>\n      <td>0.705190</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8728</th>\n      <td>0.545358</td>\n      <td>0.593931</td>\n      <td>0.273223</td>\n      <td>2.837043</td>\n      <td>0.130824</td>\n      <td>1979.367181</td>\n      <td>2215.734460</td>\n      <td>16.131903</td>\n      <td>0.000247</td>\n      <td>3817.306386</td>\n      <td>...</td>\n      <td>0.332412</td>\n      <td>2.602965</td>\n      <td>-0.238956</td>\n      <td>2.640356</td>\n      <td>-0.004591</td>\n      <td>-0.695137</td>\n      <td>-0.639137</td>\n      <td>-2.883146</td>\n      <td>0.214829</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8729</th>\n      <td>0.436206</td>\n      <td>0.605989</td>\n      <td>0.275923</td>\n      <td>5.695730</td>\n      <td>0.190655</td>\n      <td>2192.398026</td>\n      <td>2140.849300</td>\n      <td>17.080651</td>\n      <td>0.000198</td>\n      <td>4041.189283</td>\n      <td>...</td>\n      <td>0.285693</td>\n      <td>1.105075</td>\n      <td>-2.979676</td>\n      <td>0.069636</td>\n      <td>0.038741</td>\n      <td>0.715938</td>\n      <td>2.593126</td>\n      <td>-2.714100</td>\n      <td>1.224722</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8730</th>\n      <td>0.524807</td>\n      <td>0.671077</td>\n      <td>0.277764</td>\n      <td>3.745609</td>\n      <td>0.153592</td>\n      <td>2187.172172</td>\n      <td>2190.171430</td>\n      <td>16.642445</td>\n      <td>0.000244</td>\n      <td>4042.500000</td>\n      <td>...</td>\n      <td>-0.099813</td>\n      <td>0.535876</td>\n      <td>-0.444768</td>\n      <td>2.225560</td>\n      <td>1.202731</td>\n      <td>-1.514751</td>\n      <td>1.340369</td>\n      <td>-0.692652</td>\n      <td>1.283734</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8731</th>\n      <td>0.538737</td>\n      <td>0.582093</td>\n      <td>0.271992</td>\n      <td>5.034693</td>\n      <td>0.175901</td>\n      <td>1962.121130</td>\n      <td>2124.205226</td>\n      <td>16.116446</td>\n      <td>0.000228</td>\n      <td>3778.796281</td>\n      <td>...</td>\n      <td>2.109410</td>\n      <td>0.105799</td>\n      <td>-3.077201</td>\n      <td>3.065105</td>\n      <td>-4.448371</td>\n      <td>-0.421964</td>\n      <td>1.611564</td>\n      <td>-1.729048</td>\n      <td>2.511954</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>8732 rows × 54 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    if column != 'Label':\n",
    "        if df[column].dtype != float and df[column].dtype != int:\n",
    "            df[column] = df[column].apply(calculate_mean_from_string)\n",
    "    else:\n",
    "        df[column] = df[column].str.split('-').str[1].astype(int)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:48:12.621093Z",
     "start_time": "2023-11-26T20:48:12.595332Z"
    }
   },
   "id": "9f5fcf8e7522bca0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59f1fbbc0b0e99c3"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "X = df.drop('Label', axis=1) \n",
    "y = df['Label']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:24:06.955375Z",
     "start_time": "2023-11-26T20:24:06.910117Z"
    }
   },
   "id": "fcfb5f2eeb5f213e"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:24:06.955443Z",
     "start_time": "2023-11-26T20:24:06.915391Z"
    }
   },
   "id": "1c00d2acc9c38954"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      "Label\n",
      "9    811\n",
      "5    807\n",
      "2    803\n",
      "4    798\n",
      "7    791\n",
      "0    789\n",
      "3    783\n",
      "8    749\n",
      "1    352\n",
      "6    302\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print class distribution before SMOTE\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:24:06.955770Z",
     "start_time": "2023-11-26T20:24:06.924076Z"
    }
   },
   "id": "7060607ef05ba0e"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Oversample the features values using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:24:07.032065Z",
     "start_time": "2023-11-26T20:24:06.927139Z"
    }
   },
   "id": "653d109c83f8f4a9"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution after SMOTE:\n",
      "Label\n",
      "2    811\n",
      "9    811\n",
      "5    811\n",
      "1    811\n",
      "7    811\n",
      "0    811\n",
      "8    811\n",
      "4    811\n",
      "6    811\n",
      "3    811\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print class distribution after SMOTE\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:24:07.059678Z",
     "start_time": "2023-11-26T20:24:07.008393Z"
    }
   },
   "id": "7abda0c74061ad7f"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Standardize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:24:07.074817Z",
     "start_time": "2023-11-26T20:24:07.014839Z"
    }
   },
   "id": "1787e79f125e4930"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using TenserFlow"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f962185e1a1a37df"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "mean_neurons = (X_train_scaled.shape[1] + len(np.unique(y_train_resampled))) // 2\n",
    "num_input_neurons = X_train_scaled.shape[1]\n",
    "num_output_neurons = len(np.unique(y_train_resampled))\n",
    "neurons_hidden_layer = int(2/3 * num_input_neurons + 1/3 * num_output_neurons)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T21:36:11.012552Z",
     "start_time": "2023-11-26T21:36:11.008496Z"
    }
   },
   "id": "61504167f1f66574"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "229/229 [==============================] - 0s 685us/step - loss: 1.4701 - val_loss: 1.0554\n",
      "Epoch 2/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 1.0022 - val_loss: 0.8859\n",
      "Epoch 3/300\n",
      "229/229 [==============================] - 0s 451us/step - loss: 0.8873 - val_loss: 0.8392\n",
      "Epoch 4/300\n",
      "229/229 [==============================] - 0s 446us/step - loss: 0.8346 - val_loss: 0.8103\n",
      "Epoch 5/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.8067 - val_loss: 0.7840\n",
      "Epoch 6/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.7882 - val_loss: 0.7752\n",
      "Epoch 7/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.7733 - val_loss: 0.7852\n",
      "Epoch 8/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7618 - val_loss: 0.7759\n",
      "Epoch 9/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7539 - val_loss: 0.7458\n",
      "Epoch 10/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7462 - val_loss: 0.7529\n",
      "Epoch 11/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7400 - val_loss: 0.7377\n",
      "Epoch 12/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.7370 - val_loss: 0.7485\n",
      "Epoch 13/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7309 - val_loss: 0.7383\n",
      "Epoch 14/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.7282 - val_loss: 0.7326\n",
      "Epoch 15/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7219 - val_loss: 0.7562\n",
      "Epoch 16/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.7204 - val_loss: 0.7104\n",
      "Epoch 17/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.7168 - val_loss: 0.7201\n",
      "Epoch 18/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.7171 - val_loss: 0.7070\n",
      "Epoch 19/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.7122 - val_loss: 0.7077\n",
      "Epoch 20/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7110 - val_loss: 0.7122\n",
      "Epoch 21/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7092 - val_loss: 0.7141\n",
      "Epoch 22/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.7070 - val_loss: 0.7197\n",
      "Epoch 23/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7052 - val_loss: 0.7216\n",
      "Epoch 24/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7058 - val_loss: 0.7233\n",
      "Epoch 25/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.7028 - val_loss: 0.7100\n",
      "Epoch 26/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7029 - val_loss: 0.7127\n",
      "Epoch 27/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7001 - val_loss: 0.7702\n",
      "Epoch 28/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7027 - val_loss: 0.6968\n",
      "Epoch 29/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6978 - val_loss: 0.7198\n",
      "Epoch 30/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6990 - val_loss: 0.7010\n",
      "Epoch 31/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6984 - val_loss: 0.7187\n",
      "Epoch 32/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6970 - val_loss: 0.7134\n",
      "Epoch 33/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6975 - val_loss: 0.7054\n",
      "Epoch 34/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6960 - val_loss: 0.7059\n",
      "Epoch 35/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6960 - val_loss: 0.7089\n",
      "Epoch 36/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6942 - val_loss: 0.7075\n",
      "Epoch 37/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6932 - val_loss: 0.7095\n",
      "Epoch 38/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6954 - val_loss: 0.6901\n",
      "Epoch 39/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6938 - val_loss: 0.6987\n",
      "Epoch 40/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6944 - val_loss: 0.6998\n",
      "Epoch 41/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6931 - val_loss: 0.7061\n",
      "Epoch 42/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6954 - val_loss: 0.6985\n",
      "Epoch 43/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6932 - val_loss: 0.7371\n",
      "Epoch 44/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6936 - val_loss: 0.6931\n",
      "Epoch 45/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6919 - val_loss: 0.6871\n",
      "Epoch 46/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6909 - val_loss: 0.6860\n",
      "Epoch 47/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6904 - val_loss: 0.7212\n",
      "Epoch 48/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6934 - val_loss: 0.7018\n",
      "Epoch 49/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6932 - val_loss: 0.7090\n",
      "Epoch 50/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6912 - val_loss: 0.6991\n",
      "Epoch 51/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6896 - val_loss: 0.6956\n",
      "Epoch 52/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6928 - val_loss: 0.7003\n",
      "Epoch 53/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6883 - val_loss: 0.6964\n",
      "Epoch 54/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6911 - val_loss: 0.6928\n",
      "Epoch 55/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6895 - val_loss: 0.7059\n",
      "Epoch 56/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6903 - val_loss: 0.6951\n",
      "Epoch 57/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6891 - val_loss: 0.7050\n",
      "Epoch 58/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6883 - val_loss: 0.7145\n",
      "Epoch 59/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6892 - val_loss: 0.7051\n",
      "Epoch 60/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6881 - val_loss: 0.7356\n",
      "Epoch 61/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6911 - val_loss: 0.6871\n",
      "Epoch 62/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6890 - val_loss: 0.7085\n",
      "Epoch 63/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6890 - val_loss: 0.6955\n",
      "Epoch 64/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6889 - val_loss: 0.6967\n",
      "Epoch 65/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6874 - val_loss: 0.6964\n",
      "Epoch 66/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6877 - val_loss: 0.7088\n",
      "Epoch 67/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6895 - val_loss: 0.7100\n",
      "Epoch 68/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6883 - val_loss: 0.7114\n",
      "Epoch 69/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6884 - val_loss: 0.6978\n",
      "Epoch 70/300\n",
      "229/229 [==============================] - 0s 446us/step - loss: 0.6875 - val_loss: 0.7008\n",
      "Epoch 71/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6871 - val_loss: 0.6924\n",
      "Epoch 72/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6847 - val_loss: 0.7034\n",
      "Epoch 73/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6871 - val_loss: 0.6914\n",
      "Epoch 74/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6864 - val_loss: 0.6992\n",
      "Epoch 75/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6892 - val_loss: 0.6899\n",
      "Epoch 76/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6860 - val_loss: 0.7076\n",
      "Epoch 77/300\n",
      "229/229 [==============================] - 0s 452us/step - loss: 0.6853 - val_loss: 0.6935\n",
      "Epoch 78/300\n",
      "229/229 [==============================] - 0s 485us/step - loss: 0.6873 - val_loss: 0.6977\n",
      "Epoch 79/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6855 - val_loss: 0.6867\n",
      "Epoch 80/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6868 - val_loss: 0.7120\n",
      "Epoch 81/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6852 - val_loss: 0.7009\n",
      "Epoch 82/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6851 - val_loss: 0.6898\n",
      "Epoch 83/300\n",
      "229/229 [==============================] - 0s 446us/step - loss: 0.6867 - val_loss: 0.6941\n",
      "Epoch 84/300\n",
      "229/229 [==============================] - 0s 441us/step - loss: 0.6853 - val_loss: 0.6934\n",
      "Epoch 85/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6861 - val_loss: 0.6998\n",
      "Epoch 86/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6833 - val_loss: 0.7157\n",
      "Epoch 87/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6880 - val_loss: 0.7009\n",
      "Epoch 88/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6848 - val_loss: 0.6849\n",
      "Epoch 89/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6870 - val_loss: 0.6965\n",
      "Epoch 90/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6846 - val_loss: 0.6999\n",
      "Epoch 91/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6859 - val_loss: 0.7053\n",
      "Epoch 92/300\n",
      "229/229 [==============================] - 0s 492us/step - loss: 0.6867 - val_loss: 0.6931\n",
      "Epoch 93/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6869 - val_loss: 0.6904\n",
      "Epoch 94/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6834 - val_loss: 0.7039\n",
      "Epoch 95/300\n",
      "229/229 [==============================] - 0s 405us/step - loss: 0.6857 - val_loss: 0.7038\n",
      "Epoch 96/300\n",
      "229/229 [==============================] - 0s 487us/step - loss: 0.6840 - val_loss: 0.7089\n",
      "Epoch 97/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6839 - val_loss: 0.7070\n",
      "Epoch 98/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6831 - val_loss: 0.6989\n",
      "Epoch 99/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6839 - val_loss: 0.7077\n",
      "Epoch 100/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6835 - val_loss: 0.7122\n",
      "Epoch 101/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6847 - val_loss: 0.7025\n",
      "Epoch 102/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6837 - val_loss: 0.6968\n",
      "Epoch 103/300\n",
      "229/229 [==============================] - 0s 452us/step - loss: 0.6836 - val_loss: 0.7117\n",
      "Epoch 104/300\n",
      "229/229 [==============================] - 0s 457us/step - loss: 0.6843 - val_loss: 0.6902\n",
      "Epoch 105/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6837 - val_loss: 0.6987\n",
      "Epoch 106/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6826 - val_loss: 0.6882\n",
      "Epoch 107/300\n",
      "229/229 [==============================] - 0s 460us/step - loss: 0.6855 - val_loss: 0.6907\n",
      "Epoch 108/300\n",
      "229/229 [==============================] - 0s 448us/step - loss: 0.6841 - val_loss: 0.7085\n",
      "Epoch 109/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6840 - val_loss: 0.7139\n",
      "Epoch 110/300\n",
      "229/229 [==============================] - 0s 441us/step - loss: 0.6821 - val_loss: 0.7076\n",
      "Epoch 111/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6854 - val_loss: 0.6919\n",
      "Epoch 112/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6830 - val_loss: 0.6969\n",
      "Epoch 113/300\n",
      "229/229 [==============================] - 0s 449us/step - loss: 0.6847 - val_loss: 0.6871\n",
      "Epoch 114/300\n",
      "229/229 [==============================] - 0s 447us/step - loss: 0.6832 - val_loss: 0.7070\n",
      "Epoch 115/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6820 - val_loss: 0.6832\n",
      "Epoch 116/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6838 - val_loss: 0.6954\n",
      "Epoch 117/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6844 - val_loss: 0.6845\n",
      "Epoch 118/300\n",
      "229/229 [==============================] - 0s 445us/step - loss: 0.6831 - val_loss: 0.6964\n",
      "Epoch 119/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6825 - val_loss: 0.6882\n",
      "Epoch 120/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6836 - val_loss: 0.6928\n",
      "Epoch 121/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6818 - val_loss: 0.6882\n",
      "Epoch 122/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6824 - val_loss: 0.7005\n",
      "Epoch 123/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6830 - val_loss: 0.7009\n",
      "Epoch 124/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6814 - val_loss: 0.7000\n",
      "Epoch 125/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6837 - val_loss: 0.7013\n",
      "Epoch 126/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6818 - val_loss: 0.6900\n",
      "Epoch 127/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6833 - val_loss: 0.6906\n",
      "Epoch 128/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6826 - val_loss: 0.7014\n",
      "Epoch 129/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6820 - val_loss: 0.6932\n",
      "Epoch 130/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6818 - val_loss: 0.6809\n",
      "Epoch 131/300\n",
      "229/229 [==============================] - 0s 475us/step - loss: 0.6833 - val_loss: 0.6870\n",
      "Epoch 132/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6820 - val_loss: 0.6994\n",
      "Epoch 133/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6814 - val_loss: 0.6891\n",
      "Epoch 134/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6831 - val_loss: 0.6931\n",
      "Epoch 135/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6827 - val_loss: 0.7107\n",
      "Epoch 136/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6841 - val_loss: 0.6936\n",
      "Epoch 137/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6832 - val_loss: 0.7054\n",
      "Epoch 138/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6816 - val_loss: 0.7381\n",
      "Epoch 139/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6822 - val_loss: 0.6920\n",
      "Epoch 140/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6811 - val_loss: 0.7053\n",
      "Epoch 141/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6830 - val_loss: 0.6903\n",
      "Epoch 142/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6828 - val_loss: 0.6858\n",
      "Epoch 143/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6813 - val_loss: 0.7003\n",
      "Epoch 144/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6807 - val_loss: 0.7144\n",
      "Epoch 145/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6821 - val_loss: 0.7048\n",
      "Epoch 146/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6818 - val_loss: 0.6995\n",
      "Epoch 147/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6842 - val_loss: 0.6917\n",
      "Epoch 148/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6832 - val_loss: 0.6909\n",
      "Epoch 149/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6829 - val_loss: 0.6960\n",
      "Epoch 150/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6807 - val_loss: 0.6867\n",
      "Epoch 151/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6807 - val_loss: 0.6875\n",
      "Epoch 152/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6820 - val_loss: 0.6878\n",
      "Epoch 153/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6824 - val_loss: 0.6926\n",
      "Epoch 154/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6822 - val_loss: 0.6984\n",
      "Epoch 155/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6809 - val_loss: 0.6910\n",
      "Epoch 156/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6800 - val_loss: 0.6820\n",
      "Epoch 157/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6839 - val_loss: 0.7056\n",
      "Epoch 158/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6821 - val_loss: 0.7168\n",
      "Epoch 159/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6802 - val_loss: 0.6834\n",
      "Epoch 160/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6821 - val_loss: 0.6901\n",
      "Epoch 161/300\n",
      "229/229 [==============================] - 0s 472us/step - loss: 0.6794 - val_loss: 0.6851\n",
      "Epoch 162/300\n",
      "229/229 [==============================] - 0s 453us/step - loss: 0.6798 - val_loss: 0.6973\n",
      "Epoch 163/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6819 - val_loss: 0.6909\n",
      "Epoch 164/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6818 - val_loss: 0.6929\n",
      "Epoch 165/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6828 - val_loss: 0.6862\n",
      "Epoch 166/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6807 - val_loss: 0.6867\n",
      "Epoch 167/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6798 - val_loss: 0.6891\n",
      "Epoch 168/300\n",
      "229/229 [==============================] - 0s 450us/step - loss: 0.6808 - val_loss: 0.6929\n",
      "Epoch 169/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6815 - val_loss: 0.6977\n",
      "Epoch 170/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6816 - val_loss: 0.6882\n",
      "Epoch 171/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6804 - val_loss: 0.6869\n",
      "Epoch 172/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6816 - val_loss: 0.6950\n",
      "Epoch 173/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6799 - val_loss: 0.6835\n",
      "Epoch 174/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6816 - val_loss: 0.6848\n",
      "Epoch 175/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6818 - val_loss: 0.6898\n",
      "Epoch 176/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6810 - val_loss: 0.6870\n",
      "Epoch 177/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6817 - val_loss: 0.6876\n",
      "Epoch 178/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6789 - val_loss: 0.7123\n",
      "Epoch 179/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6820 - val_loss: 0.6974\n",
      "Epoch 180/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6813 - val_loss: 0.7050\n",
      "Epoch 181/300\n",
      "229/229 [==============================] - 0s 790us/step - loss: 0.6787 - val_loss: 0.6826\n",
      "Epoch 182/300\n",
      "229/229 [==============================] - 0s 658us/step - loss: 0.6812 - val_loss: 0.6835\n",
      "Epoch 183/300\n",
      "229/229 [==============================] - 0s 761us/step - loss: 0.6762 - val_loss: 0.6942\n",
      "Epoch 184/300\n",
      "229/229 [==============================] - 0s 1ms/step - loss: 0.6785 - val_loss: 0.6843\n",
      "Epoch 185/300\n",
      "229/229 [==============================] - 0s 499us/step - loss: 0.6802 - val_loss: 0.6874\n",
      "Epoch 186/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6800 - val_loss: 0.6875\n",
      "Epoch 187/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6818 - val_loss: 0.6863\n",
      "Epoch 188/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6798 - val_loss: 0.6893\n",
      "Epoch 189/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6787 - val_loss: 0.6885\n",
      "Epoch 190/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6802 - val_loss: 0.7022\n",
      "Epoch 191/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6804 - val_loss: 0.7225\n",
      "Epoch 192/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6802 - val_loss: 0.6894\n",
      "Epoch 193/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6819 - val_loss: 0.6995\n",
      "Epoch 194/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6804 - val_loss: 0.6985\n",
      "Epoch 195/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6804 - val_loss: 0.6815\n",
      "Epoch 196/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6821 - val_loss: 0.7109\n",
      "Epoch 197/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6819 - val_loss: 0.7015\n",
      "Epoch 198/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6787 - val_loss: 0.6900\n",
      "Epoch 199/300\n",
      "229/229 [==============================] - 0s 444us/step - loss: 0.6808 - val_loss: 0.7196\n",
      "Epoch 200/300\n",
      "229/229 [==============================] - 0s 441us/step - loss: 0.6804 - val_loss: 0.7007\n",
      "Epoch 201/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6806 - val_loss: 0.6933\n",
      "Epoch 202/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6818 - val_loss: 0.6890\n",
      "Epoch 203/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6784 - val_loss: 0.6818\n",
      "Epoch 204/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6780 - val_loss: 0.6889\n",
      "Epoch 205/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6813 - val_loss: 0.6964\n",
      "Epoch 206/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6791 - val_loss: 0.7101\n",
      "Epoch 207/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6807 - val_loss: 0.7003\n",
      "Epoch 208/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6789 - val_loss: 0.6952\n",
      "Epoch 209/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6809 - val_loss: 0.6794\n",
      "Epoch 210/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6790 - val_loss: 0.7045\n",
      "Epoch 211/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6812 - val_loss: 0.6858\n",
      "Epoch 212/300\n",
      "229/229 [==============================] - 0s 450us/step - loss: 0.6802 - val_loss: 0.6858\n",
      "Epoch 213/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6779 - val_loss: 0.6955\n",
      "Epoch 214/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6807 - val_loss: 0.6951\n",
      "Epoch 215/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6810 - val_loss: 0.6998\n",
      "Epoch 216/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6777 - val_loss: 0.6964\n",
      "Epoch 217/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6814 - val_loss: 0.6909\n",
      "Epoch 218/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6799 - val_loss: 0.6998\n",
      "Epoch 219/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6782 - val_loss: 0.6746\n",
      "Epoch 220/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6808 - val_loss: 0.7025\n",
      "Epoch 221/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6797 - val_loss: 0.6996\n",
      "Epoch 222/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6795 - val_loss: 0.6965\n",
      "Epoch 223/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6808 - val_loss: 0.6910\n",
      "Epoch 224/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6813 - val_loss: 0.6825\n",
      "Epoch 225/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6802 - val_loss: 0.7119\n",
      "Epoch 226/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6777 - val_loss: 0.7038\n",
      "Epoch 227/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6816 - val_loss: 0.6985\n",
      "Epoch 228/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6789 - val_loss: 0.7002\n",
      "Epoch 229/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6817 - val_loss: 0.6921\n",
      "Epoch 230/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6774 - val_loss: 0.7112\n",
      "Epoch 231/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6797 - val_loss: 0.6978\n",
      "Epoch 232/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6794 - val_loss: 0.7106\n",
      "Epoch 233/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6808 - val_loss: 0.6881\n",
      "Epoch 234/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6790 - val_loss: 0.6981\n",
      "Epoch 235/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6812 - val_loss: 0.6958\n",
      "Epoch 236/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6798 - val_loss: 0.7091\n",
      "Epoch 237/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6801 - val_loss: 0.6956\n",
      "Epoch 238/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6813 - val_loss: 0.6890\n",
      "Epoch 239/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6790 - val_loss: 0.6926\n",
      "Epoch 240/300\n",
      "229/229 [==============================] - 0s 410us/step - loss: 0.6805 - val_loss: 0.6945\n",
      "Epoch 241/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6796 - val_loss: 0.6982\n",
      "Epoch 242/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6809 - val_loss: 0.6956\n",
      "Epoch 243/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6811 - val_loss: 0.6972\n",
      "Epoch 244/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6789 - val_loss: 0.6938\n",
      "Epoch 245/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6810 - val_loss: 0.6914\n",
      "Epoch 246/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6800 - val_loss: 0.7057\n",
      "Epoch 247/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6805 - val_loss: 0.6973\n",
      "Epoch 248/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6795 - val_loss: 0.6809\n",
      "Epoch 249/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6797 - val_loss: 0.6884\n",
      "Epoch 250/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6813 - val_loss: 0.6908\n",
      "Epoch 251/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6776 - val_loss: 0.7041\n",
      "Epoch 252/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6799 - val_loss: 0.6871\n",
      "Epoch 253/300\n",
      "229/229 [==============================] - 0s 483us/step - loss: 0.6817 - val_loss: 0.6841\n",
      "Epoch 254/300\n",
      "229/229 [==============================] - 0s 473us/step - loss: 0.6782 - val_loss: 0.6839\n",
      "Epoch 255/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6802 - val_loss: 0.6962\n",
      "Epoch 256/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6809 - val_loss: 0.6905\n",
      "Epoch 257/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6788 - val_loss: 0.6916\n",
      "Epoch 258/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6801 - val_loss: 0.6994\n",
      "Epoch 259/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6810 - val_loss: 0.6886\n",
      "Epoch 260/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6807 - val_loss: 0.6903\n",
      "Epoch 261/300\n",
      "229/229 [==============================] - 0s 584us/step - loss: 0.6784 - val_loss: 0.6882\n",
      "Epoch 262/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6796 - val_loss: 0.6897\n",
      "Epoch 263/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6804 - val_loss: 0.7256\n",
      "Epoch 264/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6801 - val_loss: 0.6966\n",
      "Epoch 265/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6785 - val_loss: 0.6928\n",
      "Epoch 266/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6781 - val_loss: 0.6825\n",
      "Epoch 267/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6787 - val_loss: 0.7080\n",
      "Epoch 268/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6781 - val_loss: 0.7019\n",
      "Epoch 269/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6805 - val_loss: 0.6839\n",
      "Epoch 270/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6800 - val_loss: 0.6994\n",
      "Epoch 271/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6797 - val_loss: 0.6830\n",
      "Epoch 272/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6803 - val_loss: 0.7034\n",
      "Epoch 273/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6792 - val_loss: 0.6992\n",
      "Epoch 274/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6815 - val_loss: 0.6840\n",
      "Epoch 275/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6796 - val_loss: 0.6926\n",
      "Epoch 276/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6791 - val_loss: 0.6927\n",
      "Epoch 277/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6790 - val_loss: 0.7097\n",
      "Epoch 278/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6778 - val_loss: 0.6927\n",
      "Epoch 279/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6781 - val_loss: 0.6892\n",
      "Epoch 280/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6799 - val_loss: 0.7070\n",
      "Epoch 281/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6787 - val_loss: 0.7078\n",
      "Epoch 282/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6812 - val_loss: 0.6953\n",
      "Epoch 283/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6794 - val_loss: 0.7022\n",
      "Epoch 284/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6789 - val_loss: 0.7206\n",
      "Epoch 285/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6799 - val_loss: 0.6902\n",
      "Epoch 286/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6795 - val_loss: 0.7188\n",
      "Epoch 287/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6803 - val_loss: 0.7018\n",
      "Epoch 288/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6794 - val_loss: 0.6939\n",
      "Epoch 289/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6799 - val_loss: 0.6998\n",
      "Epoch 290/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6778 - val_loss: 0.6987\n",
      "Epoch 291/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6800 - val_loss: 0.7084\n",
      "Epoch 292/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6789 - val_loss: 0.7101\n",
      "Epoch 293/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6796 - val_loss: 0.6922\n",
      "Epoch 294/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6777 - val_loss: 0.7059\n",
      "Epoch 295/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6777 - val_loss: 0.7189\n",
      "Epoch 296/300\n",
      "229/229 [==============================] - 0s 444us/step - loss: 0.6813 - val_loss: 0.6884\n",
      "Epoch 297/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6798 - val_loss: 0.6964\n",
      "Epoch 298/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6783 - val_loss: 0.6899\n",
      "Epoch 299/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6798 - val_loss: 0.6920\n",
      "Epoch 300/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6808 - val_loss: 0.6772\n",
      "26/26 [==============================] - 0s 330us/step\n",
      "Epoch 1/300\n",
      "229/229 [==============================] - 0s 603us/step - loss: 1.5480 - val_loss: 1.1808\n",
      "Epoch 2/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.9823 - val_loss: 0.9600\n",
      "Epoch 3/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.8759 - val_loss: 0.9149\n",
      "Epoch 4/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.8286 - val_loss: 0.8639\n",
      "Epoch 5/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.7963 - val_loss: 0.8416\n",
      "Epoch 6/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7775 - val_loss: 0.8580\n",
      "Epoch 7/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7634 - val_loss: 0.8328\n",
      "Epoch 8/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7520 - val_loss: 0.8353\n",
      "Epoch 9/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7431 - val_loss: 0.8236\n",
      "Epoch 10/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.7349 - val_loss: 0.8455\n",
      "Epoch 11/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7297 - val_loss: 0.8174\n",
      "Epoch 12/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7252 - val_loss: 0.8037\n",
      "Epoch 13/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7194 - val_loss: 0.8024\n",
      "Epoch 14/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.7200 - val_loss: 0.7953\n",
      "Epoch 15/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.7138 - val_loss: 0.7863\n",
      "Epoch 16/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7108 - val_loss: 0.7873\n",
      "Epoch 17/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7093 - val_loss: 0.7954\n",
      "Epoch 18/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7066 - val_loss: 0.8017\n",
      "Epoch 19/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.7047 - val_loss: 0.8199\n",
      "Epoch 20/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7041 - val_loss: 0.7809\n",
      "Epoch 21/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7008 - val_loss: 0.8041\n",
      "Epoch 22/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6998 - val_loss: 0.7910\n",
      "Epoch 23/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.7013 - val_loss: 0.7906\n",
      "Epoch 24/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6968 - val_loss: 0.7979\n",
      "Epoch 25/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6962 - val_loss: 0.7735\n",
      "Epoch 26/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6960 - val_loss: 0.7881\n",
      "Epoch 27/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6937 - val_loss: 0.7771\n",
      "Epoch 28/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6961 - val_loss: 0.7666\n",
      "Epoch 29/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6943 - val_loss: 0.7791\n",
      "Epoch 30/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6932 - val_loss: 0.7844\n",
      "Epoch 31/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6935 - val_loss: 0.7773\n",
      "Epoch 32/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6911 - val_loss: 0.7728\n",
      "Epoch 33/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6910 - val_loss: 0.7929\n",
      "Epoch 34/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6892 - val_loss: 0.8078\n",
      "Epoch 35/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6902 - val_loss: 0.7919\n",
      "Epoch 36/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6887 - val_loss: 0.7778\n",
      "Epoch 37/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6880 - val_loss: 0.7787\n",
      "Epoch 38/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6909 - val_loss: 0.7875\n",
      "Epoch 39/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6865 - val_loss: 0.7769\n",
      "Epoch 40/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6880 - val_loss: 0.7712\n",
      "Epoch 41/300\n",
      "229/229 [==============================] - 0s 456us/step - loss: 0.6879 - val_loss: 0.7783\n",
      "Epoch 42/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6840 - val_loss: 0.8104\n",
      "Epoch 43/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6865 - val_loss: 0.7834\n",
      "Epoch 44/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6855 - val_loss: 0.7884\n",
      "Epoch 45/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6873 - val_loss: 0.7782\n",
      "Epoch 46/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6863 - val_loss: 0.7814\n",
      "Epoch 47/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6866 - val_loss: 0.7749\n",
      "Epoch 48/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6861 - val_loss: 0.7905\n",
      "Epoch 49/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6867 - val_loss: 0.7608\n",
      "Epoch 50/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6846 - val_loss: 0.7890\n",
      "Epoch 51/300\n",
      "229/229 [==============================] - 0s 493us/step - loss: 0.6853 - val_loss: 0.7849\n",
      "Epoch 52/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6851 - val_loss: 0.7852\n",
      "Epoch 53/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6844 - val_loss: 0.7798\n",
      "Epoch 54/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6848 - val_loss: 0.7662\n",
      "Epoch 55/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6840 - val_loss: 0.7849\n",
      "Epoch 56/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6830 - val_loss: 0.7800\n",
      "Epoch 57/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6825 - val_loss: 0.7688\n",
      "Epoch 58/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6835 - val_loss: 0.7820\n",
      "Epoch 59/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6822 - val_loss: 0.7870\n",
      "Epoch 60/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6814 - val_loss: 0.7877\n",
      "Epoch 61/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6825 - val_loss: 0.7708\n",
      "Epoch 62/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6824 - val_loss: 0.7911\n",
      "Epoch 63/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6845 - val_loss: 0.7805\n",
      "Epoch 64/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6841 - val_loss: 0.8849\n",
      "Epoch 65/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6838 - val_loss: 0.7738\n",
      "Epoch 66/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6826 - val_loss: 0.7650\n",
      "Epoch 67/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6831 - val_loss: 0.7756\n",
      "Epoch 68/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6823 - val_loss: 0.7671\n",
      "Epoch 69/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6834 - val_loss: 0.7645\n",
      "Epoch 70/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6816 - val_loss: 0.7951\n",
      "Epoch 71/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6827 - val_loss: 0.7814\n",
      "Epoch 72/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6799 - val_loss: 0.7681\n",
      "Epoch 73/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6789 - val_loss: 0.7830\n",
      "Epoch 74/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6833 - val_loss: 0.7927\n",
      "Epoch 75/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6820 - val_loss: 0.7779\n",
      "Epoch 76/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6825 - val_loss: 0.7759\n",
      "Epoch 77/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6844 - val_loss: 0.7760\n",
      "Epoch 78/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6805 - val_loss: 0.7689\n",
      "Epoch 79/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6809 - val_loss: 0.7691\n",
      "Epoch 80/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6795 - val_loss: 0.7822\n",
      "Epoch 81/300\n",
      "229/229 [==============================] - 0s 464us/step - loss: 0.6806 - val_loss: 0.7779\n",
      "Epoch 82/300\n",
      "229/229 [==============================] - 0s 443us/step - loss: 0.6805 - val_loss: 0.7761\n",
      "Epoch 83/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6797 - val_loss: 0.8184\n",
      "Epoch 84/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6796 - val_loss: 0.7735\n",
      "Epoch 85/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6812 - val_loss: 0.7763\n",
      "Epoch 86/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6795 - val_loss: 0.7636\n",
      "Epoch 87/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6798 - val_loss: 0.7765\n",
      "Epoch 88/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6796 - val_loss: 0.7593\n",
      "Epoch 89/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6799 - val_loss: 0.7702\n",
      "Epoch 90/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6789 - val_loss: 0.7793\n",
      "Epoch 91/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6791 - val_loss: 0.7876\n",
      "Epoch 92/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6785 - val_loss: 0.7889\n",
      "Epoch 93/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6781 - val_loss: 0.7654\n",
      "Epoch 94/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6780 - val_loss: 0.7801\n",
      "Epoch 95/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6794 - val_loss: 0.7820\n",
      "Epoch 96/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6795 - val_loss: 0.7777\n",
      "Epoch 97/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6804 - val_loss: 0.7730\n",
      "Epoch 98/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6803 - val_loss: 0.7757\n",
      "Epoch 99/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6792 - val_loss: 0.7575\n",
      "Epoch 100/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6791 - val_loss: 0.7496\n",
      "Epoch 101/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6792 - val_loss: 0.7702\n",
      "Epoch 102/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6767 - val_loss: 0.7709\n",
      "Epoch 103/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6773 - val_loss: 0.7843\n",
      "Epoch 104/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6775 - val_loss: 0.7636\n",
      "Epoch 105/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6794 - val_loss: 0.7689\n",
      "Epoch 106/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6790 - val_loss: 0.7817\n",
      "Epoch 107/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6777 - val_loss: 0.7689\n",
      "Epoch 108/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6778 - val_loss: 0.7712\n",
      "Epoch 109/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6802 - val_loss: 0.7596\n",
      "Epoch 110/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6785 - val_loss: 0.7821\n",
      "Epoch 111/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6781 - val_loss: 0.7887\n",
      "Epoch 112/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6806 - val_loss: 0.7930\n",
      "Epoch 113/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6785 - val_loss: 0.7676\n",
      "Epoch 114/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6785 - val_loss: 0.7661\n",
      "Epoch 115/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6779 - val_loss: 0.7732\n",
      "Epoch 116/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6768 - val_loss: 0.7833\n",
      "Epoch 117/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6783 - val_loss: 0.7546\n",
      "Epoch 118/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6798 - val_loss: 0.7707\n",
      "Epoch 119/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6771 - val_loss: 0.7620\n",
      "Epoch 120/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6776 - val_loss: 0.7810\n",
      "Epoch 121/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6749 - val_loss: 0.7590\n",
      "Epoch 122/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6777 - val_loss: 0.7845\n",
      "Epoch 123/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6794 - val_loss: 0.7604\n",
      "Epoch 124/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6775 - val_loss: 0.7842\n",
      "Epoch 125/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6774 - val_loss: 0.7822\n",
      "Epoch 126/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6785 - val_loss: 0.7741\n",
      "Epoch 127/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6766 - val_loss: 0.7799\n",
      "Epoch 128/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6792 - val_loss: 0.7660\n",
      "Epoch 129/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6767 - val_loss: 0.7930\n",
      "Epoch 130/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6773 - val_loss: 0.7742\n",
      "Epoch 131/300\n",
      "229/229 [==============================] - 0s 446us/step - loss: 0.6770 - val_loss: 0.7718\n",
      "Epoch 132/300\n",
      "229/229 [==============================] - 0s 445us/step - loss: 0.6769 - val_loss: 0.7541\n",
      "Epoch 133/300\n",
      "229/229 [==============================] - 0s 449us/step - loss: 0.6777 - val_loss: 0.7683\n",
      "Epoch 134/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6769 - val_loss: 0.7894\n",
      "Epoch 135/300\n",
      "229/229 [==============================] - 0s 467us/step - loss: 0.6751 - val_loss: 0.7733\n",
      "Epoch 136/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6755 - val_loss: 0.7558\n",
      "Epoch 137/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6734 - val_loss: 0.7946\n",
      "Epoch 138/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6774 - val_loss: 0.7561\n",
      "Epoch 139/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6756 - val_loss: 0.7537\n",
      "Epoch 140/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6769 - val_loss: 0.7672\n",
      "Epoch 141/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6763 - val_loss: 0.7683\n",
      "Epoch 142/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6768 - val_loss: 0.7853\n",
      "Epoch 143/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6761 - val_loss: 0.7832\n",
      "Epoch 144/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6771 - val_loss: 0.7756\n",
      "Epoch 145/300\n",
      "229/229 [==============================] - 0s 446us/step - loss: 0.6759 - val_loss: 0.7779\n",
      "Epoch 146/300\n",
      "229/229 [==============================] - 0s 773us/step - loss: 0.6763 - val_loss: 0.7796\n",
      "Epoch 147/300\n",
      "229/229 [==============================] - 0s 538us/step - loss: 0.6751 - val_loss: 0.7778\n",
      "Epoch 148/300\n",
      "229/229 [==============================] - 0s 913us/step - loss: 0.6752 - val_loss: 0.7757\n",
      "Epoch 149/300\n",
      "229/229 [==============================] - 0s 540us/step - loss: 0.6774 - val_loss: 0.7761\n",
      "Epoch 150/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6773 - val_loss: 0.7509\n",
      "Epoch 151/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6724 - val_loss: 0.7858\n",
      "Epoch 152/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6774 - val_loss: 0.7709\n",
      "Epoch 153/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6764 - val_loss: 0.7658\n",
      "Epoch 154/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6782 - val_loss: 0.7797\n",
      "Epoch 155/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6736 - val_loss: 0.7686\n",
      "Epoch 156/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6768 - val_loss: 0.7807\n",
      "Epoch 157/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6759 - val_loss: 0.7649\n",
      "Epoch 158/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6749 - val_loss: 0.7864\n",
      "Epoch 159/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6755 - val_loss: 0.7919\n",
      "Epoch 160/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6753 - val_loss: 0.7678\n",
      "Epoch 161/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6762 - val_loss: 0.7744\n",
      "Epoch 162/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6755 - val_loss: 0.7582\n",
      "Epoch 163/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6772 - val_loss: 0.8115\n",
      "Epoch 164/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6752 - val_loss: 0.7657\n",
      "Epoch 165/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6755 - val_loss: 0.7571\n",
      "Epoch 166/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6749 - val_loss: 0.7852\n",
      "Epoch 167/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6755 - val_loss: 0.7673\n",
      "Epoch 168/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6757 - val_loss: 0.7731\n",
      "Epoch 169/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6746 - val_loss: 0.7547\n",
      "Epoch 170/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6742 - val_loss: 0.7641\n",
      "Epoch 171/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6750 - val_loss: 0.7835\n",
      "Epoch 172/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6726 - val_loss: 0.7857\n",
      "Epoch 173/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6755 - val_loss: 0.7736\n",
      "Epoch 174/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6773 - val_loss: 0.7693\n",
      "Epoch 175/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6757 - val_loss: 0.7620\n",
      "Epoch 176/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6754 - val_loss: 0.7859\n",
      "Epoch 177/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6733 - val_loss: 0.7673\n",
      "Epoch 178/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6754 - val_loss: 0.7610\n",
      "Epoch 179/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6731 - val_loss: 0.7888\n",
      "Epoch 180/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6750 - val_loss: 0.7855\n",
      "Epoch 181/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6772 - val_loss: 0.7788\n",
      "Epoch 182/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6743 - val_loss: 0.7915\n",
      "Epoch 183/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6776 - val_loss: 0.7576\n",
      "Epoch 184/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6745 - val_loss: 0.7808\n",
      "Epoch 185/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6729 - val_loss: 0.7740\n",
      "Epoch 186/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6748 - val_loss: 0.7764\n",
      "Epoch 187/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6753 - val_loss: 0.7823\n",
      "Epoch 188/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6740 - val_loss: 0.7824\n",
      "Epoch 189/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6738 - val_loss: 0.7569\n",
      "Epoch 190/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6754 - val_loss: 0.7711\n",
      "Epoch 191/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6758 - val_loss: 0.7603\n",
      "Epoch 192/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6728 - val_loss: 0.7667\n",
      "Epoch 193/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6741 - val_loss: 0.7735\n",
      "Epoch 194/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6758 - val_loss: 0.7681\n",
      "Epoch 195/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6768 - val_loss: 0.7836\n",
      "Epoch 196/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6742 - val_loss: 0.7583\n",
      "Epoch 197/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6752 - val_loss: 0.7960\n",
      "Epoch 198/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6730 - val_loss: 0.7787\n",
      "Epoch 199/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6749 - val_loss: 0.7654\n",
      "Epoch 200/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6759 - val_loss: 0.7611\n",
      "Epoch 201/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6732 - val_loss: 0.7641\n",
      "Epoch 202/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6746 - val_loss: 0.7677\n",
      "Epoch 203/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6755 - val_loss: 0.7738\n",
      "Epoch 204/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6742 - val_loss: 0.7569\n",
      "Epoch 205/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6761 - val_loss: 0.7582\n",
      "Epoch 206/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6755 - val_loss: 0.7550\n",
      "Epoch 207/300\n",
      "229/229 [==============================] - 0s 445us/step - loss: 0.6749 - val_loss: 0.7778\n",
      "Epoch 208/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6743 - val_loss: 0.7654\n",
      "Epoch 209/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6742 - val_loss: 0.7581\n",
      "Epoch 210/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6751 - val_loss: 0.7685\n",
      "Epoch 211/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6767 - val_loss: 0.7585\n",
      "Epoch 212/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6737 - val_loss: 0.7662\n",
      "Epoch 213/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6737 - val_loss: 0.7945\n",
      "Epoch 214/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6770 - val_loss: 0.7727\n",
      "Epoch 215/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6745 - val_loss: 0.8811\n",
      "Epoch 216/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6761 - val_loss: 0.7644\n",
      "Epoch 217/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6743 - val_loss: 0.7737\n",
      "Epoch 218/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6771 - val_loss: 0.7731\n",
      "Epoch 219/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6760 - val_loss: 0.7611\n",
      "Epoch 220/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6753 - val_loss: 0.7658\n",
      "Epoch 221/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6741 - val_loss: 0.7798\n",
      "Epoch 222/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6735 - val_loss: 0.7786\n",
      "Epoch 223/300\n",
      "229/229 [==============================] - 0s 452us/step - loss: 0.6752 - val_loss: 0.7692\n",
      "Epoch 224/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6753 - val_loss: 0.7558\n",
      "Epoch 225/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6746 - val_loss: 0.7646\n",
      "Epoch 226/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6742 - val_loss: 0.7688\n",
      "Epoch 227/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6724 - val_loss: 0.7722\n",
      "Epoch 228/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6745 - val_loss: 0.7546\n",
      "Epoch 229/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6741 - val_loss: 0.7695\n",
      "Epoch 230/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6717 - val_loss: 0.7769\n",
      "Epoch 231/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6740 - val_loss: 0.7651\n",
      "Epoch 232/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6726 - val_loss: 0.7910\n",
      "Epoch 233/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6743 - val_loss: 0.7943\n",
      "Epoch 234/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6744 - val_loss: 0.7748\n",
      "Epoch 235/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6758 - val_loss: 0.7556\n",
      "Epoch 236/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6739 - val_loss: 0.7599\n",
      "Epoch 237/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6762 - val_loss: 0.7665\n",
      "Epoch 238/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6756 - val_loss: 0.7949\n",
      "Epoch 239/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6740 - val_loss: 0.7649\n",
      "Epoch 240/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6753 - val_loss: 0.7643\n",
      "Epoch 241/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6761 - val_loss: 0.7842\n",
      "Epoch 242/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6757 - val_loss: 0.7745\n",
      "Epoch 243/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6740 - val_loss: 0.7671\n",
      "Epoch 244/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6748 - val_loss: 0.7687\n",
      "Epoch 245/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6748 - val_loss: 0.7824\n",
      "Epoch 246/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6738 - val_loss: 0.8439\n",
      "Epoch 247/300\n",
      "229/229 [==============================] - 0s 498us/step - loss: 0.6753 - val_loss: 0.7786\n",
      "Epoch 248/300\n",
      "229/229 [==============================] - 0s 453us/step - loss: 0.6728 - val_loss: 0.7789\n",
      "Epoch 249/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6709 - val_loss: 0.7662\n",
      "Epoch 250/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6761 - val_loss: 0.7651\n",
      "Epoch 251/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6755 - val_loss: 0.7692\n",
      "Epoch 252/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6725 - val_loss: 0.7766\n",
      "Epoch 253/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6754 - val_loss: 0.7755\n",
      "Epoch 254/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6725 - val_loss: 0.7657\n",
      "Epoch 255/300\n",
      "229/229 [==============================] - 0s 471us/step - loss: 0.6729 - val_loss: 0.7531\n",
      "Epoch 256/300\n",
      "229/229 [==============================] - 0s 520us/step - loss: 0.6724 - val_loss: 0.7661\n",
      "Epoch 257/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6729 - val_loss: 0.7700\n",
      "Epoch 258/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6736 - val_loss: 0.7628\n",
      "Epoch 259/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6726 - val_loss: 0.7772\n",
      "Epoch 260/300\n",
      "229/229 [==============================] - 0s 410us/step - loss: 0.6745 - val_loss: 0.7809\n",
      "Epoch 261/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6749 - val_loss: 0.7632\n",
      "Epoch 262/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6736 - val_loss: 0.7739\n",
      "Epoch 263/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6753 - val_loss: 0.7688\n",
      "Epoch 264/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6731 - val_loss: 0.7500\n",
      "Epoch 265/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6733 - val_loss: 0.7727\n",
      "Epoch 266/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6739 - val_loss: 0.7717\n",
      "Epoch 267/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6757 - val_loss: 0.7787\n",
      "Epoch 268/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6733 - val_loss: 0.7828\n",
      "Epoch 269/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6742 - val_loss: 0.7688\n",
      "Epoch 270/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6736 - val_loss: 0.7873\n",
      "Epoch 271/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6712 - val_loss: 0.7823\n",
      "Epoch 272/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6717 - val_loss: 0.7659\n",
      "Epoch 273/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6751 - val_loss: 0.7615\n",
      "Epoch 274/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6738 - val_loss: 0.7660\n",
      "Epoch 275/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6745 - val_loss: 0.7769\n",
      "Epoch 276/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6739 - val_loss: 0.7677\n",
      "Epoch 277/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6747 - val_loss: 0.7752\n",
      "Epoch 278/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6747 - val_loss: 0.7788\n",
      "Epoch 279/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6737 - val_loss: 0.7660\n",
      "Epoch 280/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6734 - val_loss: 0.7761\n",
      "Epoch 281/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6741 - val_loss: 0.7671\n",
      "Epoch 282/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6734 - val_loss: 0.7707\n",
      "Epoch 283/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6741 - val_loss: 0.7622\n",
      "Epoch 284/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6754 - val_loss: 0.7636\n",
      "Epoch 285/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6736 - val_loss: 0.7824\n",
      "Epoch 286/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6741 - val_loss: 0.7744\n",
      "Epoch 287/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6724 - val_loss: 0.7819\n",
      "Epoch 288/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6740 - val_loss: 0.8256\n",
      "Epoch 289/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6739 - val_loss: 0.7643\n",
      "Epoch 290/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6736 - val_loss: 0.7811\n",
      "Epoch 291/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6725 - val_loss: 0.7624\n",
      "Epoch 292/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6740 - val_loss: 0.7661\n",
      "Epoch 293/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6743 - val_loss: 0.7605\n",
      "Epoch 294/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6696 - val_loss: 0.7750\n",
      "Epoch 295/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6735 - val_loss: 0.8149\n",
      "Epoch 296/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6745 - val_loss: 0.7704\n",
      "Epoch 297/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6734 - val_loss: 0.7779\n",
      "Epoch 298/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6736 - val_loss: 0.7699\n",
      "Epoch 299/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6724 - val_loss: 0.7757\n",
      "Epoch 300/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6723 - val_loss: 0.7664\n",
      "26/26 [==============================] - 0s 341us/step\n",
      "Epoch 1/300\n",
      "229/229 [==============================] - 0s 588us/step - loss: 1.4670 - val_loss: 1.1279\n",
      "Epoch 2/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 1.0075 - val_loss: 1.0059\n",
      "Epoch 3/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.8936 - val_loss: 0.9569\n",
      "Epoch 4/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.8415 - val_loss: 0.9319\n",
      "Epoch 5/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.8094 - val_loss: 0.8893\n",
      "Epoch 6/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.7828 - val_loss: 0.8931\n",
      "Epoch 7/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7682 - val_loss: 0.8657\n",
      "Epoch 8/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.7547 - val_loss: 0.8560\n",
      "Epoch 9/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.7436 - val_loss: 0.8531\n",
      "Epoch 10/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.7365 - val_loss: 0.8611\n",
      "Epoch 11/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7311 - val_loss: 0.8312\n",
      "Epoch 12/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7240 - val_loss: 0.8286\n",
      "Epoch 13/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.7201 - val_loss: 0.8460\n",
      "Epoch 14/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.7164 - val_loss: 0.8478\n",
      "Epoch 15/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7107 - val_loss: 0.8271\n",
      "Epoch 16/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7085 - val_loss: 0.8168\n",
      "Epoch 17/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7024 - val_loss: 0.8221\n",
      "Epoch 18/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7028 - val_loss: 0.8128\n",
      "Epoch 19/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6988 - val_loss: 0.8134\n",
      "Epoch 20/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6998 - val_loss: 0.8050\n",
      "Epoch 21/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6963 - val_loss: 0.8048\n",
      "Epoch 22/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6936 - val_loss: 0.8167\n",
      "Epoch 23/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6921 - val_loss: 0.8230\n",
      "Epoch 24/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6931 - val_loss: 0.8407\n",
      "Epoch 25/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6917 - val_loss: 0.8155\n",
      "Epoch 26/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6892 - val_loss: 0.8277\n",
      "Epoch 27/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6884 - val_loss: 0.8084\n",
      "Epoch 28/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6872 - val_loss: 0.8014\n",
      "Epoch 29/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6895 - val_loss: 0.8216\n",
      "Epoch 30/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6898 - val_loss: 0.8066\n",
      "Epoch 31/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6869 - val_loss: 0.8142\n",
      "Epoch 32/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6854 - val_loss: 0.8306\n",
      "Epoch 33/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6872 - val_loss: 0.8144\n",
      "Epoch 34/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6873 - val_loss: 0.8141\n",
      "Epoch 35/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6850 - val_loss: 0.7885\n",
      "Epoch 36/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6858 - val_loss: 0.8006\n",
      "Epoch 37/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6833 - val_loss: 0.8052\n",
      "Epoch 38/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6840 - val_loss: 0.7811\n",
      "Epoch 39/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6831 - val_loss: 0.7902\n",
      "Epoch 40/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6834 - val_loss: 0.7925\n",
      "Epoch 41/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6824 - val_loss: 0.8043\n",
      "Epoch 42/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6826 - val_loss: 0.7941\n",
      "Epoch 43/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6832 - val_loss: 0.7890\n",
      "Epoch 44/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6828 - val_loss: 0.7945\n",
      "Epoch 45/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6813 - val_loss: 0.7952\n",
      "Epoch 46/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6813 - val_loss: 0.8124\n",
      "Epoch 47/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6794 - val_loss: 0.7988\n",
      "Epoch 48/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6820 - val_loss: 0.7921\n",
      "Epoch 49/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6806 - val_loss: 0.7930\n",
      "Epoch 50/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6828 - val_loss: 0.8182\n",
      "Epoch 51/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6817 - val_loss: 0.8016\n",
      "Epoch 52/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6812 - val_loss: 0.7970\n",
      "Epoch 53/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6798 - val_loss: 0.7986\n",
      "Epoch 54/300\n",
      "229/229 [==============================] - 0s 452us/step - loss: 0.6795 - val_loss: 0.8098\n",
      "Epoch 55/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6795 - val_loss: 0.7857\n",
      "Epoch 56/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6809 - val_loss: 0.7914\n",
      "Epoch 57/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6775 - val_loss: 0.8047\n",
      "Epoch 58/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6777 - val_loss: 0.7927\n",
      "Epoch 59/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6802 - val_loss: 0.7949\n",
      "Epoch 60/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6780 - val_loss: 0.8267\n",
      "Epoch 61/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6812 - val_loss: 0.7966\n",
      "Epoch 62/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6801 - val_loss: 0.8093\n",
      "Epoch 63/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6788 - val_loss: 0.8047\n",
      "Epoch 64/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6815 - val_loss: 0.7950\n",
      "Epoch 65/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6758 - val_loss: 0.7957\n",
      "Epoch 66/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6764 - val_loss: 0.8142\n",
      "Epoch 67/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6778 - val_loss: 0.7819\n",
      "Epoch 68/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6773 - val_loss: 0.7949\n",
      "Epoch 69/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6745 - val_loss: 0.7914\n",
      "Epoch 70/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6768 - val_loss: 0.7857\n",
      "Epoch 71/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6766 - val_loss: 0.7859\n",
      "Epoch 72/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6786 - val_loss: 0.8007\n",
      "Epoch 73/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6803 - val_loss: 0.7803\n",
      "Epoch 74/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6779 - val_loss: 0.8040\n",
      "Epoch 75/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6780 - val_loss: 0.7977\n",
      "Epoch 76/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6762 - val_loss: 0.7965\n",
      "Epoch 77/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6767 - val_loss: 0.7969\n",
      "Epoch 78/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6766 - val_loss: 0.8064\n",
      "Epoch 79/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6768 - val_loss: 0.7968\n",
      "Epoch 80/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6762 - val_loss: 0.7860\n",
      "Epoch 81/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6752 - val_loss: 0.8263\n",
      "Epoch 82/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6767 - val_loss: 0.8021\n",
      "Epoch 83/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6730 - val_loss: 0.8029\n",
      "Epoch 84/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6771 - val_loss: 0.7889\n",
      "Epoch 85/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6751 - val_loss: 0.7827\n",
      "Epoch 86/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6761 - val_loss: 0.7891\n",
      "Epoch 87/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6766 - val_loss: 0.7791\n",
      "Epoch 88/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6750 - val_loss: 0.7926\n",
      "Epoch 89/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6750 - val_loss: 0.8472\n",
      "Epoch 90/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6757 - val_loss: 0.7928\n",
      "Epoch 91/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6749 - val_loss: 0.8153\n",
      "Epoch 92/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6761 - val_loss: 0.7947\n",
      "Epoch 93/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6774 - val_loss: 0.8001\n",
      "Epoch 94/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6748 - val_loss: 0.7981\n",
      "Epoch 95/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6720 - val_loss: 0.8103\n",
      "Epoch 96/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6756 - val_loss: 0.8019\n",
      "Epoch 97/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6759 - val_loss: 0.7921\n",
      "Epoch 98/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6768 - val_loss: 0.7915\n",
      "Epoch 99/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6758 - val_loss: 0.7876\n",
      "Epoch 100/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6764 - val_loss: 0.7987\n",
      "Epoch 101/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6763 - val_loss: 0.7937\n",
      "Epoch 102/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6746 - val_loss: 0.7976\n",
      "Epoch 103/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6753 - val_loss: 0.7984\n",
      "Epoch 104/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6745 - val_loss: 0.8017\n",
      "Epoch 105/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6743 - val_loss: 0.7953\n",
      "Epoch 106/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6735 - val_loss: 0.7833\n",
      "Epoch 107/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6768 - val_loss: 0.7830\n",
      "Epoch 108/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6736 - val_loss: 0.8090\n",
      "Epoch 109/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6751 - val_loss: 0.8049\n",
      "Epoch 110/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6731 - val_loss: 0.7957\n",
      "Epoch 111/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6734 - val_loss: 0.8094\n",
      "Epoch 112/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6753 - val_loss: 0.7931\n",
      "Epoch 113/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6748 - val_loss: 0.7844\n",
      "Epoch 114/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6732 - val_loss: 0.7971\n",
      "Epoch 115/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6736 - val_loss: 0.7955\n",
      "Epoch 116/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6738 - val_loss: 0.7945\n",
      "Epoch 117/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6725 - val_loss: 0.7998\n",
      "Epoch 118/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6747 - val_loss: 0.7737\n",
      "Epoch 119/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6728 - val_loss: 0.8012\n",
      "Epoch 120/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6736 - val_loss: 0.7871\n",
      "Epoch 121/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6741 - val_loss: 0.7964\n",
      "Epoch 122/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6707 - val_loss: 0.8097\n",
      "Epoch 123/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6751 - val_loss: 0.8268\n",
      "Epoch 124/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6739 - val_loss: 0.8027\n",
      "Epoch 125/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6720 - val_loss: 0.8136\n",
      "Epoch 126/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6739 - val_loss: 0.7848\n",
      "Epoch 127/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6719 - val_loss: 0.8073\n",
      "Epoch 128/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6736 - val_loss: 0.7734\n",
      "Epoch 129/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6744 - val_loss: 0.7885\n",
      "Epoch 130/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6727 - val_loss: 0.8159\n",
      "Epoch 131/300\n",
      "229/229 [==============================] - 0s 455us/step - loss: 0.6729 - val_loss: 0.7939\n",
      "Epoch 132/300\n",
      "229/229 [==============================] - 0s 511us/step - loss: 0.6718 - val_loss: 0.7804\n",
      "Epoch 133/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6744 - val_loss: 0.7771\n",
      "Epoch 134/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6750 - val_loss: 0.7816\n",
      "Epoch 135/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6725 - val_loss: 0.7826\n",
      "Epoch 136/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6754 - val_loss: 0.7805\n",
      "Epoch 137/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6748 - val_loss: 0.7768\n",
      "Epoch 138/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6711 - val_loss: 0.8006\n",
      "Epoch 139/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6745 - val_loss: 0.7870\n",
      "Epoch 140/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6721 - val_loss: 0.8054\n",
      "Epoch 141/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6728 - val_loss: 0.7916\n",
      "Epoch 142/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6725 - val_loss: 0.7927\n",
      "Epoch 143/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6717 - val_loss: 0.8003\n",
      "Epoch 144/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6719 - val_loss: 0.8003\n",
      "Epoch 145/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6744 - val_loss: 0.7929\n",
      "Epoch 146/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6746 - val_loss: 0.7967\n",
      "Epoch 147/300\n",
      "229/229 [==============================] - 0s 456us/step - loss: 0.6724 - val_loss: 0.7977\n",
      "Epoch 148/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6743 - val_loss: 0.7975\n",
      "Epoch 149/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6728 - val_loss: 0.7878\n",
      "Epoch 150/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6719 - val_loss: 0.7851\n",
      "Epoch 151/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6722 - val_loss: 0.8036\n",
      "Epoch 152/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6729 - val_loss: 0.7922\n",
      "Epoch 153/300\n",
      "229/229 [==============================] - 0s 443us/step - loss: 0.6736 - val_loss: 0.7961\n",
      "Epoch 154/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6728 - val_loss: 0.7895\n",
      "Epoch 155/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6745 - val_loss: 0.8076\n",
      "Epoch 156/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6735 - val_loss: 0.8081\n",
      "Epoch 157/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6734 - val_loss: 0.7789\n",
      "Epoch 158/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6724 - val_loss: 0.8053\n",
      "Epoch 159/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6720 - val_loss: 0.7924\n",
      "Epoch 160/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6737 - val_loss: 0.7791\n",
      "Epoch 161/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6738 - val_loss: 0.7733\n",
      "Epoch 162/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6699 - val_loss: 0.7803\n",
      "Epoch 163/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6721 - val_loss: 0.7822\n",
      "Epoch 164/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6721 - val_loss: 0.7841\n",
      "Epoch 165/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6722 - val_loss: 0.7860\n",
      "Epoch 166/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6722 - val_loss: 0.7819\n",
      "Epoch 167/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6740 - val_loss: 0.7866\n",
      "Epoch 168/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6725 - val_loss: 0.7887\n",
      "Epoch 169/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6725 - val_loss: 0.7911\n",
      "Epoch 170/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6714 - val_loss: 0.8003\n",
      "Epoch 171/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6702 - val_loss: 0.7924\n",
      "Epoch 172/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6718 - val_loss: 0.7896\n",
      "Epoch 173/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6718 - val_loss: 0.8045\n",
      "Epoch 174/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6705 - val_loss: 0.8133\n",
      "Epoch 175/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6715 - val_loss: 0.8071\n",
      "Epoch 176/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6728 - val_loss: 0.8071\n",
      "Epoch 177/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6721 - val_loss: 0.7963\n",
      "Epoch 178/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6721 - val_loss: 0.7703\n",
      "Epoch 179/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6728 - val_loss: 0.7899\n",
      "Epoch 180/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6700 - val_loss: 0.7970\n",
      "Epoch 181/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6724 - val_loss: 0.8078\n",
      "Epoch 182/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6723 - val_loss: 0.8067\n",
      "Epoch 183/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6710 - val_loss: 0.8104\n",
      "Epoch 184/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6713 - val_loss: 0.7904\n",
      "Epoch 185/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6707 - val_loss: 0.8009\n",
      "Epoch 186/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6721 - val_loss: 0.7666\n",
      "Epoch 187/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6725 - val_loss: 0.7704\n",
      "Epoch 188/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6715 - val_loss: 0.8046\n",
      "Epoch 189/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6712 - val_loss: 0.8149\n",
      "Epoch 190/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6729 - val_loss: 0.8260\n",
      "Epoch 191/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6721 - val_loss: 0.7906\n",
      "Epoch 192/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6711 - val_loss: 0.8031\n",
      "Epoch 193/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6716 - val_loss: 0.7937\n",
      "Epoch 194/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6708 - val_loss: 0.7757\n",
      "Epoch 195/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6725 - val_loss: 0.8044\n",
      "Epoch 196/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6733 - val_loss: 0.7774\n",
      "Epoch 197/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6695 - val_loss: 0.7776\n",
      "Epoch 198/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6729 - val_loss: 0.7959\n",
      "Epoch 199/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6726 - val_loss: 0.8223\n",
      "Epoch 200/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6710 - val_loss: 0.7845\n",
      "Epoch 201/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6720 - val_loss: 0.8072\n",
      "Epoch 202/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6725 - val_loss: 0.7986\n",
      "Epoch 203/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6697 - val_loss: 0.7963\n",
      "Epoch 204/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6713 - val_loss: 0.7799\n",
      "Epoch 205/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6709 - val_loss: 0.7871\n",
      "Epoch 206/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6724 - val_loss: 0.7924\n",
      "Epoch 207/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6698 - val_loss: 0.7897\n",
      "Epoch 208/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6719 - val_loss: 0.7820\n",
      "Epoch 209/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6721 - val_loss: 0.7758\n",
      "Epoch 210/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6713 - val_loss: 0.7956\n",
      "Epoch 211/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6711 - val_loss: 0.8064\n",
      "Epoch 212/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6710 - val_loss: 0.7759\n",
      "Epoch 213/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6720 - val_loss: 0.8037\n",
      "Epoch 214/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6692 - val_loss: 0.7895\n",
      "Epoch 215/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6728 - val_loss: 0.7749\n",
      "Epoch 216/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6716 - val_loss: 0.8075\n",
      "Epoch 217/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6721 - val_loss: 0.7874\n",
      "Epoch 218/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6706 - val_loss: 0.8050\n",
      "Epoch 219/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6697 - val_loss: 0.8085\n",
      "Epoch 220/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6709 - val_loss: 0.7740\n",
      "Epoch 221/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6716 - val_loss: 0.8043\n",
      "Epoch 222/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6723 - val_loss: 0.7967\n",
      "Epoch 223/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6708 - val_loss: 0.7870\n",
      "Epoch 224/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6721 - val_loss: 0.7885\n",
      "Epoch 225/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6705 - val_loss: 0.7861\n",
      "Epoch 226/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6706 - val_loss: 0.7813\n",
      "Epoch 227/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6708 - val_loss: 0.8140\n",
      "Epoch 228/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6722 - val_loss: 0.7897\n",
      "Epoch 229/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6709 - val_loss: 0.8062\n",
      "Epoch 230/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6717 - val_loss: 0.8050\n",
      "Epoch 231/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6691 - val_loss: 0.7845\n",
      "Epoch 232/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6754 - val_loss: 0.7825\n",
      "Epoch 233/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6712 - val_loss: 0.7906\n",
      "Epoch 234/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6713 - val_loss: 0.8011\n",
      "Epoch 235/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6715 - val_loss: 0.7771\n",
      "Epoch 236/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6692 - val_loss: 0.8223\n",
      "Epoch 237/300\n",
      "229/229 [==============================] - 0s 564us/step - loss: 0.6718 - val_loss: 0.8168\n",
      "Epoch 238/300\n",
      "229/229 [==============================] - 0s 548us/step - loss: 0.6708 - val_loss: 0.8041\n",
      "Epoch 239/300\n",
      "229/229 [==============================] - 0s 539us/step - loss: 0.6718 - val_loss: 0.7856\n",
      "Epoch 240/300\n",
      "229/229 [==============================] - 0s 1ms/step - loss: 0.6723 - val_loss: 0.7723\n",
      "Epoch 241/300\n",
      "229/229 [==============================] - 0s 588us/step - loss: 0.6711 - val_loss: 0.7907\n",
      "Epoch 242/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6713 - val_loss: 0.7966\n",
      "Epoch 243/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6724 - val_loss: 0.7751\n",
      "Epoch 244/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6711 - val_loss: 0.7866\n",
      "Epoch 245/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6694 - val_loss: 0.7898\n",
      "Epoch 246/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6732 - val_loss: 0.7980\n",
      "Epoch 247/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6735 - val_loss: 0.7818\n",
      "Epoch 248/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6694 - val_loss: 0.7679\n",
      "Epoch 249/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6707 - val_loss: 0.7972\n",
      "Epoch 250/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6704 - val_loss: 0.7804\n",
      "Epoch 251/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6706 - val_loss: 0.7988\n",
      "Epoch 252/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6715 - val_loss: 0.7850\n",
      "Epoch 253/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6711 - val_loss: 0.7883\n",
      "Epoch 254/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6688 - val_loss: 0.8015\n",
      "Epoch 255/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6701 - val_loss: 0.7905\n",
      "Epoch 256/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6729 - val_loss: 0.7938\n",
      "Epoch 257/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6720 - val_loss: 0.7806\n",
      "Epoch 258/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6713 - val_loss: 0.7967\n",
      "Epoch 259/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6723 - val_loss: 0.7739\n",
      "Epoch 260/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6707 - val_loss: 0.7744\n",
      "Epoch 261/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6723 - val_loss: 0.7795\n",
      "Epoch 262/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6695 - val_loss: 0.7978\n",
      "Epoch 263/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6707 - val_loss: 0.7883\n",
      "Epoch 264/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6699 - val_loss: 0.7789\n",
      "Epoch 265/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6713 - val_loss: 0.8007\n",
      "Epoch 266/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6694 - val_loss: 0.7932\n",
      "Epoch 267/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6704 - val_loss: 0.8050\n",
      "Epoch 268/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6709 - val_loss: 0.8037\n",
      "Epoch 269/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6706 - val_loss: 0.7937\n",
      "Epoch 270/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6699 - val_loss: 0.7831\n",
      "Epoch 271/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6713 - val_loss: 0.7842\n",
      "Epoch 272/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6697 - val_loss: 0.8287\n",
      "Epoch 273/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6703 - val_loss: 0.7819\n",
      "Epoch 274/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6689 - val_loss: 0.7994\n",
      "Epoch 275/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6726 - val_loss: 0.8049\n",
      "Epoch 276/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6715 - val_loss: 0.7831\n",
      "Epoch 277/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6696 - val_loss: 0.7973\n",
      "Epoch 278/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6724 - val_loss: 0.7721\n",
      "Epoch 279/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6701 - val_loss: 0.7966\n",
      "Epoch 280/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6709 - val_loss: 0.7808\n",
      "Epoch 281/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6720 - val_loss: 0.7922\n",
      "Epoch 282/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6706 - val_loss: 0.7853\n",
      "Epoch 283/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6700 - val_loss: 0.7822\n",
      "Epoch 284/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6681 - val_loss: 0.7929\n",
      "Epoch 285/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6711 - val_loss: 0.8260\n",
      "Epoch 286/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6696 - val_loss: 0.8019\n",
      "Epoch 287/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6712 - val_loss: 0.7873\n",
      "Epoch 288/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6718 - val_loss: 0.7883\n",
      "Epoch 289/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6703 - val_loss: 0.7805\n",
      "Epoch 290/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6730 - val_loss: 0.7940\n",
      "Epoch 291/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6672 - val_loss: 0.7796\n",
      "Epoch 292/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6714 - val_loss: 0.8332\n",
      "Epoch 293/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6702 - val_loss: 0.7987\n",
      "Epoch 294/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6705 - val_loss: 0.8153\n",
      "Epoch 295/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6725 - val_loss: 0.7742\n",
      "Epoch 296/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6689 - val_loss: 0.7919\n",
      "Epoch 297/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6715 - val_loss: 0.8123\n",
      "Epoch 298/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6700 - val_loss: 0.7901\n",
      "Epoch 299/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6693 - val_loss: 0.8129\n",
      "Epoch 300/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6701 - val_loss: 0.8006\n",
      "26/26 [==============================] - 0s 350us/step\n",
      "Epoch 1/300\n",
      "229/229 [==============================] - 0s 630us/step - loss: 1.4285 - val_loss: 1.1063\n",
      "Epoch 2/300\n",
      "229/229 [==============================] - 0s 682us/step - loss: 1.0045 - val_loss: 0.9608\n",
      "Epoch 3/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.8928 - val_loss: 0.8738\n",
      "Epoch 4/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.8383 - val_loss: 0.8497\n",
      "Epoch 5/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.8027 - val_loss: 0.8317\n",
      "Epoch 6/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7826 - val_loss: 0.8437\n",
      "Epoch 7/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7695 - val_loss: 0.7997\n",
      "Epoch 8/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7543 - val_loss: 0.7990\n",
      "Epoch 9/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7468 - val_loss: 0.7812\n",
      "Epoch 10/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7375 - val_loss: 0.7875\n",
      "Epoch 11/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.7302 - val_loss: 0.7795\n",
      "Epoch 12/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.7272 - val_loss: 0.7673\n",
      "Epoch 13/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7220 - val_loss: 0.7628\n",
      "Epoch 14/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.7185 - val_loss: 0.7720\n",
      "Epoch 15/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.7169 - val_loss: 0.7637\n",
      "Epoch 16/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7113 - val_loss: 0.7564\n",
      "Epoch 17/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7130 - val_loss: 0.7510\n",
      "Epoch 18/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7070 - val_loss: 0.7634\n",
      "Epoch 19/300\n",
      "229/229 [==============================] - 0s 488us/step - loss: 0.7053 - val_loss: 0.7532\n",
      "Epoch 20/300\n",
      "229/229 [==============================] - 0s 441us/step - loss: 0.7043 - val_loss: 0.7614\n",
      "Epoch 21/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7006 - val_loss: 0.7703\n",
      "Epoch 22/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7023 - val_loss: 0.7449\n",
      "Epoch 23/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.7011 - val_loss: 0.7553\n",
      "Epoch 24/300\n",
      "229/229 [==============================] - 0s 675us/step - loss: 0.6976 - val_loss: 0.7620\n",
      "Epoch 25/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6968 - val_loss: 0.7522\n",
      "Epoch 26/300\n",
      "229/229 [==============================] - 0s 449us/step - loss: 0.6983 - val_loss: 0.7466\n",
      "Epoch 27/300\n",
      "229/229 [==============================] - 0s 483us/step - loss: 0.6967 - val_loss: 0.7446\n",
      "Epoch 28/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6937 - val_loss: 0.7484\n",
      "Epoch 29/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6949 - val_loss: 0.7490\n",
      "Epoch 30/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6957 - val_loss: 0.7412\n",
      "Epoch 31/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6898 - val_loss: 0.7453\n",
      "Epoch 32/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6933 - val_loss: 0.7451\n",
      "Epoch 33/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6905 - val_loss: 0.7440\n",
      "Epoch 34/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6907 - val_loss: 0.7475\n",
      "Epoch 35/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6922 - val_loss: 0.7525\n",
      "Epoch 36/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6907 - val_loss: 0.7645\n",
      "Epoch 37/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6905 - val_loss: 0.7426\n",
      "Epoch 38/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6883 - val_loss: 0.7598\n",
      "Epoch 39/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6902 - val_loss: 0.7602\n",
      "Epoch 40/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6890 - val_loss: 0.7389\n",
      "Epoch 41/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6884 - val_loss: 0.7536\n",
      "Epoch 42/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6884 - val_loss: 0.7972\n",
      "Epoch 43/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6853 - val_loss: 0.7564\n",
      "Epoch 44/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6897 - val_loss: 0.7452\n",
      "Epoch 45/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6869 - val_loss: 0.7683\n",
      "Epoch 46/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6883 - val_loss: 0.7427\n",
      "Epoch 47/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6858 - val_loss: 0.7481\n",
      "Epoch 48/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6861 - val_loss: 0.7453\n",
      "Epoch 49/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6875 - val_loss: 0.7611\n",
      "Epoch 50/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6839 - val_loss: 0.7727\n",
      "Epoch 51/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6886 - val_loss: 0.7466\n",
      "Epoch 52/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6838 - val_loss: 0.7626\n",
      "Epoch 53/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6856 - val_loss: 0.7671\n",
      "Epoch 54/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6857 - val_loss: 0.7497\n",
      "Epoch 55/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6838 - val_loss: 0.7559\n",
      "Epoch 56/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6864 - val_loss: 0.7461\n",
      "Epoch 57/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6857 - val_loss: 0.7665\n",
      "Epoch 58/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6866 - val_loss: 0.7462\n",
      "Epoch 59/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6852 - val_loss: 0.7514\n",
      "Epoch 60/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6849 - val_loss: 0.7621\n",
      "Epoch 61/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6847 - val_loss: 0.7419\n",
      "Epoch 62/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6825 - val_loss: 0.7600\n",
      "Epoch 63/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6824 - val_loss: 0.7625\n",
      "Epoch 64/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6840 - val_loss: 0.7505\n",
      "Epoch 65/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6837 - val_loss: 0.7577\n",
      "Epoch 66/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6833 - val_loss: 0.8148\n",
      "Epoch 67/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6822 - val_loss: 0.7474\n",
      "Epoch 68/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6844 - val_loss: 0.7590\n",
      "Epoch 69/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6827 - val_loss: 0.7540\n",
      "Epoch 70/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6826 - val_loss: 0.7396\n",
      "Epoch 71/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6810 - val_loss: 0.7676\n",
      "Epoch 72/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6830 - val_loss: 0.7577\n",
      "Epoch 73/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6840 - val_loss: 0.7414\n",
      "Epoch 74/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6829 - val_loss: 0.7550\n",
      "Epoch 75/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6803 - val_loss: 0.7581\n",
      "Epoch 76/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6797 - val_loss: 0.7776\n",
      "Epoch 77/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6822 - val_loss: 0.7437\n",
      "Epoch 78/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6804 - val_loss: 0.8144\n",
      "Epoch 79/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6846 - val_loss: 0.7516\n",
      "Epoch 80/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6818 - val_loss: 0.7403\n",
      "Epoch 81/300\n",
      "229/229 [==============================] - 0s 404us/step - loss: 0.6822 - val_loss: 0.7568\n",
      "Epoch 82/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6814 - val_loss: 0.7487\n",
      "Epoch 83/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6816 - val_loss: 0.7569\n",
      "Epoch 84/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6821 - val_loss: 0.7394\n",
      "Epoch 85/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6787 - val_loss: 0.7629\n",
      "Epoch 86/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6805 - val_loss: 0.7564\n",
      "Epoch 87/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6812 - val_loss: 0.7471\n",
      "Epoch 88/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6803 - val_loss: 0.7572\n",
      "Epoch 89/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6810 - val_loss: 0.7672\n",
      "Epoch 90/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6809 - val_loss: 0.7498\n",
      "Epoch 91/300\n",
      "229/229 [==============================] - 0s 783us/step - loss: 0.6823 - val_loss: 0.7491\n",
      "Epoch 92/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6800 - val_loss: 0.7458\n",
      "Epoch 93/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6821 - val_loss: 0.7435\n",
      "Epoch 94/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6811 - val_loss: 0.7530\n",
      "Epoch 95/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6809 - val_loss: 0.8158\n",
      "Epoch 96/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6799 - val_loss: 0.7604\n",
      "Epoch 97/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6803 - val_loss: 0.7453\n",
      "Epoch 98/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6791 - val_loss: 0.7549\n",
      "Epoch 99/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6774 - val_loss: 0.7571\n",
      "Epoch 100/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6796 - val_loss: 0.7716\n",
      "Epoch 101/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6802 - val_loss: 0.7500\n",
      "Epoch 102/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6790 - val_loss: 0.7480\n",
      "Epoch 103/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6772 - val_loss: 0.7640\n",
      "Epoch 104/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6788 - val_loss: 0.7588\n",
      "Epoch 105/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6797 - val_loss: 0.7509\n",
      "Epoch 106/300\n",
      "229/229 [==============================] - 0s 470us/step - loss: 0.6792 - val_loss: 0.7443\n",
      "Epoch 107/300\n",
      "229/229 [==============================] - 0s 494us/step - loss: 0.6796 - val_loss: 0.7483\n",
      "Epoch 108/300\n",
      "229/229 [==============================] - 0s 445us/step - loss: 0.6797 - val_loss: 0.7427\n",
      "Epoch 109/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6801 - val_loss: 0.7579\n",
      "Epoch 110/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6775 - val_loss: 0.7419\n",
      "Epoch 111/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6783 - val_loss: 0.7524\n",
      "Epoch 112/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6790 - val_loss: 0.7513\n",
      "Epoch 113/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6789 - val_loss: 0.7557\n",
      "Epoch 114/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6782 - val_loss: 0.7778\n",
      "Epoch 115/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6797 - val_loss: 0.7547\n",
      "Epoch 116/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6778 - val_loss: 0.7640\n",
      "Epoch 117/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6791 - val_loss: 0.7472\n",
      "Epoch 118/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6781 - val_loss: 0.7409\n",
      "Epoch 119/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6799 - val_loss: 0.7464\n",
      "Epoch 120/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6769 - val_loss: 0.7337\n",
      "Epoch 121/300\n",
      "229/229 [==============================] - 0s 441us/step - loss: 0.6774 - val_loss: 0.7425\n",
      "Epoch 122/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6768 - val_loss: 0.7531\n",
      "Epoch 123/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6776 - val_loss: 0.7532\n",
      "Epoch 124/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6783 - val_loss: 0.7520\n",
      "Epoch 125/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6806 - val_loss: 0.7599\n",
      "Epoch 126/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6767 - val_loss: 0.7581\n",
      "Epoch 127/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6776 - val_loss: 0.7524\n",
      "Epoch 128/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6816 - val_loss: 0.7436\n",
      "Epoch 129/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6781 - val_loss: 0.7384\n",
      "Epoch 130/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6767 - val_loss: 0.7734\n",
      "Epoch 131/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6772 - val_loss: 0.7407\n",
      "Epoch 132/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6785 - val_loss: 0.7664\n",
      "Epoch 133/300\n",
      "229/229 [==============================] - 0s 456us/step - loss: 0.6781 - val_loss: 0.7589\n",
      "Epoch 134/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6791 - val_loss: 0.7418\n",
      "Epoch 135/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6788 - val_loss: 0.7689\n",
      "Epoch 136/300\n",
      "229/229 [==============================] - 0s 444us/step - loss: 0.6768 - val_loss: 0.7634\n",
      "Epoch 137/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6769 - val_loss: 0.7573\n",
      "Epoch 138/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6764 - val_loss: 0.7545\n",
      "Epoch 139/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6762 - val_loss: 0.7489\n",
      "Epoch 140/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6772 - val_loss: 0.7658\n",
      "Epoch 141/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6767 - val_loss: 0.7538\n",
      "Epoch 142/300\n",
      "229/229 [==============================] - 0s 458us/step - loss: 0.6778 - val_loss: 0.7636\n",
      "Epoch 143/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6781 - val_loss: 0.7624\n",
      "Epoch 144/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6765 - val_loss: 0.7448\n",
      "Epoch 145/300\n",
      "229/229 [==============================] - 0s 446us/step - loss: 0.6788 - val_loss: 0.7453\n",
      "Epoch 146/300\n",
      "229/229 [==============================] - 0s 443us/step - loss: 0.6785 - val_loss: 0.7484\n",
      "Epoch 147/300\n",
      "229/229 [==============================] - 0s 448us/step - loss: 0.6781 - val_loss: 0.7616\n",
      "Epoch 148/300\n",
      "229/229 [==============================] - 0s 443us/step - loss: 0.6774 - val_loss: 0.7578\n",
      "Epoch 149/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6768 - val_loss: 0.7496\n",
      "Epoch 150/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6757 - val_loss: 0.7605\n",
      "Epoch 151/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6775 - val_loss: 0.7513\n",
      "Epoch 152/300\n",
      "229/229 [==============================] - 0s 444us/step - loss: 0.6761 - val_loss: 0.7435\n",
      "Epoch 153/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6778 - val_loss: 0.7464\n",
      "Epoch 154/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6783 - val_loss: 0.7545\n",
      "Epoch 155/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6772 - val_loss: 0.7501\n",
      "Epoch 156/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6759 - val_loss: 0.7535\n",
      "Epoch 157/300\n",
      "229/229 [==============================] - 0s 441us/step - loss: 0.6783 - val_loss: 0.7572\n",
      "Epoch 158/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6769 - val_loss: 0.7415\n",
      "Epoch 159/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6770 - val_loss: 0.7458\n",
      "Epoch 160/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6780 - val_loss: 0.7490\n",
      "Epoch 161/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6774 - val_loss: 0.7449\n",
      "Epoch 162/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6784 - val_loss: 0.7756\n",
      "Epoch 163/300\n",
      "229/229 [==============================] - 0s 475us/step - loss: 0.6781 - val_loss: 0.7744\n",
      "Epoch 164/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6762 - val_loss: 0.7644\n",
      "Epoch 165/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6768 - val_loss: 0.7559\n",
      "Epoch 166/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6791 - val_loss: 0.7703\n",
      "Epoch 167/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6759 - val_loss: 0.7793\n",
      "Epoch 168/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6769 - val_loss: 0.7402\n",
      "Epoch 169/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6775 - val_loss: 0.7505\n",
      "Epoch 170/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6774 - val_loss: 0.7510\n",
      "Epoch 171/300\n",
      "229/229 [==============================] - 0s 441us/step - loss: 0.6766 - val_loss: 0.7460\n",
      "Epoch 172/300\n",
      "229/229 [==============================] - 0s 445us/step - loss: 0.6763 - val_loss: 0.7428\n",
      "Epoch 173/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6767 - val_loss: 0.7393\n",
      "Epoch 174/300\n",
      "229/229 [==============================] - 0s 446us/step - loss: 0.6727 - val_loss: 0.7586\n",
      "Epoch 175/300\n",
      "229/229 [==============================] - 0s 449us/step - loss: 0.6762 - val_loss: 0.7608\n",
      "Epoch 176/300\n",
      "229/229 [==============================] - 0s 449us/step - loss: 0.6761 - val_loss: 0.7561\n",
      "Epoch 177/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6776 - val_loss: 0.7839\n",
      "Epoch 178/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6782 - val_loss: 0.7516\n",
      "Epoch 179/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6781 - val_loss: 0.7652\n",
      "Epoch 180/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6770 - val_loss: 0.7552\n",
      "Epoch 181/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6764 - val_loss: 0.7569\n",
      "Epoch 182/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6763 - val_loss: 0.7526\n",
      "Epoch 183/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6760 - val_loss: 0.7517\n",
      "Epoch 184/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6755 - val_loss: 0.7828\n",
      "Epoch 185/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6756 - val_loss: 0.7802\n",
      "Epoch 186/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6758 - val_loss: 0.7544\n",
      "Epoch 187/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6764 - val_loss: 0.7468\n",
      "Epoch 188/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6776 - val_loss: 0.7638\n",
      "Epoch 189/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6750 - val_loss: 0.7625\n",
      "Epoch 190/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6761 - val_loss: 0.7527\n",
      "Epoch 191/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6760 - val_loss: 0.7648\n",
      "Epoch 192/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6792 - val_loss: 0.7559\n",
      "Epoch 193/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6770 - val_loss: 0.7462\n",
      "Epoch 194/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6762 - val_loss: 0.7412\n",
      "Epoch 195/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6767 - val_loss: 0.7483\n",
      "Epoch 196/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6758 - val_loss: 0.7557\n",
      "Epoch 197/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6762 - val_loss: 0.7611\n",
      "Epoch 198/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6757 - val_loss: 0.7606\n",
      "Epoch 199/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6757 - val_loss: 0.8060\n",
      "Epoch 200/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6784 - val_loss: 0.7427\n",
      "Epoch 201/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6781 - val_loss: 0.7586\n",
      "Epoch 202/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6767 - val_loss: 0.7638\n",
      "Epoch 203/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6754 - val_loss: 0.7623\n",
      "Epoch 204/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6747 - val_loss: 0.7598\n",
      "Epoch 205/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6754 - val_loss: 0.7577\n",
      "Epoch 206/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6781 - val_loss: 0.7502\n",
      "Epoch 207/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6762 - val_loss: 0.8512\n",
      "Epoch 208/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6764 - val_loss: 0.7619\n",
      "Epoch 209/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6766 - val_loss: 0.7460\n",
      "Epoch 210/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6769 - val_loss: 0.7555\n",
      "Epoch 211/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6765 - val_loss: 0.7488\n",
      "Epoch 212/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6775 - val_loss: 0.7534\n",
      "Epoch 213/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6770 - val_loss: 0.7549\n",
      "Epoch 214/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6759 - val_loss: 0.7623\n",
      "Epoch 215/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6748 - val_loss: 0.7332\n",
      "Epoch 216/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6764 - val_loss: 0.7683\n",
      "Epoch 217/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6767 - val_loss: 0.7528\n",
      "Epoch 218/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6760 - val_loss: 0.7487\n",
      "Epoch 219/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6750 - val_loss: 0.7480\n",
      "Epoch 220/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6746 - val_loss: 0.7460\n",
      "Epoch 221/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6767 - val_loss: 0.7654\n",
      "Epoch 222/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6756 - val_loss: 0.7632\n",
      "Epoch 223/300\n",
      "229/229 [==============================] - 0s 565us/step - loss: 0.6779 - val_loss: 0.7526\n",
      "Epoch 224/300\n",
      "229/229 [==============================] - 0s 529us/step - loss: 0.6743 - val_loss: 0.7590\n",
      "Epoch 225/300\n",
      "229/229 [==============================] - 0s 535us/step - loss: 0.6758 - val_loss: 0.7589\n",
      "Epoch 226/300\n",
      "229/229 [==============================] - 0s 1ms/step - loss: 0.6751 - val_loss: 0.7594\n",
      "Epoch 227/300\n",
      "229/229 [==============================] - 0s 494us/step - loss: 0.6755 - val_loss: 0.7638\n",
      "Epoch 228/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6795 - val_loss: 0.7479\n",
      "Epoch 229/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6770 - val_loss: 0.7508\n",
      "Epoch 230/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6761 - val_loss: 0.7450\n",
      "Epoch 231/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6758 - val_loss: 0.7645\n",
      "Epoch 232/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6769 - val_loss: 0.7684\n",
      "Epoch 233/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6761 - val_loss: 0.7403\n",
      "Epoch 234/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6761 - val_loss: 0.7581\n",
      "Epoch 235/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6778 - val_loss: 0.7566\n",
      "Epoch 236/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6755 - val_loss: 0.7550\n",
      "Epoch 237/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6745 - val_loss: 0.7661\n",
      "Epoch 238/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6769 - val_loss: 0.7417\n",
      "Epoch 239/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6747 - val_loss: 0.7543\n",
      "Epoch 240/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6769 - val_loss: 0.7490\n",
      "Epoch 241/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6759 - val_loss: 0.7492\n",
      "Epoch 242/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6741 - val_loss: 0.7536\n",
      "Epoch 243/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6768 - val_loss: 0.7403\n",
      "Epoch 244/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6756 - val_loss: 0.7643\n",
      "Epoch 245/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6764 - val_loss: 0.7414\n",
      "Epoch 246/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6750 - val_loss: 0.7485\n",
      "Epoch 247/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6767 - val_loss: 0.7595\n",
      "Epoch 248/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6773 - val_loss: 0.7951\n",
      "Epoch 249/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6752 - val_loss: 0.7517\n",
      "Epoch 250/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6752 - val_loss: 0.7489\n",
      "Epoch 251/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6762 - val_loss: 0.7464\n",
      "Epoch 252/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6764 - val_loss: 0.7526\n",
      "Epoch 253/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6755 - val_loss: 0.7505\n",
      "Epoch 254/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6741 - val_loss: 0.7531\n",
      "Epoch 255/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6770 - val_loss: 0.7593\n",
      "Epoch 256/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6761 - val_loss: 0.7477\n",
      "Epoch 257/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6775 - val_loss: 0.7575\n",
      "Epoch 258/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6763 - val_loss: 0.7476\n",
      "Epoch 259/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6768 - val_loss: 0.7399\n",
      "Epoch 260/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6771 - val_loss: 0.7422\n",
      "Epoch 261/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6762 - val_loss: 0.7536\n",
      "Epoch 262/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6769 - val_loss: 0.7538\n",
      "Epoch 263/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6761 - val_loss: 0.7547\n",
      "Epoch 264/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6754 - val_loss: 0.7684\n",
      "Epoch 265/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6739 - val_loss: 0.7461\n",
      "Epoch 266/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6750 - val_loss: 0.7608\n",
      "Epoch 267/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6779 - val_loss: 0.7493\n",
      "Epoch 268/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6762 - val_loss: 0.7511\n",
      "Epoch 269/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6752 - val_loss: 0.7515\n",
      "Epoch 270/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6762 - val_loss: 0.7598\n",
      "Epoch 271/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6744 - val_loss: 0.7577\n",
      "Epoch 272/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6758 - val_loss: 0.7524\n",
      "Epoch 273/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6763 - val_loss: 0.7527\n",
      "Epoch 274/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6760 - val_loss: 0.7422\n",
      "Epoch 275/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6764 - val_loss: 0.7709\n",
      "Epoch 276/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6770 - val_loss: 0.7590\n",
      "Epoch 277/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6746 - val_loss: 0.7641\n",
      "Epoch 278/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6776 - val_loss: 0.7370\n",
      "Epoch 279/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6763 - val_loss: 0.7553\n",
      "Epoch 280/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6757 - val_loss: 0.7488\n",
      "Epoch 281/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6780 - val_loss: 0.7781\n",
      "Epoch 282/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6745 - val_loss: 0.7524\n",
      "Epoch 283/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6767 - val_loss: 0.7667\n",
      "Epoch 284/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6752 - val_loss: 0.7448\n",
      "Epoch 285/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6752 - val_loss: 0.8266\n",
      "Epoch 286/300\n",
      "229/229 [==============================] - 0s 474us/step - loss: 0.6774 - val_loss: 0.7507\n",
      "Epoch 287/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6771 - val_loss: 0.7377\n",
      "Epoch 288/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6741 - val_loss: 0.7559\n",
      "Epoch 289/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6750 - val_loss: 0.7539\n",
      "Epoch 290/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6768 - val_loss: 0.7574\n",
      "Epoch 291/300\n",
      "229/229 [==============================] - 0s 526us/step - loss: 0.6727 - val_loss: 0.7682\n",
      "Epoch 292/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6774 - val_loss: 0.7489\n",
      "Epoch 293/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6733 - val_loss: 0.7684\n",
      "Epoch 294/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6773 - val_loss: 0.7660\n",
      "Epoch 295/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6754 - val_loss: 0.7661\n",
      "Epoch 296/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6760 - val_loss: 0.7612\n",
      "Epoch 297/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6751 - val_loss: 0.7499\n",
      "Epoch 298/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6738 - val_loss: 0.7782\n",
      "Epoch 299/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6781 - val_loss: 0.7490\n",
      "Epoch 300/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6734 - val_loss: 0.7566\n",
      "26/26 [==============================] - 0s 358us/step\n",
      "Epoch 1/300\n",
      "229/229 [==============================] - 0s 618us/step - loss: 1.5085 - val_loss: 1.1387\n",
      "Epoch 2/300\n",
      "229/229 [==============================] - 0s 444us/step - loss: 1.0086 - val_loss: 0.9445\n",
      "Epoch 3/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.8909 - val_loss: 0.8658\n",
      "Epoch 4/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.8380 - val_loss: 0.8067\n",
      "Epoch 5/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.8061 - val_loss: 0.7823\n",
      "Epoch 6/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.7851 - val_loss: 0.7691\n",
      "Epoch 7/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.7690 - val_loss: 0.7662\n",
      "Epoch 8/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.7599 - val_loss: 0.7378\n",
      "Epoch 9/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7492 - val_loss: 0.7354\n",
      "Epoch 10/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.7442 - val_loss: 0.7270\n",
      "Epoch 11/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.7389 - val_loss: 0.7175\n",
      "Epoch 12/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7313 - val_loss: 0.7338\n",
      "Epoch 13/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7294 - val_loss: 0.7055\n",
      "Epoch 14/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7263 - val_loss: 0.7205\n",
      "Epoch 15/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.7233 - val_loss: 0.7227\n",
      "Epoch 16/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7208 - val_loss: 0.6967\n",
      "Epoch 17/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.7164 - val_loss: 0.7108\n",
      "Epoch 18/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.7156 - val_loss: 0.6989\n",
      "Epoch 19/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.7135 - val_loss: 0.6952\n",
      "Epoch 20/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.7121 - val_loss: 0.6895\n",
      "Epoch 21/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.7076 - val_loss: 0.6903\n",
      "Epoch 22/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.7082 - val_loss: 0.6829\n",
      "Epoch 23/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7074 - val_loss: 0.6848\n",
      "Epoch 24/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.7054 - val_loss: 0.6995\n",
      "Epoch 25/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.7050 - val_loss: 0.6919\n",
      "Epoch 26/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.7040 - val_loss: 0.6970\n",
      "Epoch 27/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7033 - val_loss: 0.6940\n",
      "Epoch 28/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.7025 - val_loss: 0.6946\n",
      "Epoch 29/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7013 - val_loss: 0.7079\n",
      "Epoch 30/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.7003 - val_loss: 0.7057\n",
      "Epoch 31/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6995 - val_loss: 0.6846\n",
      "Epoch 32/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6978 - val_loss: 0.6798\n",
      "Epoch 33/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6990 - val_loss: 0.6763\n",
      "Epoch 34/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6985 - val_loss: 0.6835\n",
      "Epoch 35/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6975 - val_loss: 0.7003\n",
      "Epoch 36/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6971 - val_loss: 0.6897\n",
      "Epoch 37/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6986 - val_loss: 0.6964\n",
      "Epoch 38/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6965 - val_loss: 0.7035\n",
      "Epoch 39/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6963 - val_loss: 0.6844\n",
      "Epoch 40/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6953 - val_loss: 0.6830\n",
      "Epoch 41/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6954 - val_loss: 0.6812\n",
      "Epoch 42/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6963 - val_loss: 0.6858\n",
      "Epoch 43/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6951 - val_loss: 0.6784\n",
      "Epoch 44/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6944 - val_loss: 0.6696\n",
      "Epoch 45/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6937 - val_loss: 0.6762\n",
      "Epoch 46/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6961 - val_loss: 0.6796\n",
      "Epoch 47/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6923 - val_loss: 0.6813\n",
      "Epoch 48/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6923 - val_loss: 0.6973\n",
      "Epoch 49/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6961 - val_loss: 0.6882\n",
      "Epoch 50/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6933 - val_loss: 0.7415\n",
      "Epoch 51/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6921 - val_loss: 0.6762\n",
      "Epoch 52/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6933 - val_loss: 0.7389\n",
      "Epoch 53/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6905 - val_loss: 0.6891\n",
      "Epoch 54/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6907 - val_loss: 0.6804\n",
      "Epoch 55/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6918 - val_loss: 0.7495\n",
      "Epoch 56/300\n",
      "229/229 [==============================] - 0s 470us/step - loss: 0.6921 - val_loss: 0.6902\n",
      "Epoch 57/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6923 - val_loss: 0.6820\n",
      "Epoch 58/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6909 - val_loss: 0.6801\n",
      "Epoch 59/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6928 - val_loss: 0.6766\n",
      "Epoch 60/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6910 - val_loss: 0.6850\n",
      "Epoch 61/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6916 - val_loss: 0.6833\n",
      "Epoch 62/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6911 - val_loss: 0.7014\n",
      "Epoch 63/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6879 - val_loss: 0.6761\n",
      "Epoch 64/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6912 - val_loss: 0.6716\n",
      "Epoch 65/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6899 - val_loss: 0.6916\n",
      "Epoch 66/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6905 - val_loss: 0.6915\n",
      "Epoch 67/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6902 - val_loss: 0.6786\n",
      "Epoch 68/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6901 - val_loss: 0.6913\n",
      "Epoch 69/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6900 - val_loss: 0.6741\n",
      "Epoch 70/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6896 - val_loss: 0.6697\n",
      "Epoch 71/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6904 - val_loss: 0.6757\n",
      "Epoch 72/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6898 - val_loss: 0.7121\n",
      "Epoch 73/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6886 - val_loss: 0.6759\n",
      "Epoch 74/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6880 - val_loss: 0.6874\n",
      "Epoch 75/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6877 - val_loss: 0.6861\n",
      "Epoch 76/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6897 - val_loss: 0.7093\n",
      "Epoch 77/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6879 - val_loss: 0.6874\n",
      "Epoch 78/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6885 - val_loss: 0.6843\n",
      "Epoch 79/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6885 - val_loss: 0.7129\n",
      "Epoch 80/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6884 - val_loss: 0.6710\n",
      "Epoch 81/300\n",
      "229/229 [==============================] - 0s 481us/step - loss: 0.6892 - val_loss: 0.6703\n",
      "Epoch 82/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6860 - val_loss: 0.6857\n",
      "Epoch 83/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6873 - val_loss: 0.6955\n",
      "Epoch 84/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6893 - val_loss: 0.6833\n",
      "Epoch 85/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6847 - val_loss: 0.6899\n",
      "Epoch 86/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6866 - val_loss: 0.6966\n",
      "Epoch 87/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6895 - val_loss: 0.6769\n",
      "Epoch 88/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6889 - val_loss: 0.6916\n",
      "Epoch 89/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6879 - val_loss: 0.6804\n",
      "Epoch 90/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6869 - val_loss: 0.6878\n",
      "Epoch 91/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6879 - val_loss: 0.6641\n",
      "Epoch 92/300\n",
      "229/229 [==============================] - 0s 457us/step - loss: 0.6855 - val_loss: 0.6799\n",
      "Epoch 93/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6865 - val_loss: 0.7017\n",
      "Epoch 94/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6859 - val_loss: 0.6900\n",
      "Epoch 95/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6863 - val_loss: 0.6833\n",
      "Epoch 96/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6880 - val_loss: 0.6750\n",
      "Epoch 97/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6861 - val_loss: 0.6809\n",
      "Epoch 98/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6851 - val_loss: 0.7112\n",
      "Epoch 99/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6857 - val_loss: 0.7067\n",
      "Epoch 100/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6861 - val_loss: 0.7194\n",
      "Epoch 101/300\n",
      "229/229 [==============================] - 0s 448us/step - loss: 0.6869 - val_loss: 0.6994\n",
      "Epoch 102/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6866 - val_loss: 0.6780\n",
      "Epoch 103/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6854 - val_loss: 0.6959\n",
      "Epoch 104/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6885 - val_loss: 0.6850\n",
      "Epoch 105/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6854 - val_loss: 0.6970\n",
      "Epoch 106/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6859 - val_loss: 0.6923\n",
      "Epoch 107/300\n",
      "229/229 [==============================] - 0s 465us/step - loss: 0.6842 - val_loss: 0.6830\n",
      "Epoch 108/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6862 - val_loss: 0.6971\n",
      "Epoch 109/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6859 - val_loss: 0.6897\n",
      "Epoch 110/300\n",
      "229/229 [==============================] - 0s 441us/step - loss: 0.6851 - val_loss: 0.6942\n",
      "Epoch 111/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6846 - val_loss: 0.6617\n",
      "Epoch 112/300\n",
      "229/229 [==============================] - 0s 484us/step - loss: 0.6843 - val_loss: 0.6877\n",
      "Epoch 113/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6842 - val_loss: 0.6898\n",
      "Epoch 114/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6859 - val_loss: 0.7180\n",
      "Epoch 115/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6850 - val_loss: 0.6767\n",
      "Epoch 116/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6822 - val_loss: 0.6869\n",
      "Epoch 117/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6860 - val_loss: 0.6864\n",
      "Epoch 118/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6861 - val_loss: 0.7132\n",
      "Epoch 119/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6855 - val_loss: 0.6820\n",
      "Epoch 120/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6828 - val_loss: 0.6954\n",
      "Epoch 121/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6853 - val_loss: 0.6793\n",
      "Epoch 122/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6847 - val_loss: 0.6648\n",
      "Epoch 123/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6852 - val_loss: 0.6877\n",
      "Epoch 124/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6846 - val_loss: 0.6840\n",
      "Epoch 125/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6875 - val_loss: 0.7144\n",
      "Epoch 126/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6842 - val_loss: 0.6983\n",
      "Epoch 127/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6846 - val_loss: 0.6741\n",
      "Epoch 128/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6845 - val_loss: 0.6774\n",
      "Epoch 129/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6817 - val_loss: 0.6811\n",
      "Epoch 130/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6854 - val_loss: 0.6867\n",
      "Epoch 131/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6834 - val_loss: 0.6824\n",
      "Epoch 132/300\n",
      "229/229 [==============================] - 0s 468us/step - loss: 0.6846 - val_loss: 0.6902\n",
      "Epoch 133/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6839 - val_loss: 0.6994\n",
      "Epoch 134/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6861 - val_loss: 0.6782\n",
      "Epoch 135/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6859 - val_loss: 0.6742\n",
      "Epoch 136/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6838 - val_loss: 0.6881\n",
      "Epoch 137/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6825 - val_loss: 0.6747\n",
      "Epoch 138/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6829 - val_loss: 0.6856\n",
      "Epoch 139/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6844 - val_loss: 0.6883\n",
      "Epoch 140/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6835 - val_loss: 0.6957\n",
      "Epoch 141/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6841 - val_loss: 0.6799\n",
      "Epoch 142/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6835 - val_loss: 0.6914\n",
      "Epoch 143/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6841 - val_loss: 0.6811\n",
      "Epoch 144/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6824 - val_loss: 0.6804\n",
      "Epoch 145/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6857 - val_loss: 0.6794\n",
      "Epoch 146/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6828 - val_loss: 0.6829\n",
      "Epoch 147/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6841 - val_loss: 0.6883\n",
      "Epoch 148/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6824 - val_loss: 0.6733\n",
      "Epoch 149/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6819 - val_loss: 0.6703\n",
      "Epoch 150/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6826 - val_loss: 0.6804\n",
      "Epoch 151/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6845 - val_loss: 0.6709\n",
      "Epoch 152/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6816 - val_loss: 0.6826\n",
      "Epoch 153/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6833 - val_loss: 0.6855\n",
      "Epoch 154/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6830 - val_loss: 0.6940\n",
      "Epoch 155/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6826 - val_loss: 0.6958\n",
      "Epoch 156/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6821 - val_loss: 0.6860\n",
      "Epoch 157/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6828 - val_loss: 0.6994\n",
      "Epoch 158/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6852 - val_loss: 0.6825\n",
      "Epoch 159/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6835 - val_loss: 0.6978\n",
      "Epoch 160/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6834 - val_loss: 0.6839\n",
      "Epoch 161/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6833 - val_loss: 0.6988\n",
      "Epoch 162/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6826 - val_loss: 0.6917\n",
      "Epoch 163/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6839 - val_loss: 0.6861\n",
      "Epoch 164/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6822 - val_loss: 0.6942\n",
      "Epoch 165/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6815 - val_loss: 0.6978\n",
      "Epoch 166/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6835 - val_loss: 0.6687\n",
      "Epoch 167/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6810 - val_loss: 0.6794\n",
      "Epoch 168/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6821 - val_loss: 0.6985\n",
      "Epoch 169/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6815 - val_loss: 0.6950\n",
      "Epoch 170/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6824 - val_loss: 0.6943\n",
      "Epoch 171/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6830 - val_loss: 0.6869\n",
      "Epoch 172/300\n",
      "229/229 [==============================] - 0s 545us/step - loss: 0.6835 - val_loss: 0.6749\n",
      "Epoch 173/300\n",
      "229/229 [==============================] - 0s 551us/step - loss: 0.6801 - val_loss: 0.6940\n",
      "Epoch 174/300\n",
      "229/229 [==============================] - 0s 576us/step - loss: 0.6827 - val_loss: 0.6973\n",
      "Epoch 175/300\n",
      "229/229 [==============================] - 0s 966us/step - loss: 0.6817 - val_loss: 0.6892\n",
      "Epoch 176/300\n",
      "229/229 [==============================] - 0s 519us/step - loss: 0.6823 - val_loss: 0.6937\n",
      "Epoch 177/300\n",
      "229/229 [==============================] - 0s 409us/step - loss: 0.6828 - val_loss: 0.6861\n",
      "Epoch 178/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6807 - val_loss: 0.6838\n",
      "Epoch 179/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6836 - val_loss: 0.6769\n",
      "Epoch 180/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6827 - val_loss: 0.6729\n",
      "Epoch 181/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6812 - val_loss: 0.6818\n",
      "Epoch 182/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6836 - val_loss: 0.6877\n",
      "Epoch 183/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6819 - val_loss: 0.7045\n",
      "Epoch 184/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6847 - val_loss: 0.6849\n",
      "Epoch 185/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6825 - val_loss: 0.6927\n",
      "Epoch 186/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6837 - val_loss: 0.6769\n",
      "Epoch 187/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6828 - val_loss: 0.6809\n",
      "Epoch 188/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6819 - val_loss: 0.6794\n",
      "Epoch 189/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6824 - val_loss: 0.6860\n",
      "Epoch 190/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6825 - val_loss: 0.6721\n",
      "Epoch 191/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6824 - val_loss: 0.6921\n",
      "Epoch 192/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6804 - val_loss: 0.6813\n",
      "Epoch 193/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6800 - val_loss: 0.6861\n",
      "Epoch 194/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6844 - val_loss: 0.6759\n",
      "Epoch 195/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6810 - val_loss: 0.6828\n",
      "Epoch 196/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6823 - val_loss: 0.6789\n",
      "Epoch 197/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6819 - val_loss: 0.6825\n",
      "Epoch 198/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6806 - val_loss: 0.6854\n",
      "Epoch 199/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6820 - val_loss: 0.7276\n",
      "Epoch 200/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6812 - val_loss: 0.6655\n",
      "Epoch 201/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6814 - val_loss: 0.6795\n",
      "Epoch 202/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6803 - val_loss: 0.6911\n",
      "Epoch 203/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6807 - val_loss: 0.7516\n",
      "Epoch 204/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6831 - val_loss: 0.6770\n",
      "Epoch 205/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6808 - val_loss: 0.6893\n",
      "Epoch 206/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6808 - val_loss: 0.6843\n",
      "Epoch 207/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6813 - val_loss: 0.6781\n",
      "Epoch 208/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6792 - val_loss: 0.6945\n",
      "Epoch 209/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6796 - val_loss: 0.6906\n",
      "Epoch 210/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6821 - val_loss: 0.6926\n",
      "Epoch 211/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6822 - val_loss: 0.6895\n",
      "Epoch 212/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6803 - val_loss: 0.6953\n",
      "Epoch 213/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6823 - val_loss: 0.6845\n",
      "Epoch 214/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6777 - val_loss: 0.6906\n",
      "Epoch 215/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6824 - val_loss: 0.6774\n",
      "Epoch 216/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6821 - val_loss: 0.6902\n",
      "Epoch 217/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6813 - val_loss: 0.6696\n",
      "Epoch 218/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6815 - val_loss: 0.6985\n",
      "Epoch 219/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6824 - val_loss: 0.6828\n",
      "Epoch 220/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6833 - val_loss: 0.6756\n",
      "Epoch 221/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6847 - val_loss: 0.6727\n",
      "Epoch 222/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6810 - val_loss: 0.7081\n",
      "Epoch 223/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6830 - val_loss: 0.6822\n",
      "Epoch 224/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6797 - val_loss: 0.6864\n",
      "Epoch 225/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6806 - val_loss: 0.6994\n",
      "Epoch 226/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6807 - val_loss: 0.6678\n",
      "Epoch 227/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6819 - val_loss: 0.7081\n",
      "Epoch 228/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6842 - val_loss: 0.6755\n",
      "Epoch 229/300\n",
      "229/229 [==============================] - 0s 452us/step - loss: 0.6793 - val_loss: 0.6901\n",
      "Epoch 230/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6819 - val_loss: 0.6907\n",
      "Epoch 231/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6825 - val_loss: 0.6891\n",
      "Epoch 232/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6804 - val_loss: 0.6961\n",
      "Epoch 233/300\n",
      "229/229 [==============================] - 0s 441us/step - loss: 0.6831 - val_loss: 0.6865\n",
      "Epoch 234/300\n",
      "229/229 [==============================] - 0s 573us/step - loss: 0.6807 - val_loss: 0.6913\n",
      "Epoch 235/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6827 - val_loss: 0.6880\n",
      "Epoch 236/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6806 - val_loss: 0.7023\n",
      "Epoch 237/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6802 - val_loss: 0.6795\n",
      "Epoch 238/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6808 - val_loss: 0.6980\n",
      "Epoch 239/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6820 - val_loss: 0.6866\n",
      "Epoch 240/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6810 - val_loss: 0.6820\n",
      "Epoch 241/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6817 - val_loss: 0.6784\n",
      "Epoch 242/300\n",
      "229/229 [==============================] - 0s 694us/step - loss: 0.6810 - val_loss: 0.6878\n",
      "Epoch 243/300\n",
      "229/229 [==============================] - 0s 483us/step - loss: 0.6833 - val_loss: 0.7059\n",
      "Epoch 244/300\n",
      "229/229 [==============================] - 0s 456us/step - loss: 0.6799 - val_loss: 0.7087\n",
      "Epoch 245/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6829 - val_loss: 0.6856\n",
      "Epoch 246/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6827 - val_loss: 0.6885\n",
      "Epoch 247/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6802 - val_loss: 0.6783\n",
      "Epoch 248/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6803 - val_loss: 0.6716\n",
      "Epoch 249/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6809 - val_loss: 0.6888\n",
      "Epoch 250/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6837 - val_loss: 0.6834\n",
      "Epoch 251/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6809 - val_loss: 0.7110\n",
      "Epoch 252/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6792 - val_loss: 0.6973\n",
      "Epoch 253/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6823 - val_loss: 0.6833\n",
      "Epoch 254/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6810 - val_loss: 0.6856\n",
      "Epoch 255/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6827 - val_loss: 0.6799\n",
      "Epoch 256/300\n",
      "229/229 [==============================] - 0s 449us/step - loss: 0.6799 - val_loss: 0.6856\n",
      "Epoch 257/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6812 - val_loss: 0.6800\n",
      "Epoch 258/300\n",
      "229/229 [==============================] - 0s 447us/step - loss: 0.6792 - val_loss: 0.6924\n",
      "Epoch 259/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6817 - val_loss: 0.7024\n",
      "Epoch 260/300\n",
      "229/229 [==============================] - 0s 447us/step - loss: 0.6809 - val_loss: 0.6850\n",
      "Epoch 261/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6799 - val_loss: 0.6891\n",
      "Epoch 262/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6769 - val_loss: 0.6911\n",
      "Epoch 263/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6822 - val_loss: 0.6813\n",
      "Epoch 264/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6830 - val_loss: 0.6876\n",
      "Epoch 265/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6807 - val_loss: 0.7080\n",
      "Epoch 266/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6821 - val_loss: 0.6835\n",
      "Epoch 267/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6810 - val_loss: 0.6947\n",
      "Epoch 268/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6815 - val_loss: 0.6768\n",
      "Epoch 269/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6809 - val_loss: 0.6904\n",
      "Epoch 270/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6832 - val_loss: 0.6858\n",
      "Epoch 271/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6816 - val_loss: 0.6791\n",
      "Epoch 272/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6811 - val_loss: 0.6966\n",
      "Epoch 273/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6810 - val_loss: 0.6865\n",
      "Epoch 274/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6811 - val_loss: 0.6908\n",
      "Epoch 275/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6812 - val_loss: 0.6922\n",
      "Epoch 276/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6818 - val_loss: 0.6992\n",
      "Epoch 277/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6822 - val_loss: 0.6730\n",
      "Epoch 278/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6805 - val_loss: 0.6931\n",
      "Epoch 279/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6814 - val_loss: 0.7006\n",
      "Epoch 280/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6817 - val_loss: 0.6809\n",
      "Epoch 281/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6810 - val_loss: 0.6836\n",
      "Epoch 282/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6804 - val_loss: 0.6869\n",
      "Epoch 283/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6826 - val_loss: 0.6915\n",
      "Epoch 284/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6820 - val_loss: 0.6832\n",
      "Epoch 285/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6802 - val_loss: 0.6982\n",
      "Epoch 286/300\n",
      "229/229 [==============================] - 0s 460us/step - loss: 0.6803 - val_loss: 0.7210\n",
      "Epoch 287/300\n",
      "229/229 [==============================] - 0s 491us/step - loss: 0.6817 - val_loss: 0.6957\n",
      "Epoch 288/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6801 - val_loss: 0.6908\n",
      "Epoch 289/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6810 - val_loss: 0.6677\n",
      "Epoch 290/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6821 - val_loss: 0.6855\n",
      "Epoch 291/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6825 - val_loss: 0.6836\n",
      "Epoch 292/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6834 - val_loss: 0.6826\n",
      "Epoch 293/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6800 - val_loss: 0.6908\n",
      "Epoch 294/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6821 - val_loss: 0.6719\n",
      "Epoch 295/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6803 - val_loss: 0.6760\n",
      "Epoch 296/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6821 - val_loss: 0.7124\n",
      "Epoch 297/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6804 - val_loss: 0.6943\n",
      "Epoch 298/300\n",
      "229/229 [==============================] - 0s 446us/step - loss: 0.6796 - val_loss: 0.6970\n",
      "Epoch 299/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6812 - val_loss: 0.6842\n",
      "Epoch 300/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6821 - val_loss: 0.6830\n",
      "26/26 [==============================] - 0s 345us/step\n",
      "Epoch 1/300\n",
      "229/229 [==============================] - 0s 647us/step - loss: 1.4395 - val_loss: 1.0754\n",
      "Epoch 2/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.9754 - val_loss: 0.9039\n",
      "Epoch 3/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.8759 - val_loss: 0.8561\n",
      "Epoch 4/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.8269 - val_loss: 0.8248\n",
      "Epoch 5/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.8005 - val_loss: 0.8005\n",
      "Epoch 6/300\n",
      "229/229 [==============================] - 0s 459us/step - loss: 0.7826 - val_loss: 0.8108\n",
      "Epoch 7/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.7682 - val_loss: 0.8027\n",
      "Epoch 8/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.7599 - val_loss: 0.7918\n",
      "Epoch 9/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.7484 - val_loss: 0.7765\n",
      "Epoch 10/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.7420 - val_loss: 0.7787\n",
      "Epoch 11/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.7368 - val_loss: 0.7660\n",
      "Epoch 12/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.7298 - val_loss: 0.7635\n",
      "Epoch 13/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7274 - val_loss: 0.7657\n",
      "Epoch 14/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.7238 - val_loss: 0.7852\n",
      "Epoch 15/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7197 - val_loss: 0.7477\n",
      "Epoch 16/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7160 - val_loss: 0.7460\n",
      "Epoch 17/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.7154 - val_loss: 0.7661\n",
      "Epoch 18/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.7116 - val_loss: 0.7622\n",
      "Epoch 19/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7114 - val_loss: 0.7394\n",
      "Epoch 20/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7101 - val_loss: 0.7526\n",
      "Epoch 21/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7063 - val_loss: 0.7412\n",
      "Epoch 22/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7065 - val_loss: 0.7711\n",
      "Epoch 23/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.7037 - val_loss: 0.7526\n",
      "Epoch 24/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.7043 - val_loss: 0.7518\n",
      "Epoch 25/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.7015 - val_loss: 0.7486\n",
      "Epoch 26/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6975 - val_loss: 0.7575\n",
      "Epoch 27/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.7002 - val_loss: 0.7596\n",
      "Epoch 28/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6983 - val_loss: 0.7540\n",
      "Epoch 29/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6968 - val_loss: 0.7456\n",
      "Epoch 30/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6956 - val_loss: 0.7537\n",
      "Epoch 31/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6958 - val_loss: 0.7353\n",
      "Epoch 32/300\n",
      "229/229 [==============================] - 0s 409us/step - loss: 0.6953 - val_loss: 0.7452\n",
      "Epoch 33/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6953 - val_loss: 0.7288\n",
      "Epoch 34/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6927 - val_loss: 0.7425\n",
      "Epoch 35/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6926 - val_loss: 0.7474\n",
      "Epoch 36/300\n",
      "229/229 [==============================] - 0s 408us/step - loss: 0.6923 - val_loss: 0.7375\n",
      "Epoch 37/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6927 - val_loss: 0.7632\n",
      "Epoch 38/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6904 - val_loss: 0.7465\n",
      "Epoch 39/300\n",
      "229/229 [==============================] - 0s 406us/step - loss: 0.6897 - val_loss: 0.7769\n",
      "Epoch 40/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6921 - val_loss: 0.7582\n",
      "Epoch 41/300\n",
      "229/229 [==============================] - 0s 470us/step - loss: 0.6897 - val_loss: 0.7530\n",
      "Epoch 42/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6912 - val_loss: 0.7743\n",
      "Epoch 43/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6914 - val_loss: 0.7303\n",
      "Epoch 44/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6892 - val_loss: 0.7367\n",
      "Epoch 45/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6893 - val_loss: 0.7511\n",
      "Epoch 46/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6879 - val_loss: 0.7449\n",
      "Epoch 47/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6885 - val_loss: 0.7302\n",
      "Epoch 48/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6887 - val_loss: 0.7606\n",
      "Epoch 49/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6895 - val_loss: 0.7428\n",
      "Epoch 50/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6869 - val_loss: 0.7333\n",
      "Epoch 51/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6869 - val_loss: 0.7460\n",
      "Epoch 52/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6893 - val_loss: 0.7354\n",
      "Epoch 53/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6870 - val_loss: 0.7531\n",
      "Epoch 54/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6869 - val_loss: 0.7596\n",
      "Epoch 55/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6894 - val_loss: 0.7288\n",
      "Epoch 56/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6860 - val_loss: 0.7517\n",
      "Epoch 57/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6831 - val_loss: 0.7451\n",
      "Epoch 58/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6859 - val_loss: 0.7444\n",
      "Epoch 59/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6863 - val_loss: 0.7503\n",
      "Epoch 60/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6864 - val_loss: 0.7545\n",
      "Epoch 61/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6848 - val_loss: 0.7314\n",
      "Epoch 62/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6870 - val_loss: 0.7373\n",
      "Epoch 63/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6839 - val_loss: 0.7437\n",
      "Epoch 64/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6851 - val_loss: 0.7343\n",
      "Epoch 65/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6860 - val_loss: 0.7268\n",
      "Epoch 66/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6844 - val_loss: 0.7391\n",
      "Epoch 67/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6846 - val_loss: 0.7319\n",
      "Epoch 68/300\n",
      "229/229 [==============================] - 0s 407us/step - loss: 0.6837 - val_loss: 0.7416\n",
      "Epoch 69/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6819 - val_loss: 0.7450\n",
      "Epoch 70/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6842 - val_loss: 0.7312\n",
      "Epoch 71/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6841 - val_loss: 0.7766\n",
      "Epoch 72/300\n",
      "229/229 [==============================] - 0s 410us/step - loss: 0.6834 - val_loss: 0.7413\n",
      "Epoch 73/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6852 - val_loss: 0.7278\n",
      "Epoch 74/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6850 - val_loss: 0.7629\n",
      "Epoch 75/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6829 - val_loss: 0.7429\n",
      "Epoch 76/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6854 - val_loss: 0.7244\n",
      "Epoch 77/300\n",
      "229/229 [==============================] - 0s 454us/step - loss: 0.6834 - val_loss: 0.7368\n",
      "Epoch 78/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6827 - val_loss: 0.7314\n",
      "Epoch 79/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6832 - val_loss: 0.7343\n",
      "Epoch 80/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6803 - val_loss: 0.7625\n",
      "Epoch 81/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6841 - val_loss: 0.7460\n",
      "Epoch 82/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6815 - val_loss: 0.7478\n",
      "Epoch 83/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6825 - val_loss: 0.7459\n",
      "Epoch 84/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6823 - val_loss: 0.7642\n",
      "Epoch 85/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6833 - val_loss: 0.7231\n",
      "Epoch 86/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6820 - val_loss: 0.7320\n",
      "Epoch 87/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6835 - val_loss: 0.7414\n",
      "Epoch 88/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6836 - val_loss: 0.7553\n",
      "Epoch 89/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6843 - val_loss: 0.7573\n",
      "Epoch 90/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6829 - val_loss: 0.7427\n",
      "Epoch 91/300\n",
      "229/229 [==============================] - 0s 447us/step - loss: 0.6814 - val_loss: 0.7301\n",
      "Epoch 92/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6832 - val_loss: 0.7283\n",
      "Epoch 93/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6827 - val_loss: 0.7290\n",
      "Epoch 94/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6817 - val_loss: 0.7304\n",
      "Epoch 95/300\n",
      "229/229 [==============================] - 0s 651us/step - loss: 0.6829 - val_loss: 0.7502\n",
      "Epoch 96/300\n",
      "229/229 [==============================] - 0s 604us/step - loss: 0.6823 - val_loss: 0.7206\n",
      "Epoch 97/300\n",
      "229/229 [==============================] - 0s 877us/step - loss: 0.6795 - val_loss: 0.7269\n",
      "Epoch 98/300\n",
      "229/229 [==============================] - 0s 543us/step - loss: 0.6825 - val_loss: 0.7275\n",
      "Epoch 99/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6813 - val_loss: 0.7458\n",
      "Epoch 100/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6818 - val_loss: 0.7394\n",
      "Epoch 101/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6830 - val_loss: 0.7305\n",
      "Epoch 102/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6824 - val_loss: 0.7329\n",
      "Epoch 103/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6804 - val_loss: 0.7411\n",
      "Epoch 104/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6824 - val_loss: 0.7549\n",
      "Epoch 105/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6827 - val_loss: 0.7285\n",
      "Epoch 106/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6818 - val_loss: 0.7339\n",
      "Epoch 107/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6807 - val_loss: 0.7335\n",
      "Epoch 108/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6807 - val_loss: 0.7403\n",
      "Epoch 109/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6819 - val_loss: 0.7260\n",
      "Epoch 110/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6810 - val_loss: 0.7313\n",
      "Epoch 111/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6803 - val_loss: 0.7240\n",
      "Epoch 112/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6815 - val_loss: 0.7265\n",
      "Epoch 113/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6812 - val_loss: 0.7271\n",
      "Epoch 114/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6811 - val_loss: 0.7640\n",
      "Epoch 115/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6826 - val_loss: 0.7276\n",
      "Epoch 116/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6795 - val_loss: 0.7428\n",
      "Epoch 117/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6818 - val_loss: 0.7288\n",
      "Epoch 118/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6813 - val_loss: 0.7228\n",
      "Epoch 119/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6810 - val_loss: 0.7342\n",
      "Epoch 120/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6793 - val_loss: 0.7493\n",
      "Epoch 121/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6811 - val_loss: 0.7311\n",
      "Epoch 122/300\n",
      "229/229 [==============================] - 0s 410us/step - loss: 0.6782 - val_loss: 0.7306\n",
      "Epoch 123/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6814 - val_loss: 0.7211\n",
      "Epoch 124/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6820 - val_loss: 0.7446\n",
      "Epoch 125/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6798 - val_loss: 0.7329\n",
      "Epoch 126/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6785 - val_loss: 0.7521\n",
      "Epoch 127/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6798 - val_loss: 0.7461\n",
      "Epoch 128/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6812 - val_loss: 0.7307\n",
      "Epoch 129/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6802 - val_loss: 0.7278\n",
      "Epoch 130/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6817 - val_loss: 0.7430\n",
      "Epoch 131/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6791 - val_loss: 0.7229\n",
      "Epoch 132/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6797 - val_loss: 0.7438\n",
      "Epoch 133/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6782 - val_loss: 0.7497\n",
      "Epoch 134/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6803 - val_loss: 0.7406\n",
      "Epoch 135/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6784 - val_loss: 0.7411\n",
      "Epoch 136/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6809 - val_loss: 0.7223\n",
      "Epoch 137/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6785 - val_loss: 0.7309\n",
      "Epoch 138/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6804 - val_loss: 0.7343\n",
      "Epoch 139/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6792 - val_loss: 0.7375\n",
      "Epoch 140/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6794 - val_loss: 0.7449\n",
      "Epoch 141/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6786 - val_loss: 0.7540\n",
      "Epoch 142/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6810 - val_loss: 0.7254\n",
      "Epoch 143/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6786 - val_loss: 0.7400\n",
      "Epoch 144/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6776 - val_loss: 0.7459\n",
      "Epoch 145/300\n",
      "229/229 [==============================] - 0s 410us/step - loss: 0.6806 - val_loss: 0.7263\n",
      "Epoch 146/300\n",
      "229/229 [==============================] - 0s 494us/step - loss: 0.6767 - val_loss: 0.7351\n",
      "Epoch 147/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6784 - val_loss: 0.7391\n",
      "Epoch 148/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6794 - val_loss: 0.7306\n",
      "Epoch 149/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6793 - val_loss: 0.7730\n",
      "Epoch 150/300\n",
      "229/229 [==============================] - 0s 574us/step - loss: 0.6809 - val_loss: 0.7492\n",
      "Epoch 151/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6779 - val_loss: 0.7290\n",
      "Epoch 152/300\n",
      "229/229 [==============================] - 0s 408us/step - loss: 0.6764 - val_loss: 0.7293\n",
      "Epoch 153/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6772 - val_loss: 0.7400\n",
      "Epoch 154/300\n",
      "229/229 [==============================] - 0s 408us/step - loss: 0.6797 - val_loss: 0.7350\n",
      "Epoch 155/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6766 - val_loss: 0.7343\n",
      "Epoch 156/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6812 - val_loss: 0.7439\n",
      "Epoch 157/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6756 - val_loss: 0.7368\n",
      "Epoch 158/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6779 - val_loss: 0.7219\n",
      "Epoch 159/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6789 - val_loss: 0.7360\n",
      "Epoch 160/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6770 - val_loss: 0.7182\n",
      "Epoch 161/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6791 - val_loss: 0.7389\n",
      "Epoch 162/300\n",
      "229/229 [==============================] - 0s 409us/step - loss: 0.6784 - val_loss: 0.7304\n",
      "Epoch 163/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6781 - val_loss: 0.7467\n",
      "Epoch 164/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6786 - val_loss: 0.7453\n",
      "Epoch 165/300\n",
      "229/229 [==============================] - 0s 410us/step - loss: 0.6792 - val_loss: 0.7365\n",
      "Epoch 166/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6778 - val_loss: 0.7391\n",
      "Epoch 167/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6780 - val_loss: 0.7461\n",
      "Epoch 168/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6776 - val_loss: 0.7396\n",
      "Epoch 169/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6796 - val_loss: 0.7465\n",
      "Epoch 170/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6776 - val_loss: 0.7398\n",
      "Epoch 171/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6783 - val_loss: 0.7383\n",
      "Epoch 172/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6778 - val_loss: 0.7339\n",
      "Epoch 173/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6800 - val_loss: 0.7360\n",
      "Epoch 174/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6781 - val_loss: 0.7306\n",
      "Epoch 175/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6781 - val_loss: 0.7380\n",
      "Epoch 176/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6777 - val_loss: 0.7239\n",
      "Epoch 177/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6779 - val_loss: 0.7365\n",
      "Epoch 178/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6770 - val_loss: 0.7352\n",
      "Epoch 179/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6779 - val_loss: 0.7429\n",
      "Epoch 180/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6754 - val_loss: 0.7358\n",
      "Epoch 181/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6774 - val_loss: 0.7485\n",
      "Epoch 182/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6775 - val_loss: 0.7436\n",
      "Epoch 183/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6791 - val_loss: 0.7345\n",
      "Epoch 184/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6784 - val_loss: 0.7242\n",
      "Epoch 185/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6757 - val_loss: 0.7591\n",
      "Epoch 186/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6779 - val_loss: 0.7225\n",
      "Epoch 187/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6771 - val_loss: 0.7369\n",
      "Epoch 188/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6780 - val_loss: 0.7502\n",
      "Epoch 189/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6764 - val_loss: 0.7395\n",
      "Epoch 190/300\n",
      "229/229 [==============================] - 0s 409us/step - loss: 0.6787 - val_loss: 0.7278\n",
      "Epoch 191/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6779 - val_loss: 0.7437\n",
      "Epoch 192/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6800 - val_loss: 0.7381\n",
      "Epoch 193/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6782 - val_loss: 0.7275\n",
      "Epoch 194/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6753 - val_loss: 0.7348\n",
      "Epoch 195/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6756 - val_loss: 0.7409\n",
      "Epoch 196/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6788 - val_loss: 0.7189\n",
      "Epoch 197/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6781 - val_loss: 0.7312\n",
      "Epoch 198/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6791 - val_loss: 0.7269\n",
      "Epoch 199/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6773 - val_loss: 0.7825\n",
      "Epoch 200/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6789 - val_loss: 0.7367\n",
      "Epoch 201/300\n",
      "229/229 [==============================] - 0s 456us/step - loss: 0.6781 - val_loss: 0.7354\n",
      "Epoch 202/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6764 - val_loss: 0.7431\n",
      "Epoch 203/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6804 - val_loss: 0.7753\n",
      "Epoch 204/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6757 - val_loss: 0.7562\n",
      "Epoch 205/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6776 - val_loss: 0.7582\n",
      "Epoch 206/300\n",
      "229/229 [==============================] - 0s 410us/step - loss: 0.6779 - val_loss: 0.7268\n",
      "Epoch 207/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6762 - val_loss: 0.7334\n",
      "Epoch 208/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6755 - val_loss: 0.7448\n",
      "Epoch 209/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6769 - val_loss: 0.7198\n",
      "Epoch 210/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6762 - val_loss: 0.7312\n",
      "Epoch 211/300\n",
      "229/229 [==============================] - 0s 409us/step - loss: 0.6772 - val_loss: 0.7293\n",
      "Epoch 212/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6784 - val_loss: 0.7103\n",
      "Epoch 213/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6786 - val_loss: 0.7337\n",
      "Epoch 214/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6762 - val_loss: 0.7364\n",
      "Epoch 215/300\n",
      "229/229 [==============================] - 0s 408us/step - loss: 0.6770 - val_loss: 0.7367\n",
      "Epoch 216/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6765 - val_loss: 0.7183\n",
      "Epoch 217/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6769 - val_loss: 0.7319\n",
      "Epoch 218/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6772 - val_loss: 0.7414\n",
      "Epoch 219/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6764 - val_loss: 0.7493\n",
      "Epoch 220/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6763 - val_loss: 0.7450\n",
      "Epoch 221/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6786 - val_loss: 0.7416\n",
      "Epoch 222/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6785 - val_loss: 0.7375\n",
      "Epoch 223/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6776 - val_loss: 0.7404\n",
      "Epoch 224/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6788 - val_loss: 0.7522\n",
      "Epoch 225/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6772 - val_loss: 0.7350\n",
      "Epoch 226/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6767 - val_loss: 0.7239\n",
      "Epoch 227/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6785 - val_loss: 0.7199\n",
      "Epoch 228/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6774 - val_loss: 0.7489\n",
      "Epoch 229/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6771 - val_loss: 0.7241\n",
      "Epoch 230/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6786 - val_loss: 0.7395\n",
      "Epoch 231/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6771 - val_loss: 0.7472\n",
      "Epoch 232/300\n",
      "229/229 [==============================] - 0s 450us/step - loss: 0.6773 - val_loss: 0.7270\n",
      "Epoch 233/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6771 - val_loss: 0.7315\n",
      "Epoch 234/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6764 - val_loss: 0.7257\n",
      "Epoch 235/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6778 - val_loss: 0.7353\n",
      "Epoch 236/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6765 - val_loss: 0.7237\n",
      "Epoch 237/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6788 - val_loss: 0.7166\n",
      "Epoch 238/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6770 - val_loss: 0.7203\n",
      "Epoch 239/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6787 - val_loss: 0.7278\n",
      "Epoch 240/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6754 - val_loss: 0.7265\n",
      "Epoch 241/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6778 - val_loss: 0.7445\n",
      "Epoch 242/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6766 - val_loss: 0.7621\n",
      "Epoch 243/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6783 - val_loss: 0.7641\n",
      "Epoch 244/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6761 - val_loss: 0.7372\n",
      "Epoch 245/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6788 - val_loss: 0.7269\n",
      "Epoch 246/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6778 - val_loss: 0.7348\n",
      "Epoch 247/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6755 - val_loss: 0.7554\n",
      "Epoch 248/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6767 - val_loss: 0.7351\n",
      "Epoch 249/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6774 - val_loss: 0.7423\n",
      "Epoch 250/300\n",
      "229/229 [==============================] - 0s 399us/step - loss: 0.6772 - val_loss: 0.7516\n",
      "Epoch 251/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6761 - val_loss: 0.7661\n",
      "Epoch 252/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6783 - val_loss: 0.7320\n",
      "Epoch 253/300\n",
      "229/229 [==============================] - 0s 457us/step - loss: 0.6784 - val_loss: 0.7319\n",
      "Epoch 254/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6774 - val_loss: 0.7217\n",
      "Epoch 255/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6786 - val_loss: 0.7282\n",
      "Epoch 256/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6775 - val_loss: 0.7422\n",
      "Epoch 257/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6784 - val_loss: 0.7348\n",
      "Epoch 258/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6778 - val_loss: 0.7427\n",
      "Epoch 259/300\n",
      "229/229 [==============================] - 0s 406us/step - loss: 0.6771 - val_loss: 0.7575\n",
      "Epoch 260/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6767 - val_loss: 0.7264\n",
      "Epoch 261/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6758 - val_loss: 0.7351\n",
      "Epoch 262/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6746 - val_loss: 0.7502\n",
      "Epoch 263/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6773 - val_loss: 0.7329\n",
      "Epoch 264/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6788 - val_loss: 0.7550\n",
      "Epoch 265/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6754 - val_loss: 0.7305\n",
      "Epoch 266/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6776 - val_loss: 0.7336\n",
      "Epoch 267/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6747 - val_loss: 0.7330\n",
      "Epoch 268/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6778 - val_loss: 0.7420\n",
      "Epoch 269/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6771 - val_loss: 0.7406\n",
      "Epoch 270/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6758 - val_loss: 0.7361\n",
      "Epoch 271/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6772 - val_loss: 0.7217\n",
      "Epoch 272/300\n",
      "229/229 [==============================] - 0s 511us/step - loss: 0.6770 - val_loss: 0.7480\n",
      "Epoch 273/300\n",
      "229/229 [==============================] - 0s 840us/step - loss: 0.6782 - val_loss: 0.7248\n",
      "Epoch 274/300\n",
      "229/229 [==============================] - 1s 2ms/step - loss: 0.6765 - val_loss: 0.7313\n",
      "Epoch 275/300\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6768 - val_loss: 0.7503\n",
      "Epoch 276/300\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6773 - val_loss: 0.7321\n",
      "Epoch 277/300\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6780 - val_loss: 0.7283\n",
      "Epoch 278/300\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6791 - val_loss: 0.7345\n",
      "Epoch 279/300\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6792 - val_loss: 0.7253\n",
      "Epoch 280/300\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6770 - val_loss: 0.7453\n",
      "Epoch 281/300\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6757 - val_loss: 0.7325\n",
      "Epoch 282/300\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6778 - val_loss: 0.7562\n",
      "Epoch 283/300\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.6777 - val_loss: 0.7227\n",
      "Epoch 284/300\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.6770 - val_loss: 0.7658\n",
      "Epoch 285/300\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.6759 - val_loss: 0.7271\n",
      "Epoch 286/300\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6745 - val_loss: 0.7167\n",
      "Epoch 287/300\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.6791 - val_loss: 0.7234\n",
      "Epoch 288/300\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6776 - val_loss: 0.7388\n",
      "Epoch 289/300\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6767 - val_loss: 0.7401\n",
      "Epoch 290/300\n",
      "229/229 [==============================] - 1s 2ms/step - loss: 0.6774 - val_loss: 0.7296\n",
      "Epoch 291/300\n",
      "229/229 [==============================] - 0s 485us/step - loss: 0.6767 - val_loss: 0.7202\n",
      "Epoch 292/300\n",
      "229/229 [==============================] - 0s 471us/step - loss: 0.6790 - val_loss: 0.7368\n",
      "Epoch 293/300\n",
      "229/229 [==============================] - 0s 482us/step - loss: 0.6766 - val_loss: 0.7279\n",
      "Epoch 294/300\n",
      "229/229 [==============================] - 0s 480us/step - loss: 0.6768 - val_loss: 0.7336\n",
      "Epoch 295/300\n",
      "229/229 [==============================] - 0s 475us/step - loss: 0.6757 - val_loss: 0.7783\n",
      "Epoch 296/300\n",
      "229/229 [==============================] - 0s 503us/step - loss: 0.6781 - val_loss: 0.7371\n",
      "Epoch 297/300\n",
      "229/229 [==============================] - 0s 473us/step - loss: 0.6762 - val_loss: 0.7194\n",
      "Epoch 298/300\n",
      "229/229 [==============================] - 0s 471us/step - loss: 0.6773 - val_loss: 0.7282\n",
      "Epoch 299/300\n",
      "229/229 [==============================] - 0s 461us/step - loss: 0.6777 - val_loss: 0.7221\n",
      "Epoch 300/300\n",
      "229/229 [==============================] - 0s 524us/step - loss: 0.6768 - val_loss: 0.7349\n",
      "26/26 [==============================] - 0s 363us/step\n",
      "Epoch 1/300\n",
      "229/229 [==============================] - 0s 603us/step - loss: 1.4862 - val_loss: 1.0673\n",
      "Epoch 2/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.9998 - val_loss: 0.8878\n",
      "Epoch 3/300\n",
      "229/229 [==============================] - 0s 535us/step - loss: 0.8929 - val_loss: 0.8362\n",
      "Epoch 4/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.8445 - val_loss: 0.7848\n",
      "Epoch 5/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.8122 - val_loss: 0.7795\n",
      "Epoch 6/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.7924 - val_loss: 0.7550\n",
      "Epoch 7/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7755 - val_loss: 0.7398\n",
      "Epoch 8/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7628 - val_loss: 0.7254\n",
      "Epoch 9/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.7555 - val_loss: 0.7511\n",
      "Epoch 10/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.7487 - val_loss: 0.7202\n",
      "Epoch 11/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.7393 - val_loss: 0.7249\n",
      "Epoch 12/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.7323 - val_loss: 0.7165\n",
      "Epoch 13/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.7304 - val_loss: 0.7158\n",
      "Epoch 14/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.7276 - val_loss: 0.7018\n",
      "Epoch 15/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.7217 - val_loss: 0.7422\n",
      "Epoch 16/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.7217 - val_loss: 0.7011\n",
      "Epoch 17/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7164 - val_loss: 0.7102\n",
      "Epoch 18/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7145 - val_loss: 0.7188\n",
      "Epoch 19/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.7138 - val_loss: 0.7088\n",
      "Epoch 20/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.7101 - val_loss: 0.7365\n",
      "Epoch 21/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.7082 - val_loss: 0.7014\n",
      "Epoch 22/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.7073 - val_loss: 0.7123\n",
      "Epoch 23/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.7049 - val_loss: 0.6946\n",
      "Epoch 24/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.7030 - val_loss: 0.6951\n",
      "Epoch 25/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.7048 - val_loss: 0.7158\n",
      "Epoch 26/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.7015 - val_loss: 0.6905\n",
      "Epoch 27/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7022 - val_loss: 0.6982\n",
      "Epoch 28/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.7021 - val_loss: 0.7057\n",
      "Epoch 29/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.7002 - val_loss: 0.6928\n",
      "Epoch 30/300\n",
      "229/229 [==============================] - 0s 443us/step - loss: 0.6994 - val_loss: 0.7016\n",
      "Epoch 31/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6982 - val_loss: 0.6854\n",
      "Epoch 32/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6982 - val_loss: 0.7079\n",
      "Epoch 33/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6969 - val_loss: 0.6955\n",
      "Epoch 34/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6956 - val_loss: 0.6902\n",
      "Epoch 35/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6993 - val_loss: 0.6844\n",
      "Epoch 36/300\n",
      "229/229 [==============================] - 0s 443us/step - loss: 0.6951 - val_loss: 0.6930\n",
      "Epoch 37/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6969 - val_loss: 0.7191\n",
      "Epoch 38/300\n",
      "229/229 [==============================] - 0s 452us/step - loss: 0.6932 - val_loss: 0.6916\n",
      "Epoch 39/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6961 - val_loss: 0.6817\n",
      "Epoch 40/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6951 - val_loss: 0.6950\n",
      "Epoch 41/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6941 - val_loss: 0.6778\n",
      "Epoch 42/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6954 - val_loss: 0.6822\n",
      "Epoch 43/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6937 - val_loss: 0.6970\n",
      "Epoch 44/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6944 - val_loss: 0.6826\n",
      "Epoch 45/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6938 - val_loss: 0.6798\n",
      "Epoch 46/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6924 - val_loss: 0.6829\n",
      "Epoch 47/300\n",
      "229/229 [==============================] - 0s 466us/step - loss: 0.6924 - val_loss: 0.7002\n",
      "Epoch 48/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6916 - val_loss: 0.6773\n",
      "Epoch 49/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6925 - val_loss: 0.6813\n",
      "Epoch 50/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6926 - val_loss: 0.6911\n",
      "Epoch 51/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6923 - val_loss: 0.6896\n",
      "Epoch 52/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6915 - val_loss: 0.6873\n",
      "Epoch 53/300\n",
      "229/229 [==============================] - 0s 456us/step - loss: 0.6931 - val_loss: 0.6835\n",
      "Epoch 54/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6883 - val_loss: 0.6848\n",
      "Epoch 55/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6903 - val_loss: 0.7000\n",
      "Epoch 56/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6915 - val_loss: 0.6852\n",
      "Epoch 57/300\n",
      "229/229 [==============================] - 0s 444us/step - loss: 0.6900 - val_loss: 0.6901\n",
      "Epoch 58/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6900 - val_loss: 0.6990\n",
      "Epoch 59/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6912 - val_loss: 0.6835\n",
      "Epoch 60/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6867 - val_loss: 0.6912\n",
      "Epoch 61/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6913 - val_loss: 0.6876\n",
      "Epoch 62/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6894 - val_loss: 0.6828\n",
      "Epoch 63/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6887 - val_loss: 0.6791\n",
      "Epoch 64/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6887 - val_loss: 0.7039\n",
      "Epoch 65/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6892 - val_loss: 0.6764\n",
      "Epoch 66/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6891 - val_loss: 0.6776\n",
      "Epoch 67/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6900 - val_loss: 0.6776\n",
      "Epoch 68/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6888 - val_loss: 0.6847\n",
      "Epoch 69/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6888 - val_loss: 0.6784\n",
      "Epoch 70/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6911 - val_loss: 0.6873\n",
      "Epoch 71/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6895 - val_loss: 0.6855\n",
      "Epoch 72/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6864 - val_loss: 0.7078\n",
      "Epoch 73/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6899 - val_loss: 0.6880\n",
      "Epoch 74/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6880 - val_loss: 0.6843\n",
      "Epoch 75/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6868 - val_loss: 0.6900\n",
      "Epoch 76/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6872 - val_loss: 0.6960\n",
      "Epoch 77/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6877 - val_loss: 0.6920\n",
      "Epoch 78/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6866 - val_loss: 0.7285\n",
      "Epoch 79/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6877 - val_loss: 0.6794\n",
      "Epoch 80/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6894 - val_loss: 0.6860\n",
      "Epoch 81/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6857 - val_loss: 0.6897\n",
      "Epoch 82/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6875 - val_loss: 0.6884\n",
      "Epoch 83/300\n",
      "229/229 [==============================] - 0s 475us/step - loss: 0.6865 - val_loss: 0.6909\n",
      "Epoch 84/300\n",
      "229/229 [==============================] - 0s 665us/step - loss: 0.6875 - val_loss: 0.7049\n",
      "Epoch 85/300\n",
      "229/229 [==============================] - 0s 466us/step - loss: 0.6860 - val_loss: 0.7084\n",
      "Epoch 86/300\n",
      "229/229 [==============================] - 0s 452us/step - loss: 0.6878 - val_loss: 0.6849\n",
      "Epoch 87/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6847 - val_loss: 0.6769\n",
      "Epoch 88/300\n",
      "229/229 [==============================] - 0s 406us/step - loss: 0.6859 - val_loss: 0.6757\n",
      "Epoch 89/300\n",
      "229/229 [==============================] - 0s 2ms/step - loss: 0.6855 - val_loss: 0.6855\n",
      "Epoch 90/300\n",
      "229/229 [==============================] - 0s 2ms/step - loss: 0.6863 - val_loss: 0.6863\n",
      "Epoch 91/300\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.6833 - val_loss: 0.7132\n",
      "Epoch 92/300\n",
      "229/229 [==============================] - 0s 632us/step - loss: 0.6883 - val_loss: 0.6875\n",
      "Epoch 93/300\n",
      "229/229 [==============================] - 0s 578us/step - loss: 0.6848 - val_loss: 0.7040\n",
      "Epoch 94/300\n",
      "229/229 [==============================] - 0s 473us/step - loss: 0.6868 - val_loss: 0.6867\n",
      "Epoch 95/300\n",
      "229/229 [==============================] - 0s 466us/step - loss: 0.6845 - val_loss: 0.6769\n",
      "Epoch 96/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6865 - val_loss: 0.6870\n",
      "Epoch 97/300\n",
      "229/229 [==============================] - 0s 455us/step - loss: 0.6847 - val_loss: 0.6695\n",
      "Epoch 98/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6871 - val_loss: 0.7003\n",
      "Epoch 99/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6861 - val_loss: 0.6943\n",
      "Epoch 100/300\n",
      "229/229 [==============================] - 0s 451us/step - loss: 0.6843 - val_loss: 0.6813\n",
      "Epoch 101/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6863 - val_loss: 0.6920\n",
      "Epoch 102/300\n",
      "229/229 [==============================] - 0s 409us/step - loss: 0.6859 - val_loss: 0.6741\n",
      "Epoch 103/300\n",
      "229/229 [==============================] - 0s 452us/step - loss: 0.6843 - val_loss: 0.6793\n",
      "Epoch 104/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6865 - val_loss: 0.6926\n",
      "Epoch 105/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6856 - val_loss: 0.6841\n",
      "Epoch 106/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6848 - val_loss: 0.6773\n",
      "Epoch 107/300\n",
      "229/229 [==============================] - 0s 522us/step - loss: 0.6853 - val_loss: 0.6706\n",
      "Epoch 108/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6847 - val_loss: 0.7227\n",
      "Epoch 109/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6850 - val_loss: 0.6698\n",
      "Epoch 110/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6852 - val_loss: 0.7031\n",
      "Epoch 111/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6837 - val_loss: 0.6688\n",
      "Epoch 112/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6845 - val_loss: 0.6706\n",
      "Epoch 113/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6835 - val_loss: 0.6901\n",
      "Epoch 114/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6857 - val_loss: 0.6898\n",
      "Epoch 115/300\n",
      "229/229 [==============================] - 0s 533us/step - loss: 0.6854 - val_loss: 0.6748\n",
      "Epoch 116/300\n",
      "229/229 [==============================] - 0s 441us/step - loss: 0.6835 - val_loss: 0.6910\n",
      "Epoch 117/300\n",
      "229/229 [==============================] - 0s 500us/step - loss: 0.6841 - val_loss: 0.6846\n",
      "Epoch 118/300\n",
      "229/229 [==============================] - 0s 563us/step - loss: 0.6856 - val_loss: 0.7020\n",
      "Epoch 119/300\n",
      "229/229 [==============================] - 0s 453us/step - loss: 0.6845 - val_loss: 0.6871\n",
      "Epoch 120/300\n",
      "229/229 [==============================] - 0s 585us/step - loss: 0.6836 - val_loss: 0.6937\n",
      "Epoch 121/300\n",
      "229/229 [==============================] - 0s 453us/step - loss: 0.6833 - val_loss: 0.7029\n",
      "Epoch 122/300\n",
      "229/229 [==============================] - 0s 465us/step - loss: 0.6852 - val_loss: 0.6771\n",
      "Epoch 123/300\n",
      "229/229 [==============================] - 0s 576us/step - loss: 0.6846 - val_loss: 0.6760\n",
      "Epoch 124/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6845 - val_loss: 0.6825\n",
      "Epoch 125/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6812 - val_loss: 0.7015\n",
      "Epoch 126/300\n",
      "229/229 [==============================] - 0s 443us/step - loss: 0.6858 - val_loss: 0.6801\n",
      "Epoch 127/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6834 - val_loss: 0.6784\n",
      "Epoch 128/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6848 - val_loss: 0.6918\n",
      "Epoch 129/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6821 - val_loss: 0.6899\n",
      "Epoch 130/300\n",
      "229/229 [==============================] - 0s 436us/step - loss: 0.6850 - val_loss: 0.6892\n",
      "Epoch 131/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6846 - val_loss: 0.6885\n",
      "Epoch 132/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6848 - val_loss: 0.6822\n",
      "Epoch 133/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6827 - val_loss: 0.6762\n",
      "Epoch 134/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6825 - val_loss: 0.7099\n",
      "Epoch 135/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6850 - val_loss: 0.6746\n",
      "Epoch 136/300\n",
      "229/229 [==============================] - 0s 505us/step - loss: 0.6820 - val_loss: 0.6821\n",
      "Epoch 137/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6829 - val_loss: 0.6688\n",
      "Epoch 138/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6828 - val_loss: 0.6899\n",
      "Epoch 139/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6845 - val_loss: 0.7135\n",
      "Epoch 140/300\n",
      "229/229 [==============================] - 0s 577us/step - loss: 0.6830 - val_loss: 0.6889\n",
      "Epoch 141/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6830 - val_loss: 0.6792\n",
      "Epoch 142/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6804 - val_loss: 0.7014\n",
      "Epoch 143/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6856 - val_loss: 0.6880\n",
      "Epoch 144/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6844 - val_loss: 0.6871\n",
      "Epoch 145/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6828 - val_loss: 0.6949\n",
      "Epoch 146/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6832 - val_loss: 0.7187\n",
      "Epoch 147/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6827 - val_loss: 0.6760\n",
      "Epoch 148/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6831 - val_loss: 0.6823\n",
      "Epoch 149/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6831 - val_loss: 0.6911\n",
      "Epoch 150/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6837 - val_loss: 0.6755\n",
      "Epoch 151/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6837 - val_loss: 0.7127\n",
      "Epoch 152/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6816 - val_loss: 0.7027\n",
      "Epoch 153/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6822 - val_loss: 0.6745\n",
      "Epoch 154/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6835 - val_loss: 0.6828\n",
      "Epoch 155/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6812 - val_loss: 0.6885\n",
      "Epoch 156/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6828 - val_loss: 0.6829\n",
      "Epoch 157/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6812 - val_loss: 0.6776\n",
      "Epoch 158/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6834 - val_loss: 0.6782\n",
      "Epoch 159/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6836 - val_loss: 0.6862\n",
      "Epoch 160/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6818 - val_loss: 0.6827\n",
      "Epoch 161/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6808 - val_loss: 0.6986\n",
      "Epoch 162/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6830 - val_loss: 0.6663\n",
      "Epoch 163/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6827 - val_loss: 0.6839\n",
      "Epoch 164/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6821 - val_loss: 0.6940\n",
      "Epoch 165/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6804 - val_loss: 0.7024\n",
      "Epoch 166/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6857 - val_loss: 0.6863\n",
      "Epoch 167/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6826 - val_loss: 0.6902\n",
      "Epoch 168/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6839 - val_loss: 0.6840\n",
      "Epoch 169/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6840 - val_loss: 0.6827\n",
      "Epoch 170/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6832 - val_loss: 0.6749\n",
      "Epoch 171/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6822 - val_loss: 0.6824\n",
      "Epoch 172/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6827 - val_loss: 0.6788\n",
      "Epoch 173/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6826 - val_loss: 0.6868\n",
      "Epoch 174/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6833 - val_loss: 0.6877\n",
      "Epoch 175/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6795 - val_loss: 0.6962\n",
      "Epoch 176/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6816 - val_loss: 0.6889\n",
      "Epoch 177/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6823 - val_loss: 0.6831\n",
      "Epoch 178/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6830 - val_loss: 0.6961\n",
      "Epoch 179/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6822 - val_loss: 0.6797\n",
      "Epoch 180/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6821 - val_loss: 0.6889\n",
      "Epoch 181/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6831 - val_loss: 0.6725\n",
      "Epoch 182/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.6817 - val_loss: 0.6907\n",
      "Epoch 183/300\n",
      "229/229 [==============================] - 0s 500us/step - loss: 0.6806 - val_loss: 0.6751\n",
      "Epoch 184/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6823 - val_loss: 0.6747\n",
      "Epoch 185/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6823 - val_loss: 0.6883\n",
      "Epoch 186/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6808 - val_loss: 0.6749\n",
      "Epoch 187/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6823 - val_loss: 0.6836\n",
      "Epoch 188/300\n",
      "229/229 [==============================] - 0s 446us/step - loss: 0.6813 - val_loss: 0.6851\n",
      "Epoch 189/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6830 - val_loss: 0.6827\n",
      "Epoch 190/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6810 - val_loss: 0.6771\n",
      "Epoch 191/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6829 - val_loss: 0.6690\n",
      "Epoch 192/300\n",
      "229/229 [==============================] - 0s 509us/step - loss: 0.6819 - val_loss: 0.6885\n",
      "Epoch 193/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6813 - val_loss: 0.6787\n",
      "Epoch 194/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6818 - val_loss: 0.6759\n",
      "Epoch 195/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6821 - val_loss: 0.6918\n",
      "Epoch 196/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6823 - val_loss: 0.6904\n",
      "Epoch 197/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6781 - val_loss: 0.6908\n",
      "Epoch 198/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6816 - val_loss: 0.6838\n",
      "Epoch 199/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6845 - val_loss: 0.6767\n",
      "Epoch 200/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6815 - val_loss: 0.6831\n",
      "Epoch 201/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6823 - val_loss: 0.6750\n",
      "Epoch 202/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6817 - val_loss: 0.6808\n",
      "Epoch 203/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6810 - val_loss: 0.6916\n",
      "Epoch 204/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6793 - val_loss: 0.6907\n",
      "Epoch 205/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6821 - val_loss: 0.6741\n",
      "Epoch 206/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6823 - val_loss: 0.6912\n",
      "Epoch 207/300\n",
      "229/229 [==============================] - 0s 502us/step - loss: 0.6836 - val_loss: 0.6826\n",
      "Epoch 208/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6807 - val_loss: 0.7134\n",
      "Epoch 209/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6802 - val_loss: 0.6840\n",
      "Epoch 210/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6812 - val_loss: 0.7103\n",
      "Epoch 211/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6825 - val_loss: 0.6920\n",
      "Epoch 212/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6824 - val_loss: 0.6812\n",
      "Epoch 213/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6819 - val_loss: 0.6975\n",
      "Epoch 214/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6814 - val_loss: 0.6925\n",
      "Epoch 215/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6825 - val_loss: 0.6812\n",
      "Epoch 216/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6817 - val_loss: 0.6706\n",
      "Epoch 217/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6824 - val_loss: 0.7019\n",
      "Epoch 218/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6792 - val_loss: 0.7130\n",
      "Epoch 219/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6811 - val_loss: 0.6781\n",
      "Epoch 220/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6826 - val_loss: 0.6766\n",
      "Epoch 221/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6808 - val_loss: 0.6727\n",
      "Epoch 222/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6818 - val_loss: 0.6901\n",
      "Epoch 223/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6819 - val_loss: 0.6760\n",
      "Epoch 224/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6815 - val_loss: 0.6688\n",
      "Epoch 225/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6798 - val_loss: 0.6909\n",
      "Epoch 226/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6809 - val_loss: 0.6757\n",
      "Epoch 227/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6821 - val_loss: 0.6712\n",
      "Epoch 228/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6818 - val_loss: 0.6938\n",
      "Epoch 229/300\n",
      "229/229 [==============================] - 0s 459us/step - loss: 0.6825 - val_loss: 0.6714\n",
      "Epoch 230/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6811 - val_loss: 0.6826\n",
      "Epoch 231/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6797 - val_loss: 0.6921\n",
      "Epoch 232/300\n",
      "229/229 [==============================] - 0s 490us/step - loss: 0.6835 - val_loss: 0.6869\n",
      "Epoch 233/300\n",
      "229/229 [==============================] - 0s 476us/step - loss: 0.6828 - val_loss: 0.6740\n",
      "Epoch 234/300\n",
      "229/229 [==============================] - 0s 446us/step - loss: 0.6804 - val_loss: 0.6873\n",
      "Epoch 235/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6801 - val_loss: 0.6874\n",
      "Epoch 236/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6806 - val_loss: 0.6846\n",
      "Epoch 237/300\n",
      "229/229 [==============================] - 0s 432us/step - loss: 0.6800 - val_loss: 0.6748\n",
      "Epoch 238/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6812 - val_loss: 0.6813\n",
      "Epoch 239/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6828 - val_loss: 0.6701\n",
      "Epoch 240/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6829 - val_loss: 0.7074\n",
      "Epoch 241/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6817 - val_loss: 0.6709\n",
      "Epoch 242/300\n",
      "229/229 [==============================] - 0s 522us/step - loss: 0.6817 - val_loss: 0.6795\n",
      "Epoch 243/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6815 - val_loss: 0.6829\n",
      "Epoch 244/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6803 - val_loss: 0.6955\n",
      "Epoch 245/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6833 - val_loss: 0.6774\n",
      "Epoch 246/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6798 - val_loss: 0.6734\n",
      "Epoch 247/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6813 - val_loss: 0.6770\n",
      "Epoch 248/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6827 - val_loss: 0.6970\n",
      "Epoch 249/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6825 - val_loss: 0.6712\n",
      "Epoch 250/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6811 - val_loss: 0.6819\n",
      "Epoch 251/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6807 - val_loss: 0.7015\n",
      "Epoch 252/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6802 - val_loss: 0.6843\n",
      "Epoch 253/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6777 - val_loss: 0.6789\n",
      "Epoch 254/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6809 - val_loss: 0.6886\n",
      "Epoch 255/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6810 - val_loss: 0.6788\n",
      "Epoch 256/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6823 - val_loss: 0.6820\n",
      "Epoch 257/300\n",
      "229/229 [==============================] - 0s 434us/step - loss: 0.6808 - val_loss: 0.6857\n",
      "Epoch 258/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6804 - val_loss: 0.6886\n",
      "Epoch 259/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6805 - val_loss: 0.6990\n",
      "Epoch 260/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6803 - val_loss: 0.6877\n",
      "Epoch 261/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6809 - val_loss: 0.7078\n",
      "Epoch 262/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6802 - val_loss: 0.6883\n",
      "Epoch 263/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6824 - val_loss: 0.6816\n",
      "Epoch 264/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6817 - val_loss: 0.7028\n",
      "Epoch 265/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6810 - val_loss: 0.7082\n",
      "Epoch 266/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6809 - val_loss: 0.6801\n",
      "Epoch 267/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6799 - val_loss: 0.6756\n",
      "Epoch 268/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6791 - val_loss: 0.6816\n",
      "Epoch 269/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6801 - val_loss: 0.6803\n",
      "Epoch 270/300\n",
      "229/229 [==============================] - 0s 454us/step - loss: 0.6818 - val_loss: 0.6800\n",
      "Epoch 271/300\n",
      "229/229 [==============================] - 0s 469us/step - loss: 0.6777 - val_loss: 0.6988\n",
      "Epoch 272/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6816 - val_loss: 0.6841\n",
      "Epoch 273/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6822 - val_loss: 0.6749\n",
      "Epoch 274/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6783 - val_loss: 0.6781\n",
      "Epoch 275/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6812 - val_loss: 0.6816\n",
      "Epoch 276/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6812 - val_loss: 0.6836\n",
      "Epoch 277/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6841 - val_loss: 0.6782\n",
      "Epoch 278/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6817 - val_loss: 0.7037\n",
      "Epoch 279/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6827 - val_loss: 0.6760\n",
      "Epoch 280/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6800 - val_loss: 0.7076\n",
      "Epoch 281/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6810 - val_loss: 0.6891\n",
      "Epoch 282/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6813 - val_loss: 0.6746\n",
      "Epoch 283/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6818 - val_loss: 0.6924\n",
      "Epoch 284/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6816 - val_loss: 0.6906\n",
      "Epoch 285/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6804 - val_loss: 0.6873\n",
      "Epoch 286/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6805 - val_loss: 0.6747\n",
      "Epoch 287/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6782 - val_loss: 0.6772\n",
      "Epoch 288/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6807 - val_loss: 0.6831\n",
      "Epoch 289/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6814 - val_loss: 0.6669\n",
      "Epoch 290/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6799 - val_loss: 0.6850\n",
      "Epoch 291/300\n",
      "229/229 [==============================] - 0s 440us/step - loss: 0.6807 - val_loss: 0.7042\n",
      "Epoch 292/300\n",
      "229/229 [==============================] - 0s 687us/step - loss: 0.6795 - val_loss: 0.6700\n",
      "Epoch 293/300\n",
      "229/229 [==============================] - 0s 734us/step - loss: 0.6808 - val_loss: 0.6898\n",
      "Epoch 294/300\n",
      "229/229 [==============================] - 0s 955us/step - loss: 0.6800 - val_loss: 0.6849\n",
      "Epoch 295/300\n",
      "229/229 [==============================] - 0s 507us/step - loss: 0.6800 - val_loss: 0.6882\n",
      "Epoch 296/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6811 - val_loss: 0.6872\n",
      "Epoch 297/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6818 - val_loss: 0.6752\n",
      "Epoch 298/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6804 - val_loss: 0.6739\n",
      "Epoch 299/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6829 - val_loss: 0.6729\n",
      "Epoch 300/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6803 - val_loss: 0.6728\n",
      "26/26 [==============================] - 0s 335us/step\n",
      "Epoch 1/300\n",
      "229/229 [==============================] - 0s 597us/step - loss: 1.4583 - val_loss: 1.1016\n",
      "Epoch 2/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.9852 - val_loss: 0.9265\n",
      "Epoch 3/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.8837 - val_loss: 0.8821\n",
      "Epoch 4/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.8377 - val_loss: 0.8332\n",
      "Epoch 5/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.8085 - val_loss: 0.8199\n",
      "Epoch 6/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7887 - val_loss: 0.8126\n",
      "Epoch 7/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7734 - val_loss: 0.7704\n",
      "Epoch 8/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.7605 - val_loss: 0.7691\n",
      "Epoch 9/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.7506 - val_loss: 0.7532\n",
      "Epoch 10/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.7457 - val_loss: 0.7621\n",
      "Epoch 11/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.7403 - val_loss: 0.7504\n",
      "Epoch 12/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7307 - val_loss: 0.7352\n",
      "Epoch 13/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.7280 - val_loss: 0.7149\n",
      "Epoch 14/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.7256 - val_loss: 0.7385\n",
      "Epoch 15/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7193 - val_loss: 0.7204\n",
      "Epoch 16/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7176 - val_loss: 0.7292\n",
      "Epoch 17/300\n",
      "229/229 [==============================] - 0s 431us/step - loss: 0.7174 - val_loss: 0.7199\n",
      "Epoch 18/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.7128 - val_loss: 0.7274\n",
      "Epoch 19/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.7115 - val_loss: 0.7079\n",
      "Epoch 20/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.7099 - val_loss: 0.7159\n",
      "Epoch 21/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7053 - val_loss: 0.7064\n",
      "Epoch 22/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.7060 - val_loss: 0.7170\n",
      "Epoch 23/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7036 - val_loss: 0.6958\n",
      "Epoch 24/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.7038 - val_loss: 0.7219\n",
      "Epoch 25/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.7011 - val_loss: 0.7142\n",
      "Epoch 26/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.7007 - val_loss: 0.7066\n",
      "Epoch 27/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6968 - val_loss: 0.7073\n",
      "Epoch 28/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6982 - val_loss: 0.7083\n",
      "Epoch 29/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6987 - val_loss: 0.6995\n",
      "Epoch 30/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6973 - val_loss: 0.7048\n",
      "Epoch 31/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6972 - val_loss: 0.7112\n",
      "Epoch 32/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6954 - val_loss: 0.7097\n",
      "Epoch 33/300\n",
      "229/229 [==============================] - 0s 445us/step - loss: 0.6960 - val_loss: 0.7014\n",
      "Epoch 34/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6961 - val_loss: 0.7061\n",
      "Epoch 35/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6964 - val_loss: 0.7051\n",
      "Epoch 36/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6955 - val_loss: 0.7068\n",
      "Epoch 37/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6954 - val_loss: 0.6983\n",
      "Epoch 38/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6949 - val_loss: 0.7262\n",
      "Epoch 39/300\n",
      "229/229 [==============================] - 0s 528us/step - loss: 0.6955 - val_loss: 0.7011\n",
      "Epoch 40/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6927 - val_loss: 0.7039\n",
      "Epoch 41/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6962 - val_loss: 0.7119\n",
      "Epoch 42/300\n",
      "229/229 [==============================] - 0s 427us/step - loss: 0.6925 - val_loss: 0.7552\n",
      "Epoch 43/300\n",
      "229/229 [==============================] - 0s 557us/step - loss: 0.6930 - val_loss: 0.7070\n",
      "Epoch 44/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6906 - val_loss: 0.7031\n",
      "Epoch 45/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6935 - val_loss: 0.7071\n",
      "Epoch 46/300\n",
      "229/229 [==============================] - 0s 433us/step - loss: 0.6905 - val_loss: 0.6953\n",
      "Epoch 47/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6918 - val_loss: 0.6970\n",
      "Epoch 48/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6889 - val_loss: 0.6949\n",
      "Epoch 49/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6918 - val_loss: 0.7069\n",
      "Epoch 50/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6905 - val_loss: 0.7064\n",
      "Epoch 51/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6895 - val_loss: 0.7425\n",
      "Epoch 52/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6920 - val_loss: 0.7007\n",
      "Epoch 53/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6909 - val_loss: 0.7015\n",
      "Epoch 54/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6891 - val_loss: 0.7039\n",
      "Epoch 55/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6906 - val_loss: 0.7008\n",
      "Epoch 56/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6892 - val_loss: 0.7128\n",
      "Epoch 57/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6888 - val_loss: 0.7044\n",
      "Epoch 58/300\n",
      "229/229 [==============================] - 0s 423us/step - loss: 0.6888 - val_loss: 0.6978\n",
      "Epoch 59/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6888 - val_loss: 0.6938\n",
      "Epoch 60/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6884 - val_loss: 0.6957\n",
      "Epoch 61/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6898 - val_loss: 0.6918\n",
      "Epoch 62/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6861 - val_loss: 0.7026\n",
      "Epoch 63/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6884 - val_loss: 0.7032\n",
      "Epoch 64/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6891 - val_loss: 0.7064\n",
      "Epoch 65/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6861 - val_loss: 0.7090\n",
      "Epoch 66/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6890 - val_loss: 0.6972\n",
      "Epoch 67/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6870 - val_loss: 0.7008\n",
      "Epoch 68/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6883 - val_loss: 0.7022\n",
      "Epoch 69/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6870 - val_loss: 0.7143\n",
      "Epoch 70/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6867 - val_loss: 0.7081\n",
      "Epoch 71/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6869 - val_loss: 0.7138\n",
      "Epoch 72/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6885 - val_loss: 0.7027\n",
      "Epoch 73/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6862 - val_loss: 0.7142\n",
      "Epoch 74/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6860 - val_loss: 0.7127\n",
      "Epoch 75/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6882 - val_loss: 0.7168\n",
      "Epoch 76/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6867 - val_loss: 0.7077\n",
      "Epoch 77/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6873 - val_loss: 0.7036\n",
      "Epoch 78/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6858 - val_loss: 0.7012\n",
      "Epoch 79/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6876 - val_loss: 0.7052\n",
      "Epoch 80/300\n",
      "229/229 [==============================] - 0s 426us/step - loss: 0.6873 - val_loss: 0.7017\n",
      "Epoch 81/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6872 - val_loss: 0.7122\n",
      "Epoch 82/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6844 - val_loss: 0.7101\n",
      "Epoch 83/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6852 - val_loss: 0.7121\n",
      "Epoch 84/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6856 - val_loss: 0.7176\n",
      "Epoch 85/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6863 - val_loss: 0.6978\n",
      "Epoch 86/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6879 - val_loss: 0.6952\n",
      "Epoch 87/300\n",
      "229/229 [==============================] - 0s 429us/step - loss: 0.6874 - val_loss: 0.6946\n",
      "Epoch 88/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6844 - val_loss: 0.7018\n",
      "Epoch 89/300\n",
      "229/229 [==============================] - 0s 446us/step - loss: 0.6852 - val_loss: 0.7027\n",
      "Epoch 90/300\n",
      "229/229 [==============================] - 0s 450us/step - loss: 0.6855 - val_loss: 0.6908\n",
      "Epoch 91/300\n",
      "229/229 [==============================] - 0s 470us/step - loss: 0.6851 - val_loss: 0.7112\n",
      "Epoch 92/300\n",
      "229/229 [==============================] - 0s 410us/step - loss: 0.6861 - val_loss: 0.7074\n",
      "Epoch 93/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6843 - val_loss: 0.7188\n",
      "Epoch 94/300\n",
      "229/229 [==============================] - 0s 466us/step - loss: 0.6866 - val_loss: 0.6926\n",
      "Epoch 95/300\n",
      "229/229 [==============================] - 0s 437us/step - loss: 0.6857 - val_loss: 0.7132\n",
      "Epoch 96/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6845 - val_loss: 0.7079\n",
      "Epoch 97/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6851 - val_loss: 0.7033\n",
      "Epoch 98/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6857 - val_loss: 0.7277\n",
      "Epoch 99/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6832 - val_loss: 0.6994\n",
      "Epoch 100/300\n",
      "229/229 [==============================] - 0s 442us/step - loss: 0.6839 - val_loss: 0.6967\n",
      "Epoch 101/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6853 - val_loss: 0.7053\n",
      "Epoch 102/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6830 - val_loss: 0.7095\n",
      "Epoch 103/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6846 - val_loss: 0.6868\n",
      "Epoch 104/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6844 - val_loss: 0.7008\n",
      "Epoch 105/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6848 - val_loss: 0.7429\n",
      "Epoch 106/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6857 - val_loss: 0.7102\n",
      "Epoch 107/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6831 - val_loss: 0.7031\n",
      "Epoch 108/300\n",
      "229/229 [==============================] - 0s 435us/step - loss: 0.6867 - val_loss: 0.7079\n",
      "Epoch 109/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6816 - val_loss: 0.7057\n",
      "Epoch 110/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6838 - val_loss: 0.7241\n",
      "Epoch 111/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6839 - val_loss: 0.7007\n",
      "Epoch 112/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6844 - val_loss: 0.7059\n",
      "Epoch 113/300\n",
      "229/229 [==============================] - 0s 463us/step - loss: 0.6834 - val_loss: 0.6842\n",
      "Epoch 114/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6847 - val_loss: 0.6976\n",
      "Epoch 115/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6824 - val_loss: 0.7139\n",
      "Epoch 116/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6833 - val_loss: 0.6809\n",
      "Epoch 117/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6829 - val_loss: 0.7029\n",
      "Epoch 118/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6811 - val_loss: 0.6843\n",
      "Epoch 119/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6842 - val_loss: 0.6897\n",
      "Epoch 120/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6826 - val_loss: 0.7014\n",
      "Epoch 121/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6833 - val_loss: 0.6909\n",
      "Epoch 122/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6827 - val_loss: 0.7039\n",
      "Epoch 123/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6844 - val_loss: 0.6895\n",
      "Epoch 124/300\n",
      "229/229 [==============================] - 0s 439us/step - loss: 0.6835 - val_loss: 0.6905\n",
      "Epoch 125/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6847 - val_loss: 0.7013\n",
      "Epoch 126/300\n",
      "229/229 [==============================] - 0s 409us/step - loss: 0.6833 - val_loss: 0.6916\n",
      "Epoch 127/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6830 - val_loss: 0.7080\n",
      "Epoch 128/300\n",
      "229/229 [==============================] - 0s 424us/step - loss: 0.6811 - val_loss: 0.7033\n",
      "Epoch 129/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6840 - val_loss: 0.6992\n",
      "Epoch 130/300\n",
      "229/229 [==============================] - 0s 414us/step - loss: 0.6842 - val_loss: 0.6970\n",
      "Epoch 131/300\n",
      "229/229 [==============================] - 0s 444us/step - loss: 0.6832 - val_loss: 0.6992\n",
      "Epoch 132/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6844 - val_loss: 0.7231\n",
      "Epoch 133/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.6821 - val_loss: 0.7077\n",
      "Epoch 134/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6811 - val_loss: 0.6947\n",
      "Epoch 135/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6824 - val_loss: 0.6952\n",
      "Epoch 136/300\n",
      "229/229 [==============================] - 0s 409us/step - loss: 0.6816 - val_loss: 0.7048\n",
      "Epoch 137/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6822 - val_loss: 0.7087\n",
      "Epoch 138/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6815 - val_loss: 0.6980\n",
      "Epoch 139/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6819 - val_loss: 0.6999\n",
      "Epoch 140/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6820 - val_loss: 0.6958\n",
      "Epoch 141/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6816 - val_loss: 0.6868\n",
      "Epoch 142/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6820 - val_loss: 0.7223\n",
      "Epoch 143/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6826 - val_loss: 0.6934\n",
      "Epoch 144/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.6827 - val_loss: 0.6964\n",
      "Epoch 145/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6812 - val_loss: 0.7033\n",
      "Epoch 146/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6830 - val_loss: 0.6965\n",
      "Epoch 147/300\n",
      "229/229 [==============================] - 0s 369us/step - loss: 0.6836 - val_loss: 0.6997\n",
      "Epoch 148/300\n",
      "229/229 [==============================] - 0s 372us/step - loss: 0.6835 - val_loss: 0.6875\n",
      "Epoch 149/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6811 - val_loss: 0.6953\n",
      "Epoch 150/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6849 - val_loss: 0.7002\n",
      "Epoch 151/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.6827 - val_loss: 0.6972\n",
      "Epoch 152/300\n",
      "229/229 [==============================] - 0s 375us/step - loss: 0.6823 - val_loss: 0.6819\n",
      "Epoch 153/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6828 - val_loss: 0.6902\n",
      "Epoch 154/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6814 - val_loss: 0.7012\n",
      "Epoch 155/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6813 - val_loss: 0.6975\n",
      "Epoch 156/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6835 - val_loss: 0.6991\n",
      "Epoch 157/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6819 - val_loss: 0.7010\n",
      "Epoch 158/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6800 - val_loss: 0.7213\n",
      "Epoch 159/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6826 - val_loss: 0.7486\n",
      "Epoch 160/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6805 - val_loss: 0.7107\n",
      "Epoch 161/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6819 - val_loss: 0.7029\n",
      "Epoch 162/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6814 - val_loss: 0.6875\n",
      "Epoch 163/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6822 - val_loss: 0.7135\n",
      "Epoch 164/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6840 - val_loss: 0.6995\n",
      "Epoch 165/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6821 - val_loss: 0.6974\n",
      "Epoch 166/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.6808 - val_loss: 0.7097\n",
      "Epoch 167/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6820 - val_loss: 0.6935\n",
      "Epoch 168/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6827 - val_loss: 0.6886\n",
      "Epoch 169/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6825 - val_loss: 0.6971\n",
      "Epoch 170/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6803 - val_loss: 0.6991\n",
      "Epoch 171/300\n",
      "229/229 [==============================] - 0s 375us/step - loss: 0.6805 - val_loss: 0.7169\n",
      "Epoch 172/300\n",
      "229/229 [==============================] - 0s 377us/step - loss: 0.6804 - val_loss: 0.6983\n",
      "Epoch 173/300\n",
      "229/229 [==============================] - 0s 371us/step - loss: 0.6813 - val_loss: 0.6891\n",
      "Epoch 174/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6821 - val_loss: 0.7034\n",
      "Epoch 175/300\n",
      "229/229 [==============================] - 0s 372us/step - loss: 0.6824 - val_loss: 0.7204\n",
      "Epoch 176/300\n",
      "229/229 [==============================] - 0s 369us/step - loss: 0.6827 - val_loss: 0.6988\n",
      "Epoch 177/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6830 - val_loss: 0.6911\n",
      "Epoch 178/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6800 - val_loss: 0.7070\n",
      "Epoch 179/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6796 - val_loss: 0.7078\n",
      "Epoch 180/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6829 - val_loss: 0.7150\n",
      "Epoch 181/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.6799 - val_loss: 0.6996\n",
      "Epoch 182/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6804 - val_loss: 0.7065\n",
      "Epoch 183/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6803 - val_loss: 0.6971\n",
      "Epoch 184/300\n",
      "229/229 [==============================] - 0s 368us/step - loss: 0.6822 - val_loss: 0.6945\n",
      "Epoch 185/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.6812 - val_loss: 0.7040\n",
      "Epoch 186/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.6801 - val_loss: 0.6964\n",
      "Epoch 187/300\n",
      "229/229 [==============================] - 0s 368us/step - loss: 0.6807 - val_loss: 0.7073\n",
      "Epoch 188/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6805 - val_loss: 0.7018\n",
      "Epoch 189/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6820 - val_loss: 0.6911\n",
      "Epoch 190/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6823 - val_loss: 0.7124\n",
      "Epoch 191/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6754 - val_loss: 0.7020\n",
      "Epoch 192/300\n",
      "229/229 [==============================] - 0s 376us/step - loss: 0.6819 - val_loss: 0.6908\n",
      "Epoch 193/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6817 - val_loss: 0.6982\n",
      "Epoch 194/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6792 - val_loss: 0.7125\n",
      "Epoch 195/300\n",
      "229/229 [==============================] - 0s 368us/step - loss: 0.6815 - val_loss: 0.6912\n",
      "Epoch 196/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6803 - val_loss: 0.6908\n",
      "Epoch 197/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6825 - val_loss: 0.6842\n",
      "Epoch 198/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6804 - val_loss: 0.7179\n",
      "Epoch 199/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6822 - val_loss: 0.6893\n",
      "Epoch 200/300\n",
      "229/229 [==============================] - 0s 366us/step - loss: 0.6810 - val_loss: 0.6926\n",
      "Epoch 201/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6821 - val_loss: 0.6945\n",
      "Epoch 202/300\n",
      "229/229 [==============================] - 0s 402us/step - loss: 0.6802 - val_loss: 0.7129\n",
      "Epoch 203/300\n",
      "229/229 [==============================] - 0s 371us/step - loss: 0.6808 - val_loss: 0.7063\n",
      "Epoch 204/300\n",
      "229/229 [==============================] - 0s 371us/step - loss: 0.6796 - val_loss: 0.7007\n",
      "Epoch 205/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6822 - val_loss: 0.7293\n",
      "Epoch 206/300\n",
      "229/229 [==============================] - 0s 370us/step - loss: 0.6827 - val_loss: 0.7092\n",
      "Epoch 207/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6804 - val_loss: 0.7004\n",
      "Epoch 208/300\n",
      "229/229 [==============================] - 0s 367us/step - loss: 0.6811 - val_loss: 0.6980\n",
      "Epoch 209/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6808 - val_loss: 0.7007\n",
      "Epoch 210/300\n",
      "229/229 [==============================] - 0s 376us/step - loss: 0.6798 - val_loss: 0.6890\n",
      "Epoch 211/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6794 - val_loss: 0.7069\n",
      "Epoch 212/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6819 - val_loss: 0.6924\n",
      "Epoch 213/300\n",
      "229/229 [==============================] - 0s 371us/step - loss: 0.6798 - val_loss: 0.7019\n",
      "Epoch 214/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6804 - val_loss: 0.7107\n",
      "Epoch 215/300\n",
      "229/229 [==============================] - 0s 375us/step - loss: 0.6796 - val_loss: 0.7114\n",
      "Epoch 216/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6814 - val_loss: 0.7087\n",
      "Epoch 217/300\n",
      "229/229 [==============================] - 0s 422us/step - loss: 0.6800 - val_loss: 0.7129\n",
      "Epoch 218/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6806 - val_loss: 0.7021\n",
      "Epoch 219/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6827 - val_loss: 0.6999\n",
      "Epoch 220/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.6806 - val_loss: 0.6934\n",
      "Epoch 221/300\n",
      "229/229 [==============================] - 0s 371us/step - loss: 0.6807 - val_loss: 0.6953\n",
      "Epoch 222/300\n",
      "229/229 [==============================] - 0s 371us/step - loss: 0.6798 - val_loss: 0.6875\n",
      "Epoch 223/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6815 - val_loss: 0.6930\n",
      "Epoch 224/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6809 - val_loss: 0.7086\n",
      "Epoch 225/300\n",
      "229/229 [==============================] - 0s 371us/step - loss: 0.6796 - val_loss: 0.7009\n",
      "Epoch 226/300\n",
      "229/229 [==============================] - 0s 366us/step - loss: 0.6798 - val_loss: 0.7095\n",
      "Epoch 227/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6802 - val_loss: 0.7123\n",
      "Epoch 228/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6811 - val_loss: 0.7015\n",
      "Epoch 229/300\n",
      "229/229 [==============================] - 0s 377us/step - loss: 0.6810 - val_loss: 0.7080\n",
      "Epoch 230/300\n",
      "229/229 [==============================] - 0s 369us/step - loss: 0.6811 - val_loss: 0.7179\n",
      "Epoch 231/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6813 - val_loss: 0.7038\n",
      "Epoch 232/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6807 - val_loss: 0.6968\n",
      "Epoch 233/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6807 - val_loss: 0.6934\n",
      "Epoch 234/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.6773 - val_loss: 0.7151\n",
      "Epoch 235/300\n",
      "229/229 [==============================] - 0s 370us/step - loss: 0.6801 - val_loss: 0.7038\n",
      "Epoch 236/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6817 - val_loss: 0.7001\n",
      "Epoch 237/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6803 - val_loss: 0.7006\n",
      "Epoch 238/300\n",
      "229/229 [==============================] - 0s 376us/step - loss: 0.6820 - val_loss: 0.6989\n",
      "Epoch 239/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6826 - val_loss: 0.6819\n",
      "Epoch 240/300\n",
      "229/229 [==============================] - 0s 375us/step - loss: 0.6792 - val_loss: 0.6972\n",
      "Epoch 241/300\n",
      "229/229 [==============================] - 0s 368us/step - loss: 0.6804 - val_loss: 0.7419\n",
      "Epoch 242/300\n",
      "229/229 [==============================] - 0s 399us/step - loss: 0.6802 - val_loss: 0.7024\n",
      "Epoch 243/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6789 - val_loss: 0.7335\n",
      "Epoch 244/300\n",
      "229/229 [==============================] - 0s 402us/step - loss: 0.6804 - val_loss: 0.6825\n",
      "Epoch 245/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6801 - val_loss: 0.6958\n",
      "Epoch 246/300\n",
      "229/229 [==============================] - 0s 376us/step - loss: 0.6779 - val_loss: 0.7055\n",
      "Epoch 247/300\n",
      "229/229 [==============================] - 0s 370us/step - loss: 0.6807 - val_loss: 0.7021\n",
      "Epoch 248/300\n",
      "229/229 [==============================] - 0s 371us/step - loss: 0.6821 - val_loss: 0.6967\n",
      "Epoch 249/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6807 - val_loss: 0.7030\n",
      "Epoch 250/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6825 - val_loss: 0.6917\n",
      "Epoch 251/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6811 - val_loss: 0.6981\n",
      "Epoch 252/300\n",
      "229/229 [==============================] - 0s 377us/step - loss: 0.6795 - val_loss: 0.7028\n",
      "Epoch 253/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6778 - val_loss: 0.7333\n",
      "Epoch 254/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6814 - val_loss: 0.7259\n",
      "Epoch 255/300\n",
      "229/229 [==============================] - 0s 371us/step - loss: 0.6799 - val_loss: 0.6885\n",
      "Epoch 256/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6803 - val_loss: 0.6923\n",
      "Epoch 257/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6788 - val_loss: 0.7115\n",
      "Epoch 258/300\n",
      "229/229 [==============================] - 0s 377us/step - loss: 0.6826 - val_loss: 0.6959\n",
      "Epoch 259/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.6798 - val_loss: 0.6912\n",
      "Epoch 260/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6814 - val_loss: 0.6875\n",
      "Epoch 261/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6786 - val_loss: 0.6865\n",
      "Epoch 262/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6802 - val_loss: 0.6905\n",
      "Epoch 263/300\n",
      "229/229 [==============================] - 0s 377us/step - loss: 0.6777 - val_loss: 0.6983\n",
      "Epoch 264/300\n",
      "229/229 [==============================] - 0s 372us/step - loss: 0.6810 - val_loss: 0.6931\n",
      "Epoch 265/300\n",
      "229/229 [==============================] - 0s 367us/step - loss: 0.6813 - val_loss: 0.6915\n",
      "Epoch 266/300\n",
      "229/229 [==============================] - 0s 376us/step - loss: 0.6794 - val_loss: 0.6799\n",
      "Epoch 267/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6795 - val_loss: 0.6771\n",
      "Epoch 268/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6793 - val_loss: 0.6905\n",
      "Epoch 269/300\n",
      "229/229 [==============================] - 0s 375us/step - loss: 0.6782 - val_loss: 0.6930\n",
      "Epoch 270/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6811 - val_loss: 0.7055\n",
      "Epoch 271/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6797 - val_loss: 0.7025\n",
      "Epoch 272/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6808 - val_loss: 0.7066\n",
      "Epoch 273/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.6816 - val_loss: 0.7004\n",
      "Epoch 274/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6794 - val_loss: 0.6895\n",
      "Epoch 275/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.6815 - val_loss: 0.7024\n",
      "Epoch 276/300\n",
      "229/229 [==============================] - 0s 399us/step - loss: 0.6805 - val_loss: 0.7063\n",
      "Epoch 277/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6803 - val_loss: 0.6979\n",
      "Epoch 278/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.6823 - val_loss: 0.7006\n",
      "Epoch 279/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.6785 - val_loss: 0.7047\n",
      "Epoch 280/300\n",
      "229/229 [==============================] - 0s 430us/step - loss: 0.6791 - val_loss: 0.7195\n",
      "Epoch 281/300\n",
      "229/229 [==============================] - 0s 400us/step - loss: 0.6796 - val_loss: 0.6953\n",
      "Epoch 282/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6780 - val_loss: 0.6965\n",
      "Epoch 283/300\n",
      "229/229 [==============================] - 0s 407us/step - loss: 0.6820 - val_loss: 0.7000\n",
      "Epoch 284/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6791 - val_loss: 0.7047\n",
      "Epoch 285/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6809 - val_loss: 0.6913\n",
      "Epoch 286/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6802 - val_loss: 0.7088\n",
      "Epoch 287/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6820 - val_loss: 0.6985\n",
      "Epoch 288/300\n",
      "229/229 [==============================] - 0s 461us/step - loss: 0.6796 - val_loss: 0.6891\n",
      "Epoch 289/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6817 - val_loss: 0.6936\n",
      "Epoch 290/300\n",
      "229/229 [==============================] - 0s 377us/step - loss: 0.6793 - val_loss: 0.6966\n",
      "Epoch 291/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6819 - val_loss: 0.7023\n",
      "Epoch 292/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6824 - val_loss: 0.6944\n",
      "Epoch 293/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6781 - val_loss: 0.7151\n",
      "Epoch 294/300\n",
      "229/229 [==============================] - 0s 377us/step - loss: 0.6815 - val_loss: 0.7101\n",
      "Epoch 295/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6827 - val_loss: 0.6924\n",
      "Epoch 296/300\n",
      "229/229 [==============================] - 0s 375us/step - loss: 0.6811 - val_loss: 0.6994\n",
      "Epoch 297/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6792 - val_loss: 0.7058\n",
      "Epoch 298/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6817 - val_loss: 0.6878\n",
      "Epoch 299/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6802 - val_loss: 0.7099\n",
      "Epoch 300/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6789 - val_loss: 0.6995\n",
      "26/26 [==============================] - 0s 332us/step\n",
      "Epoch 1/300\n",
      "229/229 [==============================] - 0s 567us/step - loss: 1.5284 - val_loss: 1.1525\n",
      "Epoch 2/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 1.0113 - val_loss: 0.9342\n",
      "Epoch 3/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.8878 - val_loss: 0.8746\n",
      "Epoch 4/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.8384 - val_loss: 0.8455\n",
      "Epoch 5/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.8068 - val_loss: 0.8076\n",
      "Epoch 6/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.7865 - val_loss: 0.7952\n",
      "Epoch 7/300\n",
      "229/229 [==============================] - 0s 375us/step - loss: 0.7744 - val_loss: 0.7885\n",
      "Epoch 8/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.7628 - val_loss: 0.7835\n",
      "Epoch 9/300\n",
      "229/229 [==============================] - 0s 418us/step - loss: 0.7515 - val_loss: 0.7688\n",
      "Epoch 10/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.7459 - val_loss: 0.7576\n",
      "Epoch 11/300\n",
      "229/229 [==============================] - 0s 373us/step - loss: 0.7390 - val_loss: 0.7657\n",
      "Epoch 12/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.7351 - val_loss: 0.7445\n",
      "Epoch 13/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.7300 - val_loss: 0.7373\n",
      "Epoch 14/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.7260 - val_loss: 0.7310\n",
      "Epoch 15/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.7227 - val_loss: 0.7277\n",
      "Epoch 16/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.7205 - val_loss: 0.7290\n",
      "Epoch 17/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.7158 - val_loss: 0.7378\n",
      "Epoch 18/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.7147 - val_loss: 0.7165\n",
      "Epoch 19/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.7125 - val_loss: 0.7333\n",
      "Epoch 20/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.7082 - val_loss: 0.7363\n",
      "Epoch 21/300\n",
      "229/229 [==============================] - 0s 403us/step - loss: 0.7069 - val_loss: 0.7226\n",
      "Epoch 22/300\n",
      "229/229 [==============================] - 0s 401us/step - loss: 0.7045 - val_loss: 0.7255\n",
      "Epoch 23/300\n",
      "229/229 [==============================] - 0s 419us/step - loss: 0.7042 - val_loss: 0.7160\n",
      "Epoch 24/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.7031 - val_loss: 0.7264\n",
      "Epoch 25/300\n",
      "229/229 [==============================] - 0s 406us/step - loss: 0.7013 - val_loss: 0.7172\n",
      "Epoch 26/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.7002 - val_loss: 0.7302\n",
      "Epoch 27/300\n",
      "229/229 [==============================] - 0s 376us/step - loss: 0.7013 - val_loss: 0.7182\n",
      "Epoch 28/300\n",
      "229/229 [==============================] - 0s 405us/step - loss: 0.6965 - val_loss: 0.7219\n",
      "Epoch 29/300\n",
      "229/229 [==============================] - 0s 405us/step - loss: 0.6979 - val_loss: 0.7188\n",
      "Epoch 30/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6955 - val_loss: 0.7189\n",
      "Epoch 31/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6961 - val_loss: 0.7203\n",
      "Epoch 32/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6933 - val_loss: 0.7270\n",
      "Epoch 33/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6955 - val_loss: 0.7142\n",
      "Epoch 34/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6953 - val_loss: 0.7140\n",
      "Epoch 35/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6944 - val_loss: 0.7196\n",
      "Epoch 36/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6949 - val_loss: 0.7197\n",
      "Epoch 37/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6925 - val_loss: 0.7352\n",
      "Epoch 38/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6928 - val_loss: 0.7134\n",
      "Epoch 39/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6937 - val_loss: 0.7353\n",
      "Epoch 40/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6913 - val_loss: 0.7356\n",
      "Epoch 41/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6904 - val_loss: 0.7189\n",
      "Epoch 42/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6920 - val_loss: 0.7132\n",
      "Epoch 43/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6924 - val_loss: 0.7302\n",
      "Epoch 44/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6906 - val_loss: 0.7241\n",
      "Epoch 45/300\n",
      "229/229 [==============================] - 0s 890us/step - loss: 0.6908 - val_loss: 0.7278\n",
      "Epoch 46/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6901 - val_loss: 0.7261\n",
      "Epoch 47/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6903 - val_loss: 0.7329\n",
      "Epoch 48/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6911 - val_loss: 0.7369\n",
      "Epoch 49/300\n",
      "229/229 [==============================] - 0s 377us/step - loss: 0.6922 - val_loss: 0.7303\n",
      "Epoch 50/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6887 - val_loss: 0.7392\n",
      "Epoch 51/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6880 - val_loss: 0.7243\n",
      "Epoch 52/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6881 - val_loss: 0.7273\n",
      "Epoch 53/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6897 - val_loss: 0.7328\n",
      "Epoch 54/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6906 - val_loss: 0.7303\n",
      "Epoch 55/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6870 - val_loss: 0.7294\n",
      "Epoch 56/300\n",
      "229/229 [==============================] - 0s 375us/step - loss: 0.6885 - val_loss: 0.7289\n",
      "Epoch 57/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6904 - val_loss: 0.7413\n",
      "Epoch 58/300\n",
      "229/229 [==============================] - 0s 376us/step - loss: 0.6866 - val_loss: 0.7117\n",
      "Epoch 59/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6897 - val_loss: 0.7490\n",
      "Epoch 60/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6891 - val_loss: 0.7356\n",
      "Epoch 61/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6874 - val_loss: 0.7373\n",
      "Epoch 62/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6890 - val_loss: 0.7284\n",
      "Epoch 63/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6878 - val_loss: 0.7285\n",
      "Epoch 64/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6878 - val_loss: 0.7221\n",
      "Epoch 65/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6878 - val_loss: 0.7271\n",
      "Epoch 66/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6868 - val_loss: 0.7319\n",
      "Epoch 67/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6866 - val_loss: 0.7240\n",
      "Epoch 68/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6860 - val_loss: 0.7248\n",
      "Epoch 69/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6870 - val_loss: 0.7141\n",
      "Epoch 70/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6860 - val_loss: 0.7199\n",
      "Epoch 71/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6846 - val_loss: 0.7273\n",
      "Epoch 72/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6865 - val_loss: 0.7215\n",
      "Epoch 73/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6880 - val_loss: 0.7172\n",
      "Epoch 74/300\n",
      "229/229 [==============================] - 0s 402us/step - loss: 0.6869 - val_loss: 0.7185\n",
      "Epoch 75/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6834 - val_loss: 0.7142\n",
      "Epoch 76/300\n",
      "229/229 [==============================] - 0s 375us/step - loss: 0.6858 - val_loss: 0.7088\n",
      "Epoch 77/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6852 - val_loss: 0.7359\n",
      "Epoch 78/300\n",
      "229/229 [==============================] - 0s 401us/step - loss: 0.6855 - val_loss: 0.7173\n",
      "Epoch 79/300\n",
      "229/229 [==============================] - 0s 438us/step - loss: 0.6849 - val_loss: 0.7124\n",
      "Epoch 80/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6855 - val_loss: 0.7225\n",
      "Epoch 81/300\n",
      "229/229 [==============================] - 0s 410us/step - loss: 0.6862 - val_loss: 0.7228\n",
      "Epoch 82/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6867 - val_loss: 0.7313\n",
      "Epoch 83/300\n",
      "229/229 [==============================] - 0s 502us/step - loss: 0.6880 - val_loss: 0.7472\n",
      "Epoch 84/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6857 - val_loss: 0.7285\n",
      "Epoch 85/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6861 - val_loss: 0.7206\n",
      "Epoch 86/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6847 - val_loss: 0.7068\n",
      "Epoch 87/300\n",
      "229/229 [==============================] - 0s 399us/step - loss: 0.6847 - val_loss: 0.7028\n",
      "Epoch 88/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6838 - val_loss: 0.7274\n",
      "Epoch 89/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6838 - val_loss: 0.7174\n",
      "Epoch 90/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6836 - val_loss: 0.7555\n",
      "Epoch 91/300\n",
      "229/229 [==============================] - 0s 412us/step - loss: 0.6859 - val_loss: 0.7199\n",
      "Epoch 92/300\n",
      "229/229 [==============================] - 0s 405us/step - loss: 0.6861 - val_loss: 0.7143\n",
      "Epoch 93/300\n",
      "229/229 [==============================] - 0s 406us/step - loss: 0.6845 - val_loss: 0.7339\n",
      "Epoch 94/300\n",
      "229/229 [==============================] - 0s 413us/step - loss: 0.6832 - val_loss: 0.7162\n",
      "Epoch 95/300\n",
      "229/229 [==============================] - 0s 400us/step - loss: 0.6831 - val_loss: 0.7136\n",
      "Epoch 96/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6850 - val_loss: 0.7091\n",
      "Epoch 97/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6837 - val_loss: 0.7279\n",
      "Epoch 98/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6859 - val_loss: 0.7087\n",
      "Epoch 99/300\n",
      "229/229 [==============================] - 0s 377us/step - loss: 0.6830 - val_loss: 0.7407\n",
      "Epoch 100/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6853 - val_loss: 0.7104\n",
      "Epoch 101/300\n",
      "229/229 [==============================] - 0s 376us/step - loss: 0.6842 - val_loss: 0.7122\n",
      "Epoch 102/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6824 - val_loss: 0.7124\n",
      "Epoch 103/300\n",
      "229/229 [==============================] - 0s 376us/step - loss: 0.6843 - val_loss: 0.7194\n",
      "Epoch 104/300\n",
      "229/229 [==============================] - 0s 401us/step - loss: 0.6831 - val_loss: 0.7047\n",
      "Epoch 105/300\n",
      "229/229 [==============================] - 0s 445us/step - loss: 0.6848 - val_loss: 0.7114\n",
      "Epoch 106/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6825 - val_loss: 0.7302\n",
      "Epoch 107/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6838 - val_loss: 0.7367\n",
      "Epoch 108/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6829 - val_loss: 0.7179\n",
      "Epoch 109/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6835 - val_loss: 0.7319\n",
      "Epoch 110/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6812 - val_loss: 0.7116\n",
      "Epoch 111/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6824 - val_loss: 0.7170\n",
      "Epoch 112/300\n",
      "229/229 [==============================] - 0s 403us/step - loss: 0.6825 - val_loss: 0.7277\n",
      "Epoch 113/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6832 - val_loss: 0.7069\n",
      "Epoch 114/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6831 - val_loss: 0.7137\n",
      "Epoch 115/300\n",
      "229/229 [==============================] - 0s 405us/step - loss: 0.6823 - val_loss: 0.7192\n",
      "Epoch 116/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6829 - val_loss: 0.7280\n",
      "Epoch 117/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6822 - val_loss: 0.7593\n",
      "Epoch 118/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6840 - val_loss: 0.7316\n",
      "Epoch 119/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6827 - val_loss: 0.7220\n",
      "Epoch 120/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6821 - val_loss: 0.7186\n",
      "Epoch 121/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6821 - val_loss: 0.7303\n",
      "Epoch 122/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6830 - val_loss: 0.7476\n",
      "Epoch 123/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6833 - val_loss: 0.7137\n",
      "Epoch 124/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6802 - val_loss: 0.7440\n",
      "Epoch 125/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6815 - val_loss: 0.7469\n",
      "Epoch 126/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6844 - val_loss: 0.7173\n",
      "Epoch 127/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6813 - val_loss: 0.7167\n",
      "Epoch 128/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6830 - val_loss: 0.7212\n",
      "Epoch 129/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6822 - val_loss: 0.7181\n",
      "Epoch 130/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6814 - val_loss: 0.7267\n",
      "Epoch 131/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6812 - val_loss: 0.7223\n",
      "Epoch 132/300\n",
      "229/229 [==============================] - 0s 377us/step - loss: 0.6824 - val_loss: 0.7195\n",
      "Epoch 133/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6831 - val_loss: 0.7195\n",
      "Epoch 134/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6843 - val_loss: 0.7423\n",
      "Epoch 135/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6825 - val_loss: 0.7222\n",
      "Epoch 136/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6825 - val_loss: 0.7163\n",
      "Epoch 137/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6813 - val_loss: 0.7286\n",
      "Epoch 138/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6819 - val_loss: 0.7152\n",
      "Epoch 139/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6799 - val_loss: 0.7275\n",
      "Epoch 140/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6816 - val_loss: 0.7039\n",
      "Epoch 141/300\n",
      "229/229 [==============================] - 0s 400us/step - loss: 0.6819 - val_loss: 0.7165\n",
      "Epoch 142/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6817 - val_loss: 0.7114\n",
      "Epoch 143/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6808 - val_loss: 0.7133\n",
      "Epoch 144/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6812 - val_loss: 0.7051\n",
      "Epoch 145/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6813 - val_loss: 0.7122\n",
      "Epoch 146/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6794 - val_loss: 0.7076\n",
      "Epoch 147/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6816 - val_loss: 0.7298\n",
      "Epoch 148/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6829 - val_loss: 0.7029\n",
      "Epoch 149/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6823 - val_loss: 0.7256\n",
      "Epoch 150/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6815 - val_loss: 0.7106\n",
      "Epoch 151/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6811 - val_loss: 0.7157\n",
      "Epoch 152/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6808 - val_loss: 0.7217\n",
      "Epoch 153/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6789 - val_loss: 0.7137\n",
      "Epoch 154/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6825 - val_loss: 0.7173\n",
      "Epoch 155/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6813 - val_loss: 0.7084\n",
      "Epoch 156/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6825 - val_loss: 0.7053\n",
      "Epoch 157/300\n",
      "229/229 [==============================] - 0s 380us/step - loss: 0.6821 - val_loss: 0.7058\n",
      "Epoch 158/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6801 - val_loss: 0.7351\n",
      "Epoch 159/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6818 - val_loss: 0.7090\n",
      "Epoch 160/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6810 - val_loss: 0.7100\n",
      "Epoch 161/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6815 - val_loss: 0.7223\n",
      "Epoch 162/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6818 - val_loss: 0.7193\n",
      "Epoch 163/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6804 - val_loss: 0.7173\n",
      "Epoch 164/300\n",
      "229/229 [==============================] - 0s 420us/step - loss: 0.6811 - val_loss: 0.7165\n",
      "Epoch 165/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6821 - val_loss: 0.7180\n",
      "Epoch 166/300\n",
      "229/229 [==============================] - 0s 401us/step - loss: 0.6826 - val_loss: 0.7165\n",
      "Epoch 167/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6809 - val_loss: 0.7185\n",
      "Epoch 168/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6812 - val_loss: 0.7092\n",
      "Epoch 169/300\n",
      "229/229 [==============================] - 0s 377us/step - loss: 0.6821 - val_loss: 0.7170\n",
      "Epoch 170/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6810 - val_loss: 0.7127\n",
      "Epoch 171/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6807 - val_loss: 0.7181\n",
      "Epoch 172/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6799 - val_loss: 0.7045\n",
      "Epoch 173/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6831 - val_loss: 0.7125\n",
      "Epoch 174/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6814 - val_loss: 0.7239\n",
      "Epoch 175/300\n",
      "229/229 [==============================] - 0s 447us/step - loss: 0.6817 - val_loss: 0.7161\n",
      "Epoch 176/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6804 - val_loss: 0.7140\n",
      "Epoch 177/300\n",
      "229/229 [==============================] - 0s 400us/step - loss: 0.6812 - val_loss: 0.7113\n",
      "Epoch 178/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6810 - val_loss: 0.7250\n",
      "Epoch 179/300\n",
      "229/229 [==============================] - 0s 369us/step - loss: 0.6782 - val_loss: 0.7391\n",
      "Epoch 180/300\n",
      "229/229 [==============================] - 0s 367us/step - loss: 0.6814 - val_loss: 0.7101\n",
      "Epoch 181/300\n",
      "229/229 [==============================] - 0s 366us/step - loss: 0.6798 - val_loss: 0.7292\n",
      "Epoch 182/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6823 - val_loss: 0.7156\n",
      "Epoch 183/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6819 - val_loss: 0.7245\n",
      "Epoch 184/300\n",
      "229/229 [==============================] - 0s 400us/step - loss: 0.6811 - val_loss: 0.7017\n",
      "Epoch 185/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6808 - val_loss: 0.7269\n",
      "Epoch 186/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6788 - val_loss: 0.7089\n",
      "Epoch 187/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6811 - val_loss: 0.7085\n",
      "Epoch 188/300\n",
      "229/229 [==============================] - 0s 379us/step - loss: 0.6814 - val_loss: 0.7119\n",
      "Epoch 189/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6798 - val_loss: 0.7244\n",
      "Epoch 190/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6833 - val_loss: 0.7106\n",
      "Epoch 191/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6792 - val_loss: 0.7179\n",
      "Epoch 192/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6803 - val_loss: 0.7079\n",
      "Epoch 193/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6807 - val_loss: 0.7041\n",
      "Epoch 194/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6795 - val_loss: 0.7235\n",
      "Epoch 195/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6801 - val_loss: 0.7292\n",
      "Epoch 196/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6796 - val_loss: 0.7286\n",
      "Epoch 197/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6798 - val_loss: 0.7066\n",
      "Epoch 198/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6813 - val_loss: 0.7090\n",
      "Epoch 199/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6797 - val_loss: 0.7379\n",
      "Epoch 200/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6792 - val_loss: 0.7254\n",
      "Epoch 201/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6790 - val_loss: 0.7383\n",
      "Epoch 202/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6817 - val_loss: 0.7202\n",
      "Epoch 203/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6794 - val_loss: 0.7105\n",
      "Epoch 204/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6802 - val_loss: 0.7179\n",
      "Epoch 205/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6800 - val_loss: 0.7306\n",
      "Epoch 206/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6788 - val_loss: 0.7135\n",
      "Epoch 207/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6786 - val_loss: 0.7258\n",
      "Epoch 208/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6795 - val_loss: 0.7049\n",
      "Epoch 209/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6798 - val_loss: 0.7198\n",
      "Epoch 210/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6796 - val_loss: 0.7111\n",
      "Epoch 211/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6802 - val_loss: 0.7114\n",
      "Epoch 212/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6806 - val_loss: 0.7185\n",
      "Epoch 213/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6815 - val_loss: 0.7184\n",
      "Epoch 214/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6808 - val_loss: 0.7247\n",
      "Epoch 215/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6796 - val_loss: 0.7335\n",
      "Epoch 216/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6806 - val_loss: 0.7115\n",
      "Epoch 217/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6798 - val_loss: 0.7046\n",
      "Epoch 218/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6811 - val_loss: 0.7067\n",
      "Epoch 219/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6789 - val_loss: 0.7160\n",
      "Epoch 220/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6797 - val_loss: 0.7259\n",
      "Epoch 221/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6806 - val_loss: 0.7213\n",
      "Epoch 222/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6799 - val_loss: 0.7226\n",
      "Epoch 223/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6790 - val_loss: 0.7149\n",
      "Epoch 224/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6797 - val_loss: 0.7094\n",
      "Epoch 225/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6779 - val_loss: 0.7445\n",
      "Epoch 226/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6823 - val_loss: 0.7093\n",
      "Epoch 227/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6806 - val_loss: 0.7108\n",
      "Epoch 228/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6814 - val_loss: 0.7171\n",
      "Epoch 229/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6777 - val_loss: 0.7314\n",
      "Epoch 230/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6792 - val_loss: 0.7133\n",
      "Epoch 231/300\n",
      "229/229 [==============================] - 0s 378us/step - loss: 0.6801 - val_loss: 0.7239\n",
      "Epoch 232/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6801 - val_loss: 0.7224\n",
      "Epoch 233/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6802 - val_loss: 0.7226\n",
      "Epoch 234/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6783 - val_loss: 0.7125\n",
      "Epoch 235/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6789 - val_loss: 0.7260\n",
      "Epoch 236/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6782 - val_loss: 0.7544\n",
      "Epoch 237/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6818 - val_loss: 0.7040\n",
      "Epoch 238/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6767 - val_loss: 0.7211\n",
      "Epoch 239/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6801 - val_loss: 0.7477\n",
      "Epoch 240/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6793 - val_loss: 0.7221\n",
      "Epoch 241/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6775 - val_loss: 0.7175\n",
      "Epoch 242/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6795 - val_loss: 0.7161\n",
      "Epoch 243/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6792 - val_loss: 0.7162\n",
      "Epoch 244/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6815 - val_loss: 0.7203\n",
      "Epoch 245/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6775 - val_loss: 0.7180\n",
      "Epoch 246/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6807 - val_loss: 0.7172\n",
      "Epoch 247/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6795 - val_loss: 0.7210\n",
      "Epoch 248/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6780 - val_loss: 0.7149\n",
      "Epoch 249/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6785 - val_loss: 0.7132\n",
      "Epoch 250/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6776 - val_loss: 0.7257\n",
      "Epoch 251/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6786 - val_loss: 0.7123\n",
      "Epoch 252/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6785 - val_loss: 0.7113\n",
      "Epoch 253/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6780 - val_loss: 0.7130\n",
      "Epoch 254/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6804 - val_loss: 0.6974\n",
      "Epoch 255/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6785 - val_loss: 0.7141\n",
      "Epoch 256/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6776 - val_loss: 0.7189\n",
      "Epoch 257/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6808 - val_loss: 0.7200\n",
      "Epoch 258/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6786 - val_loss: 0.7229\n",
      "Epoch 259/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6808 - val_loss: 0.7083\n",
      "Epoch 260/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6811 - val_loss: 0.7238\n",
      "Epoch 261/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6801 - val_loss: 0.7118\n",
      "Epoch 262/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6776 - val_loss: 0.7181\n",
      "Epoch 263/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6812 - val_loss: 0.7193\n",
      "Epoch 264/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6770 - val_loss: 0.7259\n",
      "Epoch 265/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6802 - val_loss: 0.7103\n",
      "Epoch 266/300\n",
      "229/229 [==============================] - 0s 374us/step - loss: 0.6787 - val_loss: 0.7187\n",
      "Epoch 267/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6790 - val_loss: 0.7075\n",
      "Epoch 268/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6815 - val_loss: 0.7136\n",
      "Epoch 269/300\n",
      "229/229 [==============================] - 0s 381us/step - loss: 0.6805 - val_loss: 0.7067\n",
      "Epoch 270/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6784 - val_loss: 0.7126\n",
      "Epoch 271/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6775 - val_loss: 0.7204\n",
      "Epoch 272/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6784 - val_loss: 0.7325\n",
      "Epoch 273/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6818 - val_loss: 0.7265\n",
      "Epoch 274/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6786 - val_loss: 0.7167\n",
      "Epoch 275/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6781 - val_loss: 0.7167\n",
      "Epoch 276/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6791 - val_loss: 0.7159\n",
      "Epoch 277/300\n",
      "229/229 [==============================] - 0s 382us/step - loss: 0.6781 - val_loss: 0.7218\n",
      "Epoch 278/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6789 - val_loss: 0.7175\n",
      "Epoch 279/300\n",
      "229/229 [==============================] - 0s 384us/step - loss: 0.6785 - val_loss: 0.7269\n",
      "Epoch 280/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6793 - val_loss: 0.7263\n",
      "Epoch 281/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6786 - val_loss: 0.7512\n",
      "Epoch 282/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6788 - val_loss: 0.7108\n",
      "Epoch 283/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6780 - val_loss: 0.7117\n",
      "Epoch 284/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6801 - val_loss: 0.7159\n",
      "Epoch 285/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6785 - val_loss: 0.7159\n",
      "Epoch 286/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6804 - val_loss: 0.7244\n",
      "Epoch 287/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6797 - val_loss: 0.7232\n",
      "Epoch 288/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6800 - val_loss: 0.7364\n",
      "Epoch 289/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6786 - val_loss: 0.7322\n",
      "Epoch 290/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6815 - val_loss: 0.7188\n",
      "Epoch 291/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6789 - val_loss: 0.7285\n",
      "Epoch 292/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6795 - val_loss: 0.7377\n",
      "Epoch 293/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6799 - val_loss: 0.7293\n",
      "Epoch 294/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6792 - val_loss: 0.7155\n",
      "Epoch 295/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6801 - val_loss: 0.7160\n",
      "Epoch 296/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6772 - val_loss: 0.7229\n",
      "Epoch 297/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6784 - val_loss: 0.7749\n",
      "Epoch 298/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6803 - val_loss: 0.7135\n",
      "Epoch 299/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6775 - val_loss: 0.7074\n",
      "Epoch 300/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6806 - val_loss: 0.7113\n",
      "26/26 [==============================] - 0s 309us/step\n",
      "Epoch 1/300\n",
      "229/229 [==============================] - 0s 581us/step - loss: 1.4315 - val_loss: 1.0603\n",
      "Epoch 2/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.9717 - val_loss: 0.9215\n",
      "Epoch 3/300\n",
      "229/229 [==============================] - 0s 404us/step - loss: 0.8715 - val_loss: 0.8749\n",
      "Epoch 4/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.8234 - val_loss: 0.8519\n",
      "Epoch 5/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.7926 - val_loss: 0.8372\n",
      "Epoch 6/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.7745 - val_loss: 0.8242\n",
      "Epoch 7/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.7608 - val_loss: 0.8317\n",
      "Epoch 8/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.7529 - val_loss: 0.8195\n",
      "Epoch 9/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.7432 - val_loss: 0.8085\n",
      "Epoch 10/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.7366 - val_loss: 0.7994\n",
      "Epoch 11/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.7281 - val_loss: 0.7987\n",
      "Epoch 12/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.7264 - val_loss: 0.7987\n",
      "Epoch 13/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.7222 - val_loss: 0.8036\n",
      "Epoch 14/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.7161 - val_loss: 0.8114\n",
      "Epoch 15/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.7151 - val_loss: 0.8175\n",
      "Epoch 16/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.7146 - val_loss: 0.8025\n",
      "Epoch 17/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.7077 - val_loss: 0.7792\n",
      "Epoch 18/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.7076 - val_loss: 0.7809\n",
      "Epoch 19/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.7050 - val_loss: 0.7793\n",
      "Epoch 20/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.7050 - val_loss: 0.7766\n",
      "Epoch 21/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.7016 - val_loss: 0.8062\n",
      "Epoch 22/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6989 - val_loss: 0.7916\n",
      "Epoch 23/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6986 - val_loss: 0.7763\n",
      "Epoch 24/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6956 - val_loss: 0.7706\n",
      "Epoch 25/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6961 - val_loss: 0.7797\n",
      "Epoch 26/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6953 - val_loss: 0.7814\n",
      "Epoch 27/300\n",
      "229/229 [==============================] - 0s 386us/step - loss: 0.6925 - val_loss: 0.7761\n",
      "Epoch 28/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6937 - val_loss: 0.7758\n",
      "Epoch 29/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6930 - val_loss: 0.7702\n",
      "Epoch 30/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6916 - val_loss: 0.7790\n",
      "Epoch 31/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6918 - val_loss: 0.7707\n",
      "Epoch 32/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6906 - val_loss: 0.7701\n",
      "Epoch 33/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6890 - val_loss: 0.7809\n",
      "Epoch 34/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6900 - val_loss: 0.7752\n",
      "Epoch 35/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6891 - val_loss: 0.7720\n",
      "Epoch 36/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6877 - val_loss: 0.7853\n",
      "Epoch 37/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6873 - val_loss: 0.7739\n",
      "Epoch 38/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6882 - val_loss: 0.7674\n",
      "Epoch 39/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6872 - val_loss: 0.7754\n",
      "Epoch 40/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6881 - val_loss: 0.7688\n",
      "Epoch 41/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6868 - val_loss: 0.7728\n",
      "Epoch 42/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6887 - val_loss: 0.7796\n",
      "Epoch 43/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6851 - val_loss: 0.7845\n",
      "Epoch 44/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6857 - val_loss: 0.7710\n",
      "Epoch 45/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6857 - val_loss: 0.7667\n",
      "Epoch 46/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6848 - val_loss: 0.7730\n",
      "Epoch 47/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6840 - val_loss: 0.7655\n",
      "Epoch 48/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6860 - val_loss: 0.7959\n",
      "Epoch 49/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6849 - val_loss: 0.7663\n",
      "Epoch 50/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6840 - val_loss: 0.7916\n",
      "Epoch 51/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6857 - val_loss: 0.7576\n",
      "Epoch 52/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6837 - val_loss: 0.7804\n",
      "Epoch 53/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6842 - val_loss: 0.7541\n",
      "Epoch 54/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6833 - val_loss: 0.7807\n",
      "Epoch 55/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6841 - val_loss: 0.7755\n",
      "Epoch 56/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6836 - val_loss: 0.7784\n",
      "Epoch 57/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6812 - val_loss: 0.7762\n",
      "Epoch 58/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6840 - val_loss: 0.7712\n",
      "Epoch 59/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6823 - val_loss: 0.7680\n",
      "Epoch 60/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6833 - val_loss: 0.7662\n",
      "Epoch 61/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6848 - val_loss: 0.7576\n",
      "Epoch 62/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6832 - val_loss: 0.7725\n",
      "Epoch 63/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6841 - val_loss: 0.7596\n",
      "Epoch 64/300\n",
      "229/229 [==============================] - 0s 385us/step - loss: 0.6807 - val_loss: 0.7735\n",
      "Epoch 65/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6797 - val_loss: 0.7728\n",
      "Epoch 66/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6826 - val_loss: 0.7710\n",
      "Epoch 67/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6821 - val_loss: 0.7566\n",
      "Epoch 68/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6819 - val_loss: 0.7782\n",
      "Epoch 69/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6816 - val_loss: 0.7597\n",
      "Epoch 70/300\n",
      "229/229 [==============================] - 0s 383us/step - loss: 0.6832 - val_loss: 0.7559\n",
      "Epoch 71/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6823 - val_loss: 0.7651\n",
      "Epoch 72/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6808 - val_loss: 0.7790\n",
      "Epoch 73/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6833 - val_loss: 0.7627\n",
      "Epoch 74/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6829 - val_loss: 0.7569\n",
      "Epoch 75/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6810 - val_loss: 0.7645\n",
      "Epoch 76/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6804 - val_loss: 0.7650\n",
      "Epoch 77/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6816 - val_loss: 0.8034\n",
      "Epoch 78/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6802 - val_loss: 0.7866\n",
      "Epoch 79/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6814 - val_loss: 0.7784\n",
      "Epoch 80/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6818 - val_loss: 0.7731\n",
      "Epoch 81/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6785 - val_loss: 0.7775\n",
      "Epoch 82/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6805 - val_loss: 0.7632\n",
      "Epoch 83/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6800 - val_loss: 0.7556\n",
      "Epoch 84/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6770 - val_loss: 0.7703\n",
      "Epoch 85/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6827 - val_loss: 0.7683\n",
      "Epoch 86/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6786 - val_loss: 0.7647\n",
      "Epoch 87/300\n",
      "229/229 [==============================] - 0s 387us/step - loss: 0.6801 - val_loss: 0.7653\n",
      "Epoch 88/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6787 - val_loss: 0.7799\n",
      "Epoch 89/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6791 - val_loss: 0.7646\n",
      "Epoch 90/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6804 - val_loss: 0.7763\n",
      "Epoch 91/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6802 - val_loss: 0.7673\n",
      "Epoch 92/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6794 - val_loss: 0.7890\n",
      "Epoch 93/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6806 - val_loss: 0.7714\n",
      "Epoch 94/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6790 - val_loss: 0.7916\n",
      "Epoch 95/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6802 - val_loss: 0.7642\n",
      "Epoch 96/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6789 - val_loss: 0.7703\n",
      "Epoch 97/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6790 - val_loss: 0.7811\n",
      "Epoch 98/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6800 - val_loss: 0.7638\n",
      "Epoch 99/300\n",
      "229/229 [==============================] - 0s 416us/step - loss: 0.6774 - val_loss: 0.7707\n",
      "Epoch 100/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6789 - val_loss: 0.7718\n",
      "Epoch 101/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6787 - val_loss: 0.7751\n",
      "Epoch 102/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6803 - val_loss: 0.7589\n",
      "Epoch 103/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6786 - val_loss: 0.7681\n",
      "Epoch 104/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6784 - val_loss: 0.7553\n",
      "Epoch 105/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6796 - val_loss: 0.7688\n",
      "Epoch 106/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6777 - val_loss: 0.7658\n",
      "Epoch 107/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6788 - val_loss: 0.7594\n",
      "Epoch 108/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6801 - val_loss: 0.7564\n",
      "Epoch 109/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6783 - val_loss: 0.7619\n",
      "Epoch 110/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6793 - val_loss: 0.7647\n",
      "Epoch 111/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6798 - val_loss: 0.7582\n",
      "Epoch 112/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6772 - val_loss: 0.7678\n",
      "Epoch 113/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6758 - val_loss: 0.7616\n",
      "Epoch 114/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6795 - val_loss: 0.7600\n",
      "Epoch 115/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6776 - val_loss: 0.7590\n",
      "Epoch 116/300\n",
      "229/229 [==============================] - 0s 400us/step - loss: 0.6757 - val_loss: 0.7654\n",
      "Epoch 117/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6784 - val_loss: 0.7640\n",
      "Epoch 118/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6777 - val_loss: 0.7673\n",
      "Epoch 119/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6790 - val_loss: 0.7700\n",
      "Epoch 120/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6777 - val_loss: 0.7662\n",
      "Epoch 121/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6791 - val_loss: 0.7587\n",
      "Epoch 122/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6781 - val_loss: 0.7940\n",
      "Epoch 123/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6764 - val_loss: 0.7628\n",
      "Epoch 124/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6755 - val_loss: 0.7632\n",
      "Epoch 125/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6786 - val_loss: 0.7596\n",
      "Epoch 126/300\n",
      "229/229 [==============================] - 0s 402us/step - loss: 0.6763 - val_loss: 0.7626\n",
      "Epoch 127/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6793 - val_loss: 0.7741\n",
      "Epoch 128/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6777 - val_loss: 0.7770\n",
      "Epoch 129/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6782 - val_loss: 0.7760\n",
      "Epoch 130/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6767 - val_loss: 0.7558\n",
      "Epoch 131/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6753 - val_loss: 0.7717\n",
      "Epoch 132/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6775 - val_loss: 0.7799\n",
      "Epoch 133/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6777 - val_loss: 0.7686\n",
      "Epoch 134/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6774 - val_loss: 0.7641\n",
      "Epoch 135/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6765 - val_loss: 0.7487\n",
      "Epoch 136/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6768 - val_loss: 0.7786\n",
      "Epoch 137/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6766 - val_loss: 0.7615\n",
      "Epoch 138/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6750 - val_loss: 0.7703\n",
      "Epoch 139/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6775 - val_loss: 0.7788\n",
      "Epoch 140/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6770 - val_loss: 0.7639\n",
      "Epoch 141/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6770 - val_loss: 0.7791\n",
      "Epoch 142/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6790 - val_loss: 0.7663\n",
      "Epoch 143/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6764 - val_loss: 0.7686\n",
      "Epoch 144/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6749 - val_loss: 0.7658\n",
      "Epoch 145/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6770 - val_loss: 0.7666\n",
      "Epoch 146/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6755 - val_loss: 0.7554\n",
      "Epoch 147/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6771 - val_loss: 0.7508\n",
      "Epoch 148/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6769 - val_loss: 0.7593\n",
      "Epoch 149/300\n",
      "229/229 [==============================] - 0s 401us/step - loss: 0.6761 - val_loss: 0.7722\n",
      "Epoch 150/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6759 - val_loss: 0.7602\n",
      "Epoch 151/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6738 - val_loss: 0.7544\n",
      "Epoch 152/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6735 - val_loss: 0.7781\n",
      "Epoch 153/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6768 - val_loss: 0.7506\n",
      "Epoch 154/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6756 - val_loss: 0.7560\n",
      "Epoch 155/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6757 - val_loss: 0.7627\n",
      "Epoch 156/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6775 - val_loss: 0.7682\n",
      "Epoch 157/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6755 - val_loss: 0.7656\n",
      "Epoch 158/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6767 - val_loss: 0.7606\n",
      "Epoch 159/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6740 - val_loss: 0.7719\n",
      "Epoch 160/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6768 - val_loss: 0.7725\n",
      "Epoch 161/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6756 - val_loss: 0.7793\n",
      "Epoch 162/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6752 - val_loss: 0.7734\n",
      "Epoch 163/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6752 - val_loss: 0.7651\n",
      "Epoch 164/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6746 - val_loss: 0.7598\n",
      "Epoch 165/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6771 - val_loss: 0.7810\n",
      "Epoch 166/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6763 - val_loss: 0.7707\n",
      "Epoch 167/300\n",
      "229/229 [==============================] - 0s 404us/step - loss: 0.6734 - val_loss: 0.7766\n",
      "Epoch 168/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6807 - val_loss: 0.7754\n",
      "Epoch 169/300\n",
      "229/229 [==============================] - 0s 400us/step - loss: 0.6745 - val_loss: 0.7669\n",
      "Epoch 170/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6747 - val_loss: 0.7586\n",
      "Epoch 171/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6765 - val_loss: 0.7633\n",
      "Epoch 172/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6740 - val_loss: 0.7515\n",
      "Epoch 173/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6756 - val_loss: 0.7697\n",
      "Epoch 174/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6762 - val_loss: 0.7660\n",
      "Epoch 175/300\n",
      "229/229 [==============================] - 0s 425us/step - loss: 0.6749 - val_loss: 0.7663\n",
      "Epoch 176/300\n",
      "229/229 [==============================] - 0s 428us/step - loss: 0.6758 - val_loss: 0.7476\n",
      "Epoch 177/300\n",
      "229/229 [==============================] - 0s 406us/step - loss: 0.6767 - val_loss: 0.7626\n",
      "Epoch 178/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6756 - val_loss: 0.7887\n",
      "Epoch 179/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6747 - val_loss: 0.7596\n",
      "Epoch 180/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6751 - val_loss: 0.7525\n",
      "Epoch 181/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6764 - val_loss: 0.7671\n",
      "Epoch 182/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6735 - val_loss: 0.7709\n",
      "Epoch 183/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6762 - val_loss: 0.7547\n",
      "Epoch 184/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6739 - val_loss: 0.7697\n",
      "Epoch 185/300\n",
      "229/229 [==============================] - 0s 388us/step - loss: 0.6752 - val_loss: 0.7675\n",
      "Epoch 186/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6761 - val_loss: 0.7530\n",
      "Epoch 187/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6728 - val_loss: 0.7700\n",
      "Epoch 188/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6755 - val_loss: 0.7732\n",
      "Epoch 189/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6765 - val_loss: 0.7570\n",
      "Epoch 190/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6757 - val_loss: 0.7607\n",
      "Epoch 191/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6757 - val_loss: 0.7567\n",
      "Epoch 192/300\n",
      "229/229 [==============================] - 0s 402us/step - loss: 0.6750 - val_loss: 0.7751\n",
      "Epoch 193/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6732 - val_loss: 0.7702\n",
      "Epoch 194/300\n",
      "229/229 [==============================] - 0s 403us/step - loss: 0.6753 - val_loss: 0.7705\n",
      "Epoch 195/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6756 - val_loss: 0.7647\n",
      "Epoch 196/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6729 - val_loss: 0.7680\n",
      "Epoch 197/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6738 - val_loss: 0.7809\n",
      "Epoch 198/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6764 - val_loss: 0.7581\n",
      "Epoch 199/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6757 - val_loss: 0.7803\n",
      "Epoch 200/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6741 - val_loss: 0.7549\n",
      "Epoch 201/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6766 - val_loss: 0.7637\n",
      "Epoch 202/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6753 - val_loss: 0.7613\n",
      "Epoch 203/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6730 - val_loss: 0.7670\n",
      "Epoch 204/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6758 - val_loss: 0.7569\n",
      "Epoch 205/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6758 - val_loss: 0.7729\n",
      "Epoch 206/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6749 - val_loss: 0.7642\n",
      "Epoch 207/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6748 - val_loss: 0.7541\n",
      "Epoch 208/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6742 - val_loss: 0.7632\n",
      "Epoch 209/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6745 - val_loss: 0.7624\n",
      "Epoch 210/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6766 - val_loss: 0.7784\n",
      "Epoch 211/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6747 - val_loss: 0.7521\n",
      "Epoch 212/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6759 - val_loss: 0.7553\n",
      "Epoch 213/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6758 - val_loss: 0.7728\n",
      "Epoch 214/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6744 - val_loss: 0.7775\n",
      "Epoch 215/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6775 - val_loss: 0.7560\n",
      "Epoch 216/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6764 - val_loss: 0.7597\n",
      "Epoch 217/300\n",
      "229/229 [==============================] - 0s 400us/step - loss: 0.6745 - val_loss: 0.7634\n",
      "Epoch 218/300\n",
      "229/229 [==============================] - 0s 399us/step - loss: 0.6737 - val_loss: 0.7657\n",
      "Epoch 219/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6786 - val_loss: 0.7623\n",
      "Epoch 220/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6755 - val_loss: 0.7465\n",
      "Epoch 221/300\n",
      "229/229 [==============================] - 0s 404us/step - loss: 0.6748 - val_loss: 0.7745\n",
      "Epoch 222/300\n",
      "229/229 [==============================] - 0s 402us/step - loss: 0.6754 - val_loss: 0.7701\n",
      "Epoch 223/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6754 - val_loss: 0.7599\n",
      "Epoch 224/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6757 - val_loss: 0.7701\n",
      "Epoch 225/300\n",
      "229/229 [==============================] - 0s 402us/step - loss: 0.6763 - val_loss: 0.7898\n",
      "Epoch 226/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6742 - val_loss: 0.7611\n",
      "Epoch 227/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6751 - val_loss: 0.7542\n",
      "Epoch 228/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6761 - val_loss: 0.7694\n",
      "Epoch 229/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6739 - val_loss: 0.7590\n",
      "Epoch 230/300\n",
      "229/229 [==============================] - 0s 454us/step - loss: 0.6753 - val_loss: 0.7520\n",
      "Epoch 231/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6738 - val_loss: 0.7582\n",
      "Epoch 232/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6753 - val_loss: 0.7663\n",
      "Epoch 233/300\n",
      "229/229 [==============================] - 0s 405us/step - loss: 0.6750 - val_loss: 0.8013\n",
      "Epoch 234/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6752 - val_loss: 0.7684\n",
      "Epoch 235/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6746 - val_loss: 0.7804\n",
      "Epoch 236/300\n",
      "229/229 [==============================] - 0s 401us/step - loss: 0.6747 - val_loss: 0.7701\n",
      "Epoch 237/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6748 - val_loss: 0.7656\n",
      "Epoch 238/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6732 - val_loss: 0.7686\n",
      "Epoch 239/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6762 - val_loss: 0.7508\n",
      "Epoch 240/300\n",
      "229/229 [==============================] - 0s 421us/step - loss: 0.6762 - val_loss: 0.7684\n",
      "Epoch 241/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6729 - val_loss: 0.7758\n",
      "Epoch 242/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6761 - val_loss: 0.7674\n",
      "Epoch 243/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6767 - val_loss: 0.7790\n",
      "Epoch 244/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6753 - val_loss: 0.7638\n",
      "Epoch 245/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6742 - val_loss: 0.7545\n",
      "Epoch 246/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6716 - val_loss: 0.7707\n",
      "Epoch 247/300\n",
      "229/229 [==============================] - 0s 407us/step - loss: 0.6759 - val_loss: 0.7597\n",
      "Epoch 248/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6775 - val_loss: 0.7627\n",
      "Epoch 249/300\n",
      "229/229 [==============================] - 0s 399us/step - loss: 0.6738 - val_loss: 0.7683\n",
      "Epoch 250/300\n",
      "229/229 [==============================] - 0s 417us/step - loss: 0.6750 - val_loss: 0.7838\n",
      "Epoch 251/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6735 - val_loss: 0.7609\n",
      "Epoch 252/300\n",
      "229/229 [==============================] - 0s 415us/step - loss: 0.6740 - val_loss: 0.7759\n",
      "Epoch 253/300\n",
      "229/229 [==============================] - 0s 407us/step - loss: 0.6733 - val_loss: 0.7648\n",
      "Epoch 254/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6752 - val_loss: 0.7642\n",
      "Epoch 255/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6754 - val_loss: 0.7558\n",
      "Epoch 256/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6730 - val_loss: 0.7626\n",
      "Epoch 257/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6745 - val_loss: 0.7832\n",
      "Epoch 258/300\n",
      "229/229 [==============================] - 0s 411us/step - loss: 0.6754 - val_loss: 0.7573\n",
      "Epoch 259/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6748 - val_loss: 0.7623\n",
      "Epoch 260/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6755 - val_loss: 0.7660\n",
      "Epoch 261/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6734 - val_loss: 0.7623\n",
      "Epoch 262/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6749 - val_loss: 0.7546\n",
      "Epoch 263/300\n",
      "229/229 [==============================] - 0s 399us/step - loss: 0.6739 - val_loss: 0.7569\n",
      "Epoch 264/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6755 - val_loss: 0.7803\n",
      "Epoch 265/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6750 - val_loss: 0.7631\n",
      "Epoch 266/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6763 - val_loss: 0.7896\n",
      "Epoch 267/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6754 - val_loss: 0.7699\n",
      "Epoch 268/300\n",
      "229/229 [==============================] - 0s 392us/step - loss: 0.6747 - val_loss: 0.7454\n",
      "Epoch 269/300\n",
      "229/229 [==============================] - 0s 400us/step - loss: 0.6721 - val_loss: 0.7626\n",
      "Epoch 270/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6728 - val_loss: 0.7672\n",
      "Epoch 271/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6753 - val_loss: 0.7533\n",
      "Epoch 272/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6733 - val_loss: 0.7600\n",
      "Epoch 273/300\n",
      "229/229 [==============================] - 0s 404us/step - loss: 0.6759 - val_loss: 0.7654\n",
      "Epoch 274/300\n",
      "229/229 [==============================] - 0s 401us/step - loss: 0.6739 - val_loss: 0.7854\n",
      "Epoch 275/300\n",
      "229/229 [==============================] - 0s 389us/step - loss: 0.6739 - val_loss: 0.7511\n",
      "Epoch 276/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6738 - val_loss: 0.7783\n",
      "Epoch 277/300\n",
      "229/229 [==============================] - 0s 402us/step - loss: 0.6742 - val_loss: 0.7495\n",
      "Epoch 278/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6740 - val_loss: 0.7527\n",
      "Epoch 279/300\n",
      "229/229 [==============================] - 0s 396us/step - loss: 0.6759 - val_loss: 0.7497\n",
      "Epoch 280/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6741 - val_loss: 0.7688\n",
      "Epoch 281/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6741 - val_loss: 0.7948\n",
      "Epoch 282/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6755 - val_loss: 0.7873\n",
      "Epoch 283/300\n",
      "229/229 [==============================] - 0s 390us/step - loss: 0.6742 - val_loss: 0.7570\n",
      "Epoch 284/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6737 - val_loss: 0.7789\n",
      "Epoch 285/300\n",
      "229/229 [==============================] - 0s 399us/step - loss: 0.6736 - val_loss: 0.7732\n",
      "Epoch 286/300\n",
      "229/229 [==============================] - 0s 394us/step - loss: 0.6772 - val_loss: 0.7649\n",
      "Epoch 287/300\n",
      "229/229 [==============================] - 0s 401us/step - loss: 0.6736 - val_loss: 0.7616\n",
      "Epoch 288/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6752 - val_loss: 0.7563\n",
      "Epoch 289/300\n",
      "229/229 [==============================] - 0s 397us/step - loss: 0.6770 - val_loss: 0.7506\n",
      "Epoch 290/300\n",
      "229/229 [==============================] - 0s 405us/step - loss: 0.6725 - val_loss: 0.7704\n",
      "Epoch 291/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6760 - val_loss: 0.7715\n",
      "Epoch 292/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6762 - val_loss: 0.7641\n",
      "Epoch 293/300\n",
      "229/229 [==============================] - 0s 398us/step - loss: 0.6737 - val_loss: 0.7664\n",
      "Epoch 294/300\n",
      "229/229 [==============================] - 0s 405us/step - loss: 0.6742 - val_loss: 0.7588\n",
      "Epoch 295/300\n",
      "229/229 [==============================] - 0s 391us/step - loss: 0.6742 - val_loss: 0.7721\n",
      "Epoch 296/300\n",
      "229/229 [==============================] - 0s 410us/step - loss: 0.6750 - val_loss: 0.7717\n",
      "Epoch 297/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6757 - val_loss: 0.7638\n",
      "Epoch 298/300\n",
      "229/229 [==============================] - 0s 393us/step - loss: 0.6729 - val_loss: 0.7605\n",
      "Epoch 299/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6737 - val_loss: 0.7695\n",
      "Epoch 300/300\n",
      "229/229 [==============================] - 0s 395us/step - loss: 0.6761 - val_loss: 0.7656\n",
      "26/26 [==============================] - 0s 321us/step\n",
      "Average Cross-Validation Accuracy: 0.7712700369913688\n"
     ]
    }
   ],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for train_index, val_index in stratified_kfold.split(X_train_scaled, y_train_resampled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_resampled[train_index], y_train_resampled[val_index]\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=mean_neurons, input_shape=(num_input_neurons,)),\n",
    "        tf.keras.layers.Dense(units=neurons_hidden_layer),\n",
    "        tf.keras.layers.Dense(units=num_output_neurons, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy')\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=300, validation_data=(X_val_fold, y_val_fold))\n",
    "\n",
    "    y_val_pred_probs = model.predict(X_val_fold)\n",
    "    y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
    "\n",
    "    fold_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "    cv_scores.append(fold_accuracy)\n",
    "\n",
    "average_cv_accuracy = np.mean(cv_scores)\n",
    "print(f'Average Cross-Validation Accuracy: {average_cv_accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:29:12.639179Z",
     "start_time": "2023-11-26T20:24:07.039095Z"
    }
   },
   "id": "15166f9d7801ce10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's try to find the best dropout and activation functions for the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f51b1db2ed41d543"
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "def grid_search_best_parameters():\n",
    "    best_avg_accuracy = 0\n",
    "    best_parameters = {}\n",
    "\n",
    "    dropout_values = np.arange(0, 1, 0.1)\n",
    "    activation_functions = ['relu', 'sigmoid', 'exponential']\n",
    "\n",
    "    total_runs = len(dropout_values) * len(activation_functions) * len(activation_functions)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Adjust the number of folds as needed\n",
    "\n",
    "    with tqdm(total=total_runs, desc=\"Grid Search Progress\", position=0, leave=True) as pbar:\n",
    "        for i, dropout in enumerate(dropout_values):\n",
    "            for function1 in activation_functions:\n",
    "                for function2 in activation_functions:\n",
    "                    avg_accuracy = 0\n",
    "\n",
    "                    for train_index, test_index in skf.split(X_train_scaled, y_train_resampled):\n",
    "                        X_train_cv, X_test_cv = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "                        y_train_cv, y_test_cv = y_train_resampled[train_index], y_train_resampled[test_index]\n",
    "\n",
    "                        # Build an MLP with dropout using TensorFlow \n",
    "                        m = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(units=mean_neurons, activation=function1, input_shape=(X_train_scaled.shape[1],)),\n",
    "                            tf.keras.layers.Dropout(dropout),\n",
    "                            tf.keras.layers.Dense(units=neurons_hidden_layer, activation=function2),\n",
    "                            tf.keras.layers.Dropout(dropout),\n",
    "                            tf.keras.layers.Dense(units=len(np.unique(y_train_resampled)), activation='softmax')\n",
    "                        ])\n",
    "\n",
    "                        # Compile the model\n",
    "                        m.compile(loss='sparse_categorical_crossentropy')\n",
    "\n",
    "                        # Train the model\n",
    "                        m.fit(X_train_cv, y_train_cv, epochs=300, validation_data=(X_test_scaled, y_test), verbose=0)\n",
    "\n",
    "                        # Evaluate the model on the test set\n",
    "                        y_pred_prob = m.predict(X_test_cv)\n",
    "                        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "                        # Accuracy calculation\n",
    "                        accuracy = accuracy_score(y_test_cv, y_pred)\n",
    "                        avg_accuracy += accuracy\n",
    "\n",
    "                    avg_accuracy /= skf.get_n_splits()\n",
    "\n",
    "                    # Check if the current parameters result in a higher average accuracy\n",
    "                    if avg_accuracy > best_avg_accuracy:\n",
    "                        best_avg_accuracy = avg_accuracy\n",
    "                        best_parameters = {\n",
    "                            'best_dropout': dropout,\n",
    "                            'best_function1': function1,\n",
    "                            'best_function2': function2,\n",
    "                            'best_avg_accuracy': best_avg_accuracy\n",
    "                        }\n",
    "\n",
    "                    # Update progress bar\n",
    "                    pbar.update(1)\n",
    "\n",
    "    return best_parameters\n",
    "\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3e1ab0afbbede01"
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "parameters = grid_search_best_parameters()\n",
    "print(parameters)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d29b54b63d0f9085"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](act_funct.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6abc9e5a7320e6f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dropout = 0.1 # parameters['best_dropout']\n",
    "function1 = 'relu' # parameters['best_function1']\n",
    "function2 = 'relu' # parameters['best_function2']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eacbfa58cec2578c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "function = 'relu'\n",
    "optimizer = 'adam'\n",
    "loss_function = 'sparse_categorical_crossentropy'\n",
    "batch_size = 32\n",
    "num_epochs = 300\n",
    "learning_rate = 0.001"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3952beed0a70b6bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now lets train the model with the best parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa15d340c6130829"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for train_index, val_index in stratified_kfold.split(X_train_scaled, y_train_resampled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_resampled[train_index], y_train_resampled[val_index]\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=mean_neurons, activation=function, input_shape=(num_input_neurons,)),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(units=neurons_hidden_layer, activation=function),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(units=num_output_neurons, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy')\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=300, validation_data=(X_val_fold, y_val_fold))\n",
    "\n",
    "    y_val_pred_probs = model.predict(X_val_fold)\n",
    "    y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
    "\n",
    "    fold_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "    cv_scores.append(fold_accuracy)\n",
    "\n",
    "average_cv_accuracy = np.mean(cv_scores)\n",
    "print(f'Average Cross-Validation Accuracy: {average_cv_accuracy}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d92457429bca363"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now lets change the training strategies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4834ff5cd087ad7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d26c03aea2192a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def grid_search_best_parameters():\n",
    "    best_avg_accuracy = 0\n",
    "    best_parameters = {}\n",
    "\n",
    "    optimizer = ['adam', 'sgd', 'adagrad']\n",
    "    learning_rate = ['0.005','0.01' '0.1']\n",
    "    batch_size = [32, 64]\n",
    "\n",
    "    total_runs = len(optimizer) * len(learning_rate) * len(batch_size)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    with tqdm(total=total_runs, desc=\"Grid Search Progress\", position=0, leave=True) as pbar:\n",
    "        for params in product(optimizer_values, learning_rate_values, batch_size_values):\n",
    "            optimizer, learning_rate, batch_size = params\n",
    "            avg_accuracy = 0\n",
    "\n",
    "            for train_index, test_index in skf.split(X_train_scaled, y_train_resampled):\n",
    "                X_train_cv, X_test_cv = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "                y_train_cv, y_test_cv = y_train_resampled[train_index], y_train_resampled[test_index]\n",
    "\n",
    "                model = tf.keras.Sequential([\n",
    "                    tf.keras.layers.Dense(units=mean_neurons, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "                    tf.keras.layers.Dropout(dropout),\n",
    "                    tf.keras.layers.Dense(units=neurons_hidden_layer, activation='relu'),\n",
    "                    tf.keras.layers.Dropout(dropout),\n",
    "                    tf.keras.layers.Dense(units=len(np.unique(y_train_resampled)), activation='softmax')\n",
    "                ])\n",
    "\n",
    "                # Compile the model with the specified optimizer and learning rate\n",
    "                model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, learning_rate=learning_rate)\n",
    "\n",
    "                # Train the model\n",
    "                model.fit(X_train_cv, y_train_cv, epochs=300, validation_data=(X_test_scaled, y_test), batch_size=batch_size, verbose=0)\n",
    "\n",
    "                # Evaluate the model on the test set\n",
    "                y_pred_prob = model.predict(X_test_cv)\n",
    "                y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "                # Accuracy calculation\n",
    "                accuracy = accuracy_score(y_test_cv, y_pred)\n",
    "                avg_accuracy += accuracy\n",
    "\n",
    "            avg_accuracy /= skf.get_n_splits()\n",
    "\n",
    "            # Check if the current parameters result in a higher average accuracy\n",
    "            if avg_accuracy > best_avg_accuracy:\n",
    "                best_avg_accuracy = avg_accuracy\n",
    "                best_parameters = {\n",
    "                    'best_optimizer': optimizer,\n",
    "                    'best_learning_rate': learning_rate,\n",
    "                    'best_batch_size': batch_size,\n",
    "                    'best_avg_accuracy': best_avg_accuracy\n",
    "                }\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "    return best_parameters\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af351b7d095710b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "early_stopping = {'True', 'False'}\n",
    "weight_regularization = {'True', 'False'}\n",
    "data_augmentation = {'True', 'False'}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a73c36ebc842cdfc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d93a9e73baae778"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using Scikit-Learn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "974a14f2280efa95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create an MLP classifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(mean_neurons,), activation=\"relu\", max_iter=300)\n",
    "mlp_classifier.fit(X_train_scaled, y_train_resampled)\n",
    "y_pred = mlp_classifier.predict(X_test_scaled)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd6c936ae202ca0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a859ec96ccf1fd34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "34159ca705beb644"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "27c54484e0905b0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "### CNN\n",
    "# Reshape data for CNN\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1], 1))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train_onehot = to_categorical(y_train_encoded)\n",
    "y_test_onehot = to_categorical(y_test_encoded)\n",
    "# Define the CNN model with different activation functions for hidden layers\n",
    "activation_functions = ['tanh', 'relu', 'sigmoid']\n",
    "\n",
    "for activation1 in activation_functions:\n",
    "    for activation2 in activation_functions:\n",
    "        # Define the CNN model\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1, X_train_scaled.shape[1], 1)))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(64, (3, 3), activation=activation1))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(64, (3, 3), activation=activation2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64, activation=activation1))\n",
    "        model.add(Dense(y_train_onehot.shape[1], activation='sigmoid'))  # Sigmoid for the output layer\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train_onehot, epochs=10, validation_split=0.2)\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test_reshaped, y_test_onehot)\n",
    "print(f'Test \n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7b1d35b852f08d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "55b1ea5c60f882ac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
