{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "869bfaa48bc07b43"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:09:48.337314Z",
     "start_time": "2023-11-27T23:09:44.757565Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Input de DataSet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c4c1db19cb01c9b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "datasets = [pd.read_csv(f'datasets/urbansounds_features_{i}.csv') for i in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:09:48.389943Z",
     "start_time": "2023-11-27T23:09:48.336575Z"
    }
   },
   "id": "8b44e345a051e112"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean the DataSet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d210a4e9b159b459"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def calculate_mean_from_string(string):\n",
    "    cleaned_string = string.replace('\\n', '')\n",
    "    numbers = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", cleaned_string)\n",
    "    array = np.array(numbers, dtype=float)\n",
    "    mean_value = np.mean(array)\n",
    "    return mean_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:09:48.395854Z",
     "start_time": "2023-11-27T23:09:48.390652Z"
    }
   },
   "id": "8c658efd7620a805"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "for df in datasets:\n",
    "    for column in df.columns:\n",
    "        if column != 'Label':\n",
    "            if df[column].dtype != float and df[column].dtype != int:\n",
    "                df[column] = df[column].apply(calculate_mean_from_string)\n",
    "        else:\n",
    "            df[column] = df[column].str.split('-').str[1].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:09:48.440379Z",
     "start_time": "2023-11-27T23:09:48.438904Z"
    }
   },
   "id": "9f5fcf8e7522bca0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59f1fbbc0b0e99c3"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def heatmap(test,pred):\n",
    "    cm = confusion_matrix(test, pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:09:48.446364Z",
     "start_time": "2023-11-27T23:09:48.441306Z"
    }
   },
   "id": "dfcac10f9d44c870"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using TenserFlow"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f962185e1a1a37df"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Combine all labels from different datasets\n",
    "all_labels = np.concatenate([df['Label'].values for df in datasets])\n",
    "\n",
    "# Define the stratified k-fold\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:09:48.446540Z",
     "start_time": "2023-11-27T23:09:48.443972Z"
    }
   },
   "id": "55968b59bbd9f314"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def oversample_features(X, y):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "\n",
    "def standardize_features(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:09:48.452359Z",
     "start_time": "2023-11-27T23:09:48.445479Z"
    }
   },
   "id": "340cb572ca5a8c72"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def preprocess_data(dataset):\n",
    "    X = dataset.drop('Label', axis=1)\n",
    "    y = dataset['Label']\n",
    "\n",
    "    # Oversample and standardize the features\n",
    "    X_resampled, y_resampled = oversample_features(X, y)\n",
    "    X_scaled = standardize_features(X_resampled)\n",
    "\n",
    "    return X_scaled, y_resampled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:09:48.452521Z",
     "start_time": "2023-11-27T23:09:48.449146Z"
    }
   },
   "id": "52fd4a27a07e8e33"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def prepare_datasets(fold):\n",
    "    # Prepare training dataset\n",
    "    training_datasets = [dataset for index, dataset in enumerate(datasets) if index != fold]\n",
    "    combined_df = pd.concat(training_datasets, ignore_index=True)\n",
    "    X_train, y_train = preprocess_data(combined_df)\n",
    "\n",
    "    # Prepare validation dataset\n",
    "    validation_dataset = datasets[fold]\n",
    "    X_val, y_val = preprocess_data(validation_dataset)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:09:48.453421Z",
     "start_time": "2023-11-27T23:09:48.452098Z"
    }
   },
   "id": "25885b3e3e64ba0f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def define_model(X_train, y_train):\n",
    "    mean_neurons = (X_train.shape[1] + len(np.unique(y_train))) // 2\n",
    "    num_input_neurons = X_train.shape[1]\n",
    "    num_output_neurons = len(np.unique(y_train))\n",
    "    neurons_hidden_layer = int(2 / 3 * num_input_neurons + 1 / 3 * num_output_neurons)\n",
    "\n",
    "    # Define and compile the model with hyperparameters\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=neurons_hidden_layer, activation='relu',\n",
    "                              input_shape=(X_train.shape[1],),\n",
    "                              kernel_regularizer=tf.keras.regularizers.l1_l2(l1=regulizer, l2=regulizer)),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(units=mean_neurons, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(units=len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:09:48.458733Z",
     "start_time": "2023-11-27T23:09:48.456690Z"
    }
   },
   "id": "2a0cd70a7d22571a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def build_and_train_model(X_train, y_train, X_val, y_val, num_epochs):\n",
    "    # Determine model architecture and compile\n",
    "    model = define_model(X_train, y_train)\n",
    "\n",
    "    # Train the model\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=num_epochs,\n",
    "              callbacks=[early_stopping])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:09:48.465407Z",
     "start_time": "2023-11-27T23:09:48.459726Z"
    }
   },
   "id": "3ae637cec6904f59"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_val, y_val):\n",
    "    y_val_pred_probs = model.predict(X_val)\n",
    "    y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
    "    fold_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    return fold_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:09:48.465639Z",
     "start_time": "2023-11-27T23:09:48.461738Z"
    }
   },
   "id": "524aa33c27cc2703"
  },
  {
   "cell_type": "markdown",
   "source": [
    "After executing a grid search, we can see that the best hyperparameters are:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff4065e395400c30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![parameter_search.png](parameter_search.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc29a2281dc01f28"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Hyperparameter Grid\n",
    "num_epochs = 201\n",
    "dropout = 0.06\n",
    "learning_rate = '0.1'\n",
    "patience = 15\n",
    "optimizer = 'adam'\n",
    "regulizer = 0.1\n",
    "batch_size = 64"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:11:10.300934Z",
     "start_time": "2023-11-27T23:11:10.292773Z"
    }
   },
   "id": "e4c5b2a703a64144"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/201\n",
      "142/142 [==============================] - 0s 947us/step - loss: 18.6390 - val_loss: 8.2680\n",
      "Epoch 2/201\n",
      "142/142 [==============================] - 0s 669us/step - loss: 4.1742 - val_loss: 2.2480\n",
      "Epoch 3/201\n",
      "142/142 [==============================] - 0s 593us/step - loss: 2.1683 - val_loss: 2.0577\n",
      "Epoch 4/201\n",
      "142/142 [==============================] - 0s 604us/step - loss: 2.0517 - val_loss: 1.9510\n",
      "Epoch 5/201\n",
      "142/142 [==============================] - 0s 585us/step - loss: 1.9708 - val_loss: 1.8763\n",
      "Epoch 6/201\n",
      "142/142 [==============================] - 0s 606us/step - loss: 1.9106 - val_loss: 1.8136\n",
      "Epoch 7/201\n",
      "142/142 [==============================] - 0s 605us/step - loss: 1.8583 - val_loss: 1.7420\n",
      "Epoch 8/201\n",
      "142/142 [==============================] - 0s 615us/step - loss: 1.8021 - val_loss: 1.7186\n",
      "Epoch 9/201\n",
      "142/142 [==============================] - 0s 594us/step - loss: 1.7604 - val_loss: 1.6434\n",
      "Epoch 10/201\n",
      "142/142 [==============================] - 0s 599us/step - loss: 1.7238 - val_loss: 1.6056\n",
      "Epoch 11/201\n",
      "142/142 [==============================] - 0s 588us/step - loss: 1.6897 - val_loss: 1.6252\n",
      "Epoch 12/201\n",
      "142/142 [==============================] - 0s 603us/step - loss: 1.6850 - val_loss: 1.5595\n",
      "Epoch 13/201\n",
      "142/142 [==============================] - 0s 589us/step - loss: 1.6586 - val_loss: 1.6088\n",
      "Epoch 14/201\n",
      "142/142 [==============================] - 0s 589us/step - loss: 1.6256 - val_loss: 1.6025\n",
      "Epoch 15/201\n",
      "142/142 [==============================] - 0s 595us/step - loss: 1.6169 - val_loss: 1.5703\n",
      "Epoch 16/201\n",
      "142/142 [==============================] - 0s 582us/step - loss: 1.6044 - val_loss: 1.5355\n",
      "Epoch 17/201\n",
      "142/142 [==============================] - 0s 584us/step - loss: 1.5839 - val_loss: 1.5249\n",
      "Epoch 18/201\n",
      "142/142 [==============================] - 0s 587us/step - loss: 1.5667 - val_loss: 1.5229\n",
      "Epoch 19/201\n",
      "142/142 [==============================] - 0s 590us/step - loss: 1.5458 - val_loss: 1.5160\n",
      "Epoch 20/201\n",
      "142/142 [==============================] - 0s 575us/step - loss: 1.5472 - val_loss: 1.5193\n",
      "Epoch 21/201\n",
      "142/142 [==============================] - 0s 585us/step - loss: 1.5348 - val_loss: 1.5000\n",
      "Epoch 22/201\n",
      "142/142 [==============================] - 0s 602us/step - loss: 1.5208 - val_loss: 1.5098\n",
      "Epoch 23/201\n",
      "142/142 [==============================] - 0s 590us/step - loss: 1.5089 - val_loss: 1.5057\n",
      "Epoch 24/201\n",
      "142/142 [==============================] - 0s 589us/step - loss: 1.5065 - val_loss: 1.4914\n",
      "Epoch 25/201\n",
      "142/142 [==============================] - 0s 596us/step - loss: 1.4965 - val_loss: 1.5192\n",
      "Epoch 26/201\n",
      "142/142 [==============================] - 0s 588us/step - loss: 1.4792 - val_loss: 1.4957\n",
      "Epoch 27/201\n",
      "142/142 [==============================] - 0s 589us/step - loss: 1.4831 - val_loss: 1.5034\n",
      "Epoch 28/201\n",
      "142/142 [==============================] - 0s 597us/step - loss: 1.4791 - val_loss: 1.4835\n",
      "Epoch 29/201\n",
      "142/142 [==============================] - 0s 585us/step - loss: 1.4586 - val_loss: 1.4779\n",
      "Epoch 30/201\n",
      "142/142 [==============================] - 0s 585us/step - loss: 1.4716 - val_loss: 1.4924\n",
      "Epoch 31/201\n",
      "142/142 [==============================] - 0s 595us/step - loss: 1.4572 - val_loss: 1.5056\n",
      "Epoch 32/201\n",
      "142/142 [==============================] - 0s 579us/step - loss: 1.4496 - val_loss: 1.5087\n",
      "Epoch 33/201\n",
      "142/142 [==============================] - 0s 591us/step - loss: 1.4411 - val_loss: 1.5024\n",
      "Epoch 34/201\n",
      "142/142 [==============================] - 0s 597us/step - loss: 1.4353 - val_loss: 1.4871\n",
      "Epoch 35/201\n",
      "142/142 [==============================] - 0s 592us/step - loss: 1.4361 - val_loss: 1.4737\n",
      "Epoch 36/201\n",
      "142/142 [==============================] - 0s 585us/step - loss: 1.4306 - val_loss: 1.4416\n",
      "Epoch 37/201\n",
      "142/142 [==============================] - 0s 592us/step - loss: 1.4235 - val_loss: 1.4842\n",
      "Epoch 38/201\n",
      "142/142 [==============================] - 0s 590us/step - loss: 1.4342 - val_loss: 1.4908\n",
      "Epoch 39/201\n",
      "142/142 [==============================] - 0s 582us/step - loss: 1.4271 - val_loss: 1.4975\n",
      "Epoch 40/201\n",
      "142/142 [==============================] - 0s 591us/step - loss: 1.4172 - val_loss: 1.4641\n",
      "Epoch 41/201\n",
      "142/142 [==============================] - 0s 590us/step - loss: 1.4092 - val_loss: 1.4529\n",
      "Epoch 42/201\n",
      "142/142 [==============================] - 0s 590us/step - loss: 1.4059 - val_loss: 1.5044\n",
      "Epoch 43/201\n",
      "142/142 [==============================] - 0s 601us/step - loss: 1.4196 - val_loss: 1.5354\n",
      "Epoch 44/201\n",
      "142/142 [==============================] - 0s 922us/step - loss: 1.3982 - val_loss: 1.5119\n",
      "Epoch 45/201\n",
      "142/142 [==============================] - 0s 594us/step - loss: 1.3951 - val_loss: 1.4643\n",
      "Epoch 46/201\n",
      "142/142 [==============================] - 0s 599us/step - loss: 1.3873 - val_loss: 1.4751\n",
      "Epoch 47/201\n",
      "142/142 [==============================] - 0s 581us/step - loss: 1.3887 - val_loss: 1.5382\n",
      "Epoch 48/201\n",
      "142/142 [==============================] - 0s 609us/step - loss: 1.3908 - val_loss: 1.5942\n",
      "Epoch 49/201\n",
      "142/142 [==============================] - 0s 587us/step - loss: 1.3917 - val_loss: 1.5148\n",
      "Epoch 50/201\n",
      "142/142 [==============================] - 0s 589us/step - loss: 1.3838 - val_loss: 1.5048\n",
      "Epoch 51/201\n",
      "142/142 [==============================] - 0s 590us/step - loss: 1.3868 - val_loss: 1.5819\n",
      "38/38 [==============================] - 0s 320us/step\n",
      "Epoch 1/201\n",
      "141/141 [==============================] - 1s 1ms/step - loss: 18.9808 - val_loss: 8.5466\n",
      "Epoch 2/201\n",
      "141/141 [==============================] - 0s 614us/step - loss: 4.2996 - val_loss: 2.2943\n",
      "Epoch 3/201\n",
      "141/141 [==============================] - 0s 597us/step - loss: 2.2125 - val_loss: 2.1581\n",
      "Epoch 4/201\n",
      "141/141 [==============================] - 0s 599us/step - loss: 2.0987 - val_loss: 2.0671\n",
      "Epoch 5/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 2.0109 - val_loss: 1.9898\n",
      "Epoch 6/201\n",
      "141/141 [==============================] - 0s 603us/step - loss: 1.9376 - val_loss: 1.9399\n",
      "Epoch 7/201\n",
      "141/141 [==============================] - 0s 605us/step - loss: 1.8833 - val_loss: 1.9077\n",
      "Epoch 8/201\n",
      "141/141 [==============================] - 0s 597us/step - loss: 1.8171 - val_loss: 1.8414\n",
      "Epoch 9/201\n",
      "141/141 [==============================] - 0s 597us/step - loss: 1.7782 - val_loss: 1.8514\n",
      "Epoch 10/201\n",
      "141/141 [==============================] - 0s 605us/step - loss: 1.7402 - val_loss: 1.8097\n",
      "Epoch 11/201\n",
      "141/141 [==============================] - 0s 599us/step - loss: 1.7078 - val_loss: 1.7608\n",
      "Epoch 12/201\n",
      "141/141 [==============================] - 0s 588us/step - loss: 1.6834 - val_loss: 1.7801\n",
      "Epoch 13/201\n",
      "141/141 [==============================] - 0s 624us/step - loss: 1.6519 - val_loss: 1.7389\n",
      "Epoch 14/201\n",
      "141/141 [==============================] - 0s 597us/step - loss: 1.6391 - val_loss: 1.7062\n",
      "Epoch 15/201\n",
      "141/141 [==============================] - 0s 607us/step - loss: 1.6060 - val_loss: 1.7202\n",
      "Epoch 16/201\n",
      "141/141 [==============================] - 0s 596us/step - loss: 1.5894 - val_loss: 1.6798\n",
      "Epoch 17/201\n",
      "141/141 [==============================] - 0s 597us/step - loss: 1.5815 - val_loss: 1.6465\n",
      "Epoch 18/201\n",
      "141/141 [==============================] - 0s 598us/step - loss: 1.5494 - val_loss: 1.7033\n",
      "Epoch 19/201\n",
      "141/141 [==============================] - 0s 611us/step - loss: 1.5492 - val_loss: 1.7325\n",
      "Epoch 20/201\n",
      "141/141 [==============================] - 0s 589us/step - loss: 1.5412 - val_loss: 1.7039\n",
      "Epoch 21/201\n",
      "141/141 [==============================] - 0s 603us/step - loss: 1.5337 - val_loss: 1.7137\n",
      "Epoch 22/201\n",
      "141/141 [==============================] - 0s 592us/step - loss: 1.5207 - val_loss: 1.6270\n",
      "Epoch 23/201\n",
      "141/141 [==============================] - 0s 598us/step - loss: 1.5185 - val_loss: 1.6613\n",
      "Epoch 24/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 1.5046 - val_loss: 1.6542\n",
      "Epoch 25/201\n",
      "141/141 [==============================] - 0s 622us/step - loss: 1.5033 - val_loss: 1.6654\n",
      "Epoch 26/201\n",
      "141/141 [==============================] - 0s 613us/step - loss: 1.4907 - val_loss: 1.6102\n",
      "Epoch 27/201\n",
      "141/141 [==============================] - 0s 593us/step - loss: 1.4779 - val_loss: 1.6145\n",
      "Epoch 28/201\n",
      "141/141 [==============================] - 0s 591us/step - loss: 1.4773 - val_loss: 1.6571\n",
      "Epoch 29/201\n",
      "141/141 [==============================] - 0s 595us/step - loss: 1.4680 - val_loss: 1.6219\n",
      "Epoch 30/201\n",
      "141/141 [==============================] - 0s 600us/step - loss: 1.4502 - val_loss: 1.5661\n",
      "Epoch 31/201\n",
      "141/141 [==============================] - 0s 604us/step - loss: 1.4419 - val_loss: 1.5847\n",
      "Epoch 32/201\n",
      "141/141 [==============================] - 0s 595us/step - loss: 1.4458 - val_loss: 1.7068\n",
      "Epoch 33/201\n",
      "141/141 [==============================] - 0s 596us/step - loss: 1.4377 - val_loss: 1.6045\n",
      "Epoch 34/201\n",
      "141/141 [==============================] - 0s 587us/step - loss: 1.4373 - val_loss: 1.7196\n",
      "Epoch 35/201\n",
      "141/141 [==============================] - 0s 604us/step - loss: 1.4396 - val_loss: 1.6442\n",
      "Epoch 36/201\n",
      "141/141 [==============================] - 0s 591us/step - loss: 1.4310 - val_loss: 1.6330\n",
      "Epoch 37/201\n",
      "141/141 [==============================] - 0s 623us/step - loss: 1.4299 - val_loss: 1.6007\n",
      "Epoch 38/201\n",
      "141/141 [==============================] - 0s 596us/step - loss: 1.4367 - val_loss: 1.5813\n",
      "Epoch 39/201\n",
      "141/141 [==============================] - 0s 597us/step - loss: 1.4129 - val_loss: 1.6033\n",
      "Epoch 40/201\n",
      "141/141 [==============================] - 0s 603us/step - loss: 1.4229 - val_loss: 1.7106\n",
      "Epoch 41/201\n",
      "141/141 [==============================] - 0s 604us/step - loss: 1.4125 - val_loss: 1.5522\n",
      "Epoch 42/201\n",
      "141/141 [==============================] - 0s 615us/step - loss: 1.4174 - val_loss: 1.5952\n",
      "Epoch 43/201\n",
      "141/141 [==============================] - 0s 600us/step - loss: 1.4067 - val_loss: 1.6733\n",
      "Epoch 44/201\n",
      "141/141 [==============================] - 0s 600us/step - loss: 1.3986 - val_loss: 1.6771\n",
      "Epoch 45/201\n",
      "141/141 [==============================] - 0s 598us/step - loss: 1.4099 - val_loss: 1.5986\n",
      "Epoch 46/201\n",
      "141/141 [==============================] - 0s 767us/step - loss: 1.3975 - val_loss: 1.6052\n",
      "Epoch 47/201\n",
      "141/141 [==============================] - 0s 598us/step - loss: 1.3871 - val_loss: 1.6409\n",
      "Epoch 48/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 1.3993 - val_loss: 1.6448\n",
      "Epoch 49/201\n",
      "141/141 [==============================] - 0s 607us/step - loss: 1.3985 - val_loss: 1.7773\n",
      "Epoch 50/201\n",
      "141/141 [==============================] - 0s 596us/step - loss: 1.3915 - val_loss: 1.6451\n",
      "Epoch 51/201\n",
      "141/141 [==============================] - 0s 598us/step - loss: 1.3858 - val_loss: 1.6099\n",
      "Epoch 52/201\n",
      "141/141 [==============================] - 0s 611us/step - loss: 1.3929 - val_loss: 1.7437\n",
      "Epoch 53/201\n",
      "141/141 [==============================] - 0s 595us/step - loss: 1.3728 - val_loss: 1.6333\n",
      "Epoch 54/201\n",
      "141/141 [==============================] - 0s 606us/step - loss: 1.3720 - val_loss: 1.6544\n",
      "Epoch 55/201\n",
      "141/141 [==============================] - 0s 592us/step - loss: 1.3642 - val_loss: 1.6650\n",
      "Epoch 56/201\n",
      "141/141 [==============================] - 0s 616us/step - loss: 1.3751 - val_loss: 1.7124\n",
      "38/38 [==============================] - 0s 321us/step\n",
      "Epoch 1/201\n",
      "141/141 [==============================] - 0s 920us/step - loss: 18.8745 - val_loss: 8.4114\n",
      "Epoch 2/201\n",
      "141/141 [==============================] - 0s 600us/step - loss: 4.2270 - val_loss: 2.2565\n",
      "Epoch 3/201\n",
      "141/141 [==============================] - 0s 594us/step - loss: 2.1938 - val_loss: 2.1128\n",
      "Epoch 4/201\n",
      "141/141 [==============================] - 0s 606us/step - loss: 2.0731 - val_loss: 1.9666\n",
      "Epoch 5/201\n",
      "141/141 [==============================] - 0s 598us/step - loss: 1.9666 - val_loss: 1.8680\n",
      "Epoch 6/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 1.8945 - val_loss: 1.8053\n",
      "Epoch 7/201\n",
      "141/141 [==============================] - 0s 591us/step - loss: 1.8473 - val_loss: 1.7736\n",
      "Epoch 8/201\n",
      "141/141 [==============================] - 0s 587us/step - loss: 1.8170 - val_loss: 1.7199\n",
      "Epoch 9/201\n",
      "141/141 [==============================] - 0s 603us/step - loss: 1.7831 - val_loss: 1.7215\n",
      "Epoch 10/201\n",
      "141/141 [==============================] - 0s 591us/step - loss: 1.7632 - val_loss: 1.6759\n",
      "Epoch 11/201\n",
      "141/141 [==============================] - 0s 591us/step - loss: 1.7307 - val_loss: 1.6790\n",
      "Epoch 12/201\n",
      "141/141 [==============================] - 0s 611us/step - loss: 1.7131 - val_loss: 1.6662\n",
      "Epoch 13/201\n",
      "141/141 [==============================] - 0s 643us/step - loss: 1.6902 - val_loss: 1.6157\n",
      "Epoch 14/201\n",
      "141/141 [==============================] - 0s 616us/step - loss: 1.6749 - val_loss: 1.6102\n",
      "Epoch 15/201\n",
      "141/141 [==============================] - 0s 585us/step - loss: 1.6574 - val_loss: 1.6101\n",
      "Epoch 16/201\n",
      "141/141 [==============================] - 0s 600us/step - loss: 1.6337 - val_loss: 1.6203\n",
      "Epoch 17/201\n",
      "141/141 [==============================] - 0s 603us/step - loss: 1.6319 - val_loss: 1.6510\n",
      "Epoch 18/201\n",
      "141/141 [==============================] - 0s 589us/step - loss: 1.6082 - val_loss: 1.5893\n",
      "Epoch 19/201\n",
      "141/141 [==============================] - 0s 600us/step - loss: 1.5960 - val_loss: 1.6039\n",
      "Epoch 20/201\n",
      "141/141 [==============================] - 0s 596us/step - loss: 1.5931 - val_loss: 1.5831\n",
      "Epoch 21/201\n",
      "141/141 [==============================] - 0s 597us/step - loss: 1.5702 - val_loss: 1.6075\n",
      "Epoch 22/201\n",
      "141/141 [==============================] - 0s 599us/step - loss: 1.5625 - val_loss: 1.5931\n",
      "Epoch 23/201\n",
      "141/141 [==============================] - 0s 594us/step - loss: 1.5472 - val_loss: 1.5617\n",
      "Epoch 24/201\n",
      "141/141 [==============================] - 0s 590us/step - loss: 1.5391 - val_loss: 1.5514\n",
      "Epoch 25/201\n",
      "141/141 [==============================] - 0s 600us/step - loss: 1.5394 - val_loss: 1.5880\n",
      "Epoch 26/201\n",
      "141/141 [==============================] - 0s 589us/step - loss: 1.5140 - val_loss: 1.5231\n",
      "Epoch 27/201\n",
      "141/141 [==============================] - 0s 587us/step - loss: 1.4972 - val_loss: 1.5685\n",
      "Epoch 28/201\n",
      "141/141 [==============================] - 0s 595us/step - loss: 1.5033 - val_loss: 1.5578\n",
      "Epoch 29/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 1.4846 - val_loss: 1.5799\n",
      "Epoch 30/201\n",
      "141/141 [==============================] - 0s 601us/step - loss: 1.4874 - val_loss: 1.5280\n",
      "Epoch 31/201\n",
      "141/141 [==============================] - 0s 585us/step - loss: 1.4669 - val_loss: 1.5283\n",
      "Epoch 32/201\n",
      "141/141 [==============================] - 0s 600us/step - loss: 1.4568 - val_loss: 1.4476\n",
      "Epoch 33/201\n",
      "141/141 [==============================] - 0s 596us/step - loss: 1.4602 - val_loss: 1.5321\n",
      "Epoch 34/201\n",
      "141/141 [==============================] - 0s 602us/step - loss: 1.4680 - val_loss: 1.4483\n",
      "Epoch 35/201\n",
      "141/141 [==============================] - 0s 599us/step - loss: 1.4487 - val_loss: 1.5311\n",
      "Epoch 36/201\n",
      "141/141 [==============================] - 0s 599us/step - loss: 1.4295 - val_loss: 1.5338\n",
      "Epoch 37/201\n",
      "141/141 [==============================] - 0s 594us/step - loss: 1.4456 - val_loss: 1.5462\n",
      "Epoch 38/201\n",
      "141/141 [==============================] - 0s 598us/step - loss: 1.4196 - val_loss: 1.4298\n",
      "Epoch 39/201\n",
      "141/141 [==============================] - 0s 610us/step - loss: 1.4324 - val_loss: 1.5120\n",
      "Epoch 40/201\n",
      "141/141 [==============================] - 0s 592us/step - loss: 1.4272 - val_loss: 1.5731\n",
      "Epoch 41/201\n",
      "141/141 [==============================] - 0s 603us/step - loss: 1.4107 - val_loss: 1.5825\n",
      "Epoch 42/201\n",
      "141/141 [==============================] - 0s 590us/step - loss: 1.4339 - val_loss: 1.5097\n",
      "Epoch 43/201\n",
      "141/141 [==============================] - 0s 592us/step - loss: 1.4057 - val_loss: 1.5008\n",
      "Epoch 44/201\n",
      "141/141 [==============================] - 0s 601us/step - loss: 1.4016 - val_loss: 1.5478\n",
      "Epoch 45/201\n",
      "141/141 [==============================] - 0s 582us/step - loss: 1.4013 - val_loss: 1.4917\n",
      "Epoch 46/201\n",
      "141/141 [==============================] - 0s 603us/step - loss: 1.4058 - val_loss: 1.5484\n",
      "Epoch 47/201\n",
      "141/141 [==============================] - 0s 613us/step - loss: 1.3901 - val_loss: 1.5066\n",
      "Epoch 48/201\n",
      "141/141 [==============================] - 0s 611us/step - loss: 1.3901 - val_loss: 1.5357\n",
      "Epoch 49/201\n",
      "141/141 [==============================] - 0s 592us/step - loss: 1.3786 - val_loss: 1.5368\n",
      "Epoch 50/201\n",
      "141/141 [==============================] - 0s 588us/step - loss: 1.3812 - val_loss: 1.5516\n",
      "Epoch 51/201\n",
      "141/141 [==============================] - 0s 596us/step - loss: 1.3707 - val_loss: 1.5444\n",
      "Epoch 52/201\n",
      "141/141 [==============================] - 0s 591us/step - loss: 1.3719 - val_loss: 1.5174\n",
      "Epoch 53/201\n",
      "141/141 [==============================] - 0s 600us/step - loss: 1.3611 - val_loss: 1.5132\n",
      "38/38 [==============================] - 0s 322us/step\n",
      "Epoch 1/201\n",
      "141/141 [==============================] - 0s 949us/step - loss: 18.9739 - val_loss: 8.7764\n",
      "Epoch 2/201\n",
      "141/141 [==============================] - 0s 612us/step - loss: 4.4352 - val_loss: 2.3231\n",
      "Epoch 3/201\n",
      "141/141 [==============================] - 0s 612us/step - loss: 2.2073 - val_loss: 2.1903\n",
      "Epoch 4/201\n",
      "141/141 [==============================] - 0s 606us/step - loss: 2.0777 - val_loss: 2.1206\n",
      "Epoch 5/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 2.0010 - val_loss: 2.0749\n",
      "Epoch 6/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 1.9328 - val_loss: 2.0033\n",
      "Epoch 7/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 1.8799 - val_loss: 1.9528\n",
      "Epoch 8/201\n",
      "141/141 [==============================] - 0s 609us/step - loss: 1.8343 - val_loss: 1.9160\n",
      "Epoch 9/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 1.8011 - val_loss: 1.8768\n",
      "Epoch 10/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 1.7521 - val_loss: 1.8070\n",
      "Epoch 11/201\n",
      "141/141 [==============================] - 0s 610us/step - loss: 1.7343 - val_loss: 1.8060\n",
      "Epoch 12/201\n",
      "141/141 [==============================] - 0s 604us/step - loss: 1.7078 - val_loss: 1.7689\n",
      "Epoch 13/201\n",
      "141/141 [==============================] - 0s 615us/step - loss: 1.6767 - val_loss: 1.7400\n",
      "Epoch 14/201\n",
      "141/141 [==============================] - 0s 607us/step - loss: 1.6583 - val_loss: 1.7280\n",
      "Epoch 15/201\n",
      "141/141 [==============================] - 0s 603us/step - loss: 1.6317 - val_loss: 1.7037\n",
      "Epoch 16/201\n",
      "141/141 [==============================] - 0s 603us/step - loss: 1.6297 - val_loss: 1.6983\n",
      "Epoch 17/201\n",
      "141/141 [==============================] - 0s 604us/step - loss: 1.6045 - val_loss: 1.7093\n",
      "Epoch 18/201\n",
      "141/141 [==============================] - 0s 606us/step - loss: 1.5996 - val_loss: 1.6501\n",
      "Epoch 19/201\n",
      "141/141 [==============================] - 0s 621us/step - loss: 1.5843 - val_loss: 1.6475\n",
      "Epoch 20/201\n",
      "141/141 [==============================] - 0s 616us/step - loss: 1.5661 - val_loss: 1.6471\n",
      "Epoch 21/201\n",
      "141/141 [==============================] - 0s 605us/step - loss: 1.5604 - val_loss: 1.6111\n",
      "Epoch 22/201\n",
      "141/141 [==============================] - 0s 609us/step - loss: 1.5442 - val_loss: 1.6352\n",
      "Epoch 23/201\n",
      "141/141 [==============================] - 0s 606us/step - loss: 1.5294 - val_loss: 1.5966\n",
      "Epoch 24/201\n",
      "141/141 [==============================] - 0s 610us/step - loss: 1.5228 - val_loss: 1.6152\n",
      "Epoch 25/201\n",
      "141/141 [==============================] - 0s 627us/step - loss: 1.5127 - val_loss: 1.6126\n",
      "Epoch 26/201\n",
      "141/141 [==============================] - 0s 601us/step - loss: 1.5084 - val_loss: 1.6388\n",
      "Epoch 27/201\n",
      "141/141 [==============================] - 0s 689us/step - loss: 1.4901 - val_loss: 1.6153\n",
      "Epoch 28/201\n",
      "141/141 [==============================] - 0s 958us/step - loss: 1.4935 - val_loss: 1.5658\n",
      "Epoch 29/201\n",
      "141/141 [==============================] - 0s 590us/step - loss: 1.4849 - val_loss: 1.5787\n",
      "Epoch 30/201\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 1.4710 - val_loss: 1.5984\n",
      "Epoch 31/201\n",
      "141/141 [==============================] - 0s 609us/step - loss: 1.4527 - val_loss: 1.5776\n",
      "Epoch 32/201\n",
      "141/141 [==============================] - 0s 605us/step - loss: 1.4570 - val_loss: 1.5358\n",
      "Epoch 33/201\n",
      "141/141 [==============================] - 0s 615us/step - loss: 1.4451 - val_loss: 1.5722\n",
      "Epoch 34/201\n",
      "141/141 [==============================] - 0s 612us/step - loss: 1.4412 - val_loss: 1.5745\n",
      "Epoch 35/201\n",
      "141/141 [==============================] - 0s 618us/step - loss: 1.4353 - val_loss: 1.5542\n",
      "Epoch 36/201\n",
      "141/141 [==============================] - 0s 609us/step - loss: 1.4359 - val_loss: 1.5407\n",
      "Epoch 37/201\n",
      "141/141 [==============================] - 0s 615us/step - loss: 1.4204 - val_loss: 1.5394\n",
      "Epoch 38/201\n",
      "141/141 [==============================] - 0s 614us/step - loss: 1.4172 - val_loss: 1.5073\n",
      "Epoch 39/201\n",
      "141/141 [==============================] - 0s 605us/step - loss: 1.4246 - val_loss: 1.5449\n",
      "Epoch 40/201\n",
      "141/141 [==============================] - 0s 609us/step - loss: 1.4117 - val_loss: 1.5633\n",
      "Epoch 41/201\n",
      "141/141 [==============================] - 0s 609us/step - loss: 1.4187 - val_loss: 1.5382\n",
      "Epoch 42/201\n",
      "141/141 [==============================] - 0s 623us/step - loss: 1.4113 - val_loss: 1.5361\n",
      "Epoch 43/201\n",
      "141/141 [==============================] - 0s 612us/step - loss: 1.4104 - val_loss: 1.5228\n",
      "Epoch 44/201\n",
      "141/141 [==============================] - 0s 604us/step - loss: 1.3953 - val_loss: 1.5284\n",
      "Epoch 45/201\n",
      "141/141 [==============================] - 0s 639us/step - loss: 1.4046 - val_loss: 1.4780\n",
      "Epoch 46/201\n",
      "141/141 [==============================] - 0s 633us/step - loss: 1.3998 - val_loss: 1.5191\n",
      "Epoch 47/201\n",
      "141/141 [==============================] - 0s 635us/step - loss: 1.3835 - val_loss: 1.5326\n",
      "Epoch 48/201\n",
      "141/141 [==============================] - 0s 606us/step - loss: 1.3869 - val_loss: 1.5573\n",
      "Epoch 49/201\n",
      "141/141 [==============================] - 0s 606us/step - loss: 1.3854 - val_loss: 1.5522\n",
      "Epoch 50/201\n",
      "141/141 [==============================] - 0s 604us/step - loss: 1.3865 - val_loss: 1.5519\n",
      "Epoch 51/201\n",
      "141/141 [==============================] - 0s 602us/step - loss: 1.3878 - val_loss: 1.5281\n",
      "Epoch 52/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 1.3723 - val_loss: 1.5760\n",
      "Epoch 53/201\n",
      "141/141 [==============================] - 0s 614us/step - loss: 1.3526 - val_loss: 1.5234\n",
      "Epoch 54/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 1.3567 - val_loss: 1.5105\n",
      "Epoch 55/201\n",
      "141/141 [==============================] - 0s 615us/step - loss: 1.3571 - val_loss: 1.5338\n",
      "Epoch 56/201\n",
      "141/141 [==============================] - 0s 604us/step - loss: 1.3670 - val_loss: 1.5730\n",
      "Epoch 57/201\n",
      "141/141 [==============================] - 0s 608us/step - loss: 1.3668 - val_loss: 1.5831\n",
      "Epoch 58/201\n",
      "141/141 [==============================] - 0s 612us/step - loss: 1.3587 - val_loss: 1.5370\n",
      "Epoch 59/201\n",
      "141/141 [==============================] - 0s 622us/step - loss: 1.3605 - val_loss: 1.5459\n",
      "Epoch 60/201\n",
      "141/141 [==============================] - 0s 606us/step - loss: 1.3497 - val_loss: 1.5778\n",
      "52/52 [==============================] - 0s 308us/step\n",
      "Epoch 1/201\n",
      "141/141 [==============================] - 0s 918us/step - loss: 18.7564 - val_loss: 8.5204\n",
      "Epoch 2/201\n",
      "141/141 [==============================] - 0s 595us/step - loss: 4.3010 - val_loss: 2.3120\n",
      "Epoch 3/201\n",
      "141/141 [==============================] - 0s 587us/step - loss: 2.1853 - val_loss: 2.1462\n",
      "Epoch 4/201\n",
      "141/141 [==============================] - 0s 594us/step - loss: 2.0745 - val_loss: 2.0395\n",
      "Epoch 5/201\n",
      "141/141 [==============================] - 0s 603us/step - loss: 1.9968 - val_loss: 1.9464\n",
      "Epoch 6/201\n",
      "141/141 [==============================] - 0s 585us/step - loss: 1.9326 - val_loss: 1.9168\n",
      "Epoch 7/201\n",
      "141/141 [==============================] - 0s 606us/step - loss: 1.8872 - val_loss: 1.8675\n",
      "Epoch 8/201\n",
      "141/141 [==============================] - 0s 590us/step - loss: 1.8577 - val_loss: 1.8347\n",
      "Epoch 9/201\n",
      "141/141 [==============================] - 0s 598us/step - loss: 1.8231 - val_loss: 1.7912\n",
      "Epoch 10/201\n",
      "141/141 [==============================] - 0s 653us/step - loss: 1.7928 - val_loss: 1.7558\n",
      "Epoch 11/201\n",
      "141/141 [==============================] - 0s 658us/step - loss: 1.7716 - val_loss: 1.7412\n",
      "Epoch 12/201\n",
      "141/141 [==============================] - 0s 638us/step - loss: 1.7347 - val_loss: 1.7195\n",
      "Epoch 13/201\n",
      "141/141 [==============================] - 0s 643us/step - loss: 1.7223 - val_loss: 1.6758\n",
      "Epoch 14/201\n",
      "141/141 [==============================] - 0s 695us/step - loss: 1.6876 - val_loss: 1.7012\n",
      "Epoch 15/201\n",
      "141/141 [==============================] - 0s 597us/step - loss: 1.6690 - val_loss: 1.6465\n",
      "Epoch 16/201\n",
      "141/141 [==============================] - 0s 640us/step - loss: 1.6293 - val_loss: 1.6475\n",
      "Epoch 17/201\n",
      "141/141 [==============================] - 0s 617us/step - loss: 1.6134 - val_loss: 1.6529\n",
      "Epoch 18/201\n",
      "141/141 [==============================] - 0s 670us/step - loss: 1.6000 - val_loss: 1.6499\n",
      "Epoch 19/201\n",
      "141/141 [==============================] - 0s 646us/step - loss: 1.5787 - val_loss: 1.6072\n",
      "Epoch 20/201\n",
      "141/141 [==============================] - 0s 631us/step - loss: 1.5648 - val_loss: 1.6395\n",
      "Epoch 21/201\n",
      "141/141 [==============================] - 0s 644us/step - loss: 1.5492 - val_loss: 1.5788\n",
      "Epoch 22/201\n",
      "141/141 [==============================] - 0s 661us/step - loss: 1.5281 - val_loss: 1.6001\n",
      "Epoch 23/201\n",
      "141/141 [==============================] - 0s 666us/step - loss: 1.5249 - val_loss: 1.5682\n",
      "Epoch 24/201\n",
      "141/141 [==============================] - 0s 631us/step - loss: 1.5273 - val_loss: 1.5719\n",
      "Epoch 25/201\n",
      "141/141 [==============================] - 0s 583us/step - loss: 1.5095 - val_loss: 1.5780\n",
      "Epoch 26/201\n",
      "141/141 [==============================] - 0s 590us/step - loss: 1.5106 - val_loss: 1.6219\n",
      "Epoch 27/201\n",
      "141/141 [==============================] - 0s 598us/step - loss: 1.5077 - val_loss: 1.5404\n",
      "Epoch 28/201\n",
      "141/141 [==============================] - 0s 589us/step - loss: 1.4917 - val_loss: 1.5280\n",
      "Epoch 29/201\n",
      "141/141 [==============================] - 0s 590us/step - loss: 1.4878 - val_loss: 1.6050\n",
      "Epoch 30/201\n",
      "141/141 [==============================] - 0s 589us/step - loss: 1.4743 - val_loss: 1.5952\n",
      "Epoch 31/201\n",
      "141/141 [==============================] - 0s 577us/step - loss: 1.4697 - val_loss: 1.5448\n",
      "Epoch 32/201\n",
      "141/141 [==============================] - 0s 596us/step - loss: 1.4670 - val_loss: 1.5555\n",
      "Epoch 33/201\n",
      "141/141 [==============================] - 0s 576us/step - loss: 1.4537 - val_loss: 1.5737\n",
      "Epoch 34/201\n",
      "141/141 [==============================] - 0s 589us/step - loss: 1.4515 - val_loss: 1.5409\n",
      "Epoch 35/201\n",
      "141/141 [==============================] - 0s 615us/step - loss: 1.4373 - val_loss: 1.5306\n",
      "Epoch 36/201\n",
      "141/141 [==============================] - 0s 580us/step - loss: 1.4396 - val_loss: 1.5337\n",
      "Epoch 37/201\n",
      "141/141 [==============================] - 0s 585us/step - loss: 1.4328 - val_loss: 1.5609\n",
      "Epoch 38/201\n",
      "141/141 [==============================] - 0s 596us/step - loss: 1.4228 - val_loss: 1.5307\n",
      "Epoch 39/201\n",
      "141/141 [==============================] - 0s 599us/step - loss: 1.4239 - val_loss: 1.4838\n",
      "Epoch 40/201\n",
      "141/141 [==============================] - 0s 583us/step - loss: 1.4218 - val_loss: 1.5053\n",
      "Epoch 41/201\n",
      "141/141 [==============================] - 0s 599us/step - loss: 1.4171 - val_loss: 1.5288\n",
      "Epoch 42/201\n",
      "141/141 [==============================] - 0s 594us/step - loss: 1.4244 - val_loss: 1.5507\n",
      "Epoch 43/201\n",
      "141/141 [==============================] - 0s 579us/step - loss: 1.4105 - val_loss: 1.4790\n",
      "Epoch 44/201\n",
      "141/141 [==============================] - 0s 595us/step - loss: 1.3883 - val_loss: 1.5402\n",
      "Epoch 45/201\n",
      "141/141 [==============================] - 0s 585us/step - loss: 1.4148 - val_loss: 1.4999\n",
      "Epoch 46/201\n",
      "141/141 [==============================] - 0s 594us/step - loss: 1.3854 - val_loss: 1.5031\n",
      "Epoch 47/201\n",
      "141/141 [==============================] - 0s 594us/step - loss: 1.3983 - val_loss: 1.5402\n",
      "Epoch 48/201\n",
      "141/141 [==============================] - 0s 590us/step - loss: 1.4125 - val_loss: 1.5237\n",
      "Epoch 49/201\n",
      "141/141 [==============================] - 0s 583us/step - loss: 1.3952 - val_loss: 1.4577\n",
      "Epoch 50/201\n",
      "141/141 [==============================] - 0s 589us/step - loss: 1.3818 - val_loss: 1.5144\n",
      "Epoch 51/201\n",
      "141/141 [==============================] - 0s 628us/step - loss: 1.3891 - val_loss: 1.5143\n",
      "Epoch 52/201\n",
      "141/141 [==============================] - 0s 709us/step - loss: 1.3811 - val_loss: 1.5228\n",
      "Epoch 53/201\n",
      "141/141 [==============================] - 0s 583us/step - loss: 1.3747 - val_loss: 1.4704\n",
      "Epoch 54/201\n",
      "141/141 [==============================] - 0s 582us/step - loss: 1.3729 - val_loss: 1.5102\n",
      "Epoch 55/201\n",
      "141/141 [==============================] - 0s 590us/step - loss: 1.3737 - val_loss: 1.4902\n",
      "Epoch 56/201\n",
      "141/141 [==============================] - 0s 593us/step - loss: 1.3706 - val_loss: 1.4765\n",
      "Epoch 57/201\n",
      "141/141 [==============================] - 0s 584us/step - loss: 1.3567 - val_loss: 1.5031\n",
      "Epoch 58/201\n",
      "141/141 [==============================] - 0s 597us/step - loss: 1.3626 - val_loss: 1.4837\n",
      "Epoch 59/201\n",
      "141/141 [==============================] - 0s 579us/step - loss: 1.3777 - val_loss: 1.4448\n",
      "Epoch 60/201\n",
      "141/141 [==============================] - 0s 591us/step - loss: 1.3426 - val_loss: 1.4386\n",
      "Epoch 61/201\n",
      "141/141 [==============================] - 0s 584us/step - loss: 1.3534 - val_loss: 1.4772\n",
      "Epoch 62/201\n",
      "141/141 [==============================] - 0s 577us/step - loss: 1.3546 - val_loss: 1.4426\n",
      "Epoch 63/201\n",
      "141/141 [==============================] - 0s 592us/step - loss: 1.3592 - val_loss: 1.3766\n",
      "Epoch 64/201\n",
      "141/141 [==============================] - 0s 591us/step - loss: 1.3425 - val_loss: 1.4498\n",
      "Epoch 65/201\n",
      "141/141 [==============================] - 0s 577us/step - loss: 1.3478 - val_loss: 1.4615\n",
      "Epoch 66/201\n",
      "141/141 [==============================] - 0s 586us/step - loss: 1.3365 - val_loss: 1.4350\n",
      "Epoch 67/201\n",
      "141/141 [==============================] - 0s 589us/step - loss: 1.3373 - val_loss: 1.4134\n",
      "Epoch 68/201\n",
      "141/141 [==============================] - 0s 595us/step - loss: 1.3435 - val_loss: 1.5038\n",
      "Epoch 69/201\n",
      "141/141 [==============================] - 0s 579us/step - loss: 1.3402 - val_loss: 1.4341\n",
      "Epoch 70/201\n",
      "141/141 [==============================] - 0s 603us/step - loss: 1.3338 - val_loss: 1.4739\n",
      "Epoch 71/201\n",
      "141/141 [==============================] - 0s 579us/step - loss: 1.3411 - val_loss: 1.4953\n",
      "Epoch 72/201\n",
      "141/141 [==============================] - 0s 588us/step - loss: 1.3273 - val_loss: 1.4555\n",
      "Epoch 73/201\n",
      "141/141 [==============================] - 0s 588us/step - loss: 1.3494 - val_loss: 1.5078\n",
      "Epoch 74/201\n",
      "141/141 [==============================] - 0s 596us/step - loss: 1.3332 - val_loss: 1.4356\n",
      "Epoch 75/201\n",
      "141/141 [==============================] - 0s 587us/step - loss: 1.3313 - val_loss: 1.4667\n",
      "Epoch 76/201\n",
      "141/141 [==============================] - 0s 602us/step - loss: 1.3298 - val_loss: 1.4027\n",
      "Epoch 77/201\n",
      "141/141 [==============================] - 0s 580us/step - loss: 1.3242 - val_loss: 1.4179\n",
      "Epoch 78/201\n",
      "141/141 [==============================] - 0s 583us/step - loss: 1.3228 - val_loss: 1.4491\n",
      "38/38 [==============================] - 0s 327us/step\n",
      "Epoch 1/201\n",
      "146/146 [==============================] - 0s 893us/step - loss: 18.6750 - val_loss: 8.1072\n",
      "Epoch 2/201\n",
      "146/146 [==============================] - 0s 583us/step - loss: 3.9690 - val_loss: 2.2499\n",
      "Epoch 3/201\n",
      "146/146 [==============================] - 0s 591us/step - loss: 2.1868 - val_loss: 2.1412\n",
      "Epoch 4/201\n",
      "146/146 [==============================] - 0s 576us/step - loss: 2.1061 - val_loss: 2.0809\n",
      "Epoch 5/201\n",
      "146/146 [==============================] - 0s 590us/step - loss: 2.0360 - val_loss: 2.0400\n",
      "Epoch 6/201\n",
      "146/146 [==============================] - 0s 589us/step - loss: 1.9726 - val_loss: 1.9863\n",
      "Epoch 7/201\n",
      "146/146 [==============================] - 0s 573us/step - loss: 1.9115 - val_loss: 1.9707\n",
      "Epoch 8/201\n",
      "146/146 [==============================] - 0s 569us/step - loss: 1.8580 - val_loss: 1.9049\n",
      "Epoch 9/201\n",
      "146/146 [==============================] - 0s 580us/step - loss: 1.8066 - val_loss: 1.8501\n",
      "Epoch 10/201\n",
      "146/146 [==============================] - 0s 581us/step - loss: 1.7741 - val_loss: 1.8107\n",
      "Epoch 11/201\n",
      "146/146 [==============================] - 0s 576us/step - loss: 1.7329 - val_loss: 1.7876\n",
      "Epoch 12/201\n",
      "146/146 [==============================] - 0s 590us/step - loss: 1.7175 - val_loss: 1.7683\n",
      "Epoch 13/201\n",
      "146/146 [==============================] - 0s 573us/step - loss: 1.6860 - val_loss: 1.7447\n",
      "Epoch 14/201\n",
      "146/146 [==============================] - 0s 584us/step - loss: 1.6628 - val_loss: 1.7244\n",
      "Epoch 15/201\n",
      "146/146 [==============================] - 0s 581us/step - loss: 1.6427 - val_loss: 1.6819\n",
      "Epoch 16/201\n",
      "146/146 [==============================] - 0s 585us/step - loss: 1.6182 - val_loss: 1.6942\n",
      "Epoch 17/201\n",
      "146/146 [==============================] - 0s 597us/step - loss: 1.5925 - val_loss: 1.6615\n",
      "Epoch 18/201\n",
      "146/146 [==============================] - 0s 1ms/step - loss: 1.5878 - val_loss: 1.6870\n",
      "Epoch 19/201\n",
      "146/146 [==============================] - 0s 571us/step - loss: 1.5811 - val_loss: 1.6516\n",
      "Epoch 20/201\n",
      "146/146 [==============================] - 0s 575us/step - loss: 1.5651 - val_loss: 1.6451\n",
      "Epoch 21/201\n",
      "146/146 [==============================] - 0s 585us/step - loss: 1.5429 - val_loss: 1.6298\n",
      "Epoch 22/201\n",
      "146/146 [==============================] - 0s 591us/step - loss: 1.5422 - val_loss: 1.5929\n",
      "Epoch 23/201\n",
      "146/146 [==============================] - 0s 579us/step - loss: 1.5211 - val_loss: 1.6050\n",
      "Epoch 24/201\n",
      "146/146 [==============================] - 0s 582us/step - loss: 1.5180 - val_loss: 1.6075\n",
      "Epoch 25/201\n",
      "146/146 [==============================] - 0s 579us/step - loss: 1.5006 - val_loss: 1.5657\n",
      "Epoch 26/201\n",
      "146/146 [==============================] - 0s 581us/step - loss: 1.4836 - val_loss: 1.5744\n",
      "Epoch 27/201\n",
      "146/146 [==============================] - 0s 574us/step - loss: 1.4848 - val_loss: 1.5348\n",
      "Epoch 28/201\n",
      "146/146 [==============================] - 0s 594us/step - loss: 1.4732 - val_loss: 1.5510\n",
      "Epoch 29/201\n",
      "146/146 [==============================] - 0s 580us/step - loss: 1.4834 - val_loss: 1.5740\n",
      "Epoch 30/201\n",
      "146/146 [==============================] - 0s 595us/step - loss: 1.4640 - val_loss: 1.5143\n",
      "Epoch 31/201\n",
      "146/146 [==============================] - 0s 573us/step - loss: 1.4742 - val_loss: 1.5939\n",
      "Epoch 32/201\n",
      "146/146 [==============================] - 0s 574us/step - loss: 1.4559 - val_loss: 1.5817\n",
      "Epoch 33/201\n",
      "146/146 [==============================] - 0s 583us/step - loss: 1.4539 - val_loss: 1.5077\n",
      "Epoch 34/201\n",
      "146/146 [==============================] - 0s 579us/step - loss: 1.4585 - val_loss: 1.5844\n",
      "Epoch 35/201\n",
      "146/146 [==============================] - 0s 591us/step - loss: 1.4298 - val_loss: 1.5879\n",
      "Epoch 36/201\n",
      "146/146 [==============================] - 0s 593us/step - loss: 1.4394 - val_loss: 1.5095\n",
      "Epoch 37/201\n",
      "146/146 [==============================] - 0s 573us/step - loss: 1.4316 - val_loss: 1.5704\n",
      "Epoch 38/201\n",
      "146/146 [==============================] - 0s 587us/step - loss: 1.4373 - val_loss: 1.5774\n",
      "Epoch 39/201\n",
      "146/146 [==============================] - 0s 578us/step - loss: 1.4237 - val_loss: 1.5687\n",
      "Epoch 40/201\n",
      "146/146 [==============================] - 0s 585us/step - loss: 1.4195 - val_loss: 1.5728\n",
      "Epoch 41/201\n",
      "146/146 [==============================] - 0s 577us/step - loss: 1.4219 - val_loss: 1.5093\n",
      "Epoch 42/201\n",
      "146/146 [==============================] - 0s 572us/step - loss: 1.4179 - val_loss: 1.5535\n",
      "Epoch 43/201\n",
      "146/146 [==============================] - 0s 588us/step - loss: 1.4133 - val_loss: 1.6063\n",
      "Epoch 44/201\n",
      "146/146 [==============================] - 0s 580us/step - loss: 1.4137 - val_loss: 1.5717\n",
      "Epoch 45/201\n",
      "146/146 [==============================] - 0s 692us/step - loss: 1.4006 - val_loss: 1.5628\n",
      "Epoch 46/201\n",
      "146/146 [==============================] - 0s 599us/step - loss: 1.4078 - val_loss: 1.5737\n",
      "Epoch 47/201\n",
      "146/146 [==============================] - 0s 581us/step - loss: 1.3927 - val_loss: 1.5156\n",
      "Epoch 48/201\n",
      "146/146 [==============================] - 0s 590us/step - loss: 1.3942 - val_loss: 1.6062\n",
      "34/34 [==============================] - 0s 318us/step\n",
      "Epoch 1/201\n",
      "145/145 [==============================] - 0s 895us/step - loss: 18.0487 - val_loss: 7.9273\n",
      "Epoch 2/201\n",
      "145/145 [==============================] - 0s 584us/step - loss: 4.0153 - val_loss: 2.2882\n",
      "Epoch 3/201\n",
      "145/145 [==============================] - 0s 599us/step - loss: 2.1877 - val_loss: 2.1476\n",
      "Epoch 4/201\n",
      "145/145 [==============================] - 0s 580us/step - loss: 2.0581 - val_loss: 2.1061\n",
      "Epoch 5/201\n",
      "145/145 [==============================] - 0s 614us/step - loss: 1.9805 - val_loss: 2.0838\n",
      "Epoch 6/201\n",
      "145/145 [==============================] - 0s 589us/step - loss: 1.9097 - val_loss: 2.0583\n",
      "Epoch 7/201\n",
      "145/145 [==============================] - 0s 573us/step - loss: 1.8593 - val_loss: 2.0352\n",
      "Epoch 8/201\n",
      "145/145 [==============================] - 0s 578us/step - loss: 1.8120 - val_loss: 1.9887\n",
      "Epoch 9/201\n",
      "145/145 [==============================] - 0s 581us/step - loss: 1.7750 - val_loss: 1.9615\n",
      "Epoch 10/201\n",
      "145/145 [==============================] - 0s 591us/step - loss: 1.7480 - val_loss: 1.9059\n",
      "Epoch 11/201\n",
      "145/145 [==============================] - 0s 580us/step - loss: 1.7119 - val_loss: 1.8999\n",
      "Epoch 12/201\n",
      "145/145 [==============================] - 0s 585us/step - loss: 1.6899 - val_loss: 1.8151\n",
      "Epoch 13/201\n",
      "145/145 [==============================] - 0s 583us/step - loss: 1.6662 - val_loss: 1.8543\n",
      "Epoch 14/201\n",
      "145/145 [==============================] - 0s 591us/step - loss: 1.6493 - val_loss: 1.8083\n",
      "Epoch 15/201\n",
      "145/145 [==============================] - 0s 571us/step - loss: 1.6309 - val_loss: 1.7878\n",
      "Epoch 16/201\n",
      "145/145 [==============================] - 0s 587us/step - loss: 1.6112 - val_loss: 1.7409\n",
      "Epoch 17/201\n",
      "145/145 [==============================] - 0s 577us/step - loss: 1.5941 - val_loss: 1.8113\n",
      "Epoch 18/201\n",
      "145/145 [==============================] - 0s 581us/step - loss: 1.5799 - val_loss: 1.8160\n",
      "Epoch 19/201\n",
      "145/145 [==============================] - 0s 587us/step - loss: 1.5628 - val_loss: 1.7987\n",
      "Epoch 20/201\n",
      "145/145 [==============================] - 0s 578us/step - loss: 1.5467 - val_loss: 1.8234\n",
      "Epoch 21/201\n",
      "145/145 [==============================] - 0s 576us/step - loss: 1.5263 - val_loss: 1.7465\n",
      "Epoch 22/201\n",
      "145/145 [==============================] - 0s 577us/step - loss: 1.5302 - val_loss: 1.7930\n",
      "Epoch 23/201\n",
      "145/145 [==============================] - 0s 588us/step - loss: 1.5241 - val_loss: 1.7240\n",
      "Epoch 24/201\n",
      "145/145 [==============================] - 0s 578us/step - loss: 1.5098 - val_loss: 1.7073\n",
      "Epoch 25/201\n",
      "145/145 [==============================] - 0s 585us/step - loss: 1.5097 - val_loss: 1.8133\n",
      "Epoch 26/201\n",
      "145/145 [==============================] - 0s 690us/step - loss: 1.4879 - val_loss: 1.7573\n",
      "Epoch 27/201\n",
      "145/145 [==============================] - 0s 690us/step - loss: 1.4808 - val_loss: 1.7235\n",
      "Epoch 28/201\n",
      "145/145 [==============================] - 0s 616us/step - loss: 1.4753 - val_loss: 1.7379\n",
      "Epoch 29/201\n",
      "145/145 [==============================] - 0s 597us/step - loss: 1.4661 - val_loss: 1.7174\n",
      "Epoch 30/201\n",
      "145/145 [==============================] - 0s 607us/step - loss: 1.4480 - val_loss: 1.7122\n",
      "Epoch 31/201\n",
      "145/145 [==============================] - 0s 576us/step - loss: 1.4567 - val_loss: 1.6726\n",
      "Epoch 32/201\n",
      "145/145 [==============================] - 0s 584us/step - loss: 1.4407 - val_loss: 1.6927\n",
      "Epoch 33/201\n",
      "145/145 [==============================] - 0s 590us/step - loss: 1.4262 - val_loss: 1.6715\n",
      "Epoch 34/201\n",
      "145/145 [==============================] - 0s 582us/step - loss: 1.4290 - val_loss: 1.7084\n",
      "Epoch 35/201\n",
      "145/145 [==============================] - 0s 591us/step - loss: 1.4221 - val_loss: 1.7100\n",
      "Epoch 36/201\n",
      "145/145 [==============================] - 0s 576us/step - loss: 1.4151 - val_loss: 1.7544\n",
      "Epoch 37/201\n",
      "145/145 [==============================] - 0s 587us/step - loss: 1.4061 - val_loss: 1.7829\n",
      "Epoch 38/201\n",
      "145/145 [==============================] - 0s 574us/step - loss: 1.4106 - val_loss: 1.6893\n",
      "Epoch 39/201\n",
      "145/145 [==============================] - 0s 584us/step - loss: 1.3974 - val_loss: 1.7501\n",
      "Epoch 40/201\n",
      "145/145 [==============================] - 0s 598us/step - loss: 1.4020 - val_loss: 1.8020\n",
      "Epoch 41/201\n",
      "145/145 [==============================] - 0s 591us/step - loss: 1.3972 - val_loss: 1.7565\n",
      "Epoch 42/201\n",
      "145/145 [==============================] - 0s 584us/step - loss: 1.3699 - val_loss: 1.6923\n",
      "Epoch 43/201\n",
      "145/145 [==============================] - 0s 572us/step - loss: 1.3815 - val_loss: 1.7509\n",
      "Epoch 44/201\n",
      "145/145 [==============================] - 0s 582us/step - loss: 1.3852 - val_loss: 1.7304\n",
      "Epoch 45/201\n",
      "145/145 [==============================] - 0s 594us/step - loss: 1.3871 - val_loss: 1.7902\n",
      "Epoch 46/201\n",
      "145/145 [==============================] - 0s 584us/step - loss: 1.3740 - val_loss: 1.7582\n",
      "Epoch 47/201\n",
      "145/145 [==============================] - 0s 581us/step - loss: 1.3650 - val_loss: 1.7292\n",
      "Epoch 48/201\n",
      "145/145 [==============================] - 0s 585us/step - loss: 1.3637 - val_loss: 1.7701\n",
      "34/34 [==============================] - 0s 347us/step\n",
      "Epoch 1/201\n",
      "145/145 [==============================] - 0s 907us/step - loss: 18.1639 - val_loss: 7.8521\n",
      "Epoch 2/201\n",
      "145/145 [==============================] - 0s 587us/step - loss: 3.9868 - val_loss: 2.2061\n",
      "Epoch 3/201\n",
      "145/145 [==============================] - 0s 571us/step - loss: 2.1857 - val_loss: 2.0412\n",
      "Epoch 4/201\n",
      "145/145 [==============================] - 0s 585us/step - loss: 2.0595 - val_loss: 1.9410\n",
      "Epoch 5/201\n",
      "145/145 [==============================] - 0s 595us/step - loss: 1.9499 - val_loss: 1.8526\n",
      "Epoch 6/201\n",
      "145/145 [==============================] - 0s 574us/step - loss: 1.8747 - val_loss: 1.8055\n",
      "Epoch 7/201\n",
      "145/145 [==============================] - 0s 582us/step - loss: 1.8081 - val_loss: 1.7566\n",
      "Epoch 8/201\n",
      "145/145 [==============================] - 0s 669us/step - loss: 1.7677 - val_loss: 1.7659\n",
      "Epoch 9/201\n",
      "145/145 [==============================] - 0s 589us/step - loss: 1.7292 - val_loss: 1.7037\n",
      "Epoch 10/201\n",
      "145/145 [==============================] - 0s 576us/step - loss: 1.6926 - val_loss: 1.6977\n",
      "Epoch 11/201\n",
      "145/145 [==============================] - 0s 583us/step - loss: 1.6576 - val_loss: 1.6960\n",
      "Epoch 12/201\n",
      "145/145 [==============================] - 0s 585us/step - loss: 1.6421 - val_loss: 1.6431\n",
      "Epoch 13/201\n",
      "145/145 [==============================] - 0s 588us/step - loss: 1.6278 - val_loss: 1.6450\n",
      "Epoch 14/201\n",
      "145/145 [==============================] - 0s 581us/step - loss: 1.6083 - val_loss: 1.6226\n",
      "Epoch 15/201\n",
      "145/145 [==============================] - 0s 592us/step - loss: 1.5998 - val_loss: 1.6100\n",
      "Epoch 16/201\n",
      "145/145 [==============================] - 0s 577us/step - loss: 1.5682 - val_loss: 1.6717\n",
      "Epoch 17/201\n",
      "145/145 [==============================] - 0s 581us/step - loss: 1.5524 - val_loss: 1.5629\n",
      "Epoch 18/201\n",
      "145/145 [==============================] - 0s 576us/step - loss: 1.5492 - val_loss: 1.5641\n",
      "Epoch 19/201\n",
      "145/145 [==============================] - 0s 581us/step - loss: 1.5344 - val_loss: 1.6339\n",
      "Epoch 20/201\n",
      "145/145 [==============================] - 0s 576us/step - loss: 1.5119 - val_loss: 1.5774\n",
      "Epoch 21/201\n",
      "145/145 [==============================] - 0s 582us/step - loss: 1.5084 - val_loss: 1.5681\n",
      "Epoch 22/201\n",
      "145/145 [==============================] - 0s 636us/step - loss: 1.4922 - val_loss: 1.5461\n",
      "Epoch 23/201\n",
      "145/145 [==============================] - 0s 656us/step - loss: 1.4958 - val_loss: 1.5517\n",
      "Epoch 24/201\n",
      "145/145 [==============================] - 0s 584us/step - loss: 1.4970 - val_loss: 1.5480\n",
      "Epoch 25/201\n",
      "145/145 [==============================] - 0s 577us/step - loss: 1.4604 - val_loss: 1.5909\n",
      "Epoch 26/201\n",
      "145/145 [==============================] - 0s 583us/step - loss: 1.4773 - val_loss: 1.5562\n",
      "Epoch 27/201\n",
      "145/145 [==============================] - 0s 583us/step - loss: 1.4457 - val_loss: 1.5783\n",
      "Epoch 28/201\n",
      "145/145 [==============================] - 0s 576us/step - loss: 1.4283 - val_loss: 1.5137\n",
      "Epoch 29/201\n",
      "145/145 [==============================] - 0s 587us/step - loss: 1.4357 - val_loss: 1.5233\n",
      "Epoch 30/201\n",
      "145/145 [==============================] - 0s 582us/step - loss: 1.4319 - val_loss: 1.4988\n",
      "Epoch 31/201\n",
      "145/145 [==============================] - 0s 581us/step - loss: 1.4224 - val_loss: 1.4606\n",
      "Epoch 32/201\n",
      "145/145 [==============================] - 0s 577us/step - loss: 1.4005 - val_loss: 1.5246\n",
      "Epoch 33/201\n",
      "145/145 [==============================] - 0s 591us/step - loss: 1.4791 - val_loss: 1.5886\n",
      "Epoch 34/201\n",
      "145/145 [==============================] - 0s 584us/step - loss: 1.4155 - val_loss: 1.4777\n",
      "Epoch 35/201\n",
      "145/145 [==============================] - 0s 575us/step - loss: 1.4072 - val_loss: 1.5154\n",
      "Epoch 36/201\n",
      "145/145 [==============================] - 0s 580us/step - loss: 1.4255 - val_loss: 1.5574\n",
      "Epoch 37/201\n",
      "145/145 [==============================] - 0s 589us/step - loss: 1.3828 - val_loss: 1.5145\n",
      "Epoch 38/201\n",
      "145/145 [==============================] - 0s 583us/step - loss: 1.3802 - val_loss: 1.5087\n",
      "Epoch 39/201\n",
      "145/145 [==============================] - 0s 581us/step - loss: 1.3822 - val_loss: 1.5234\n",
      "Epoch 40/201\n",
      "145/145 [==============================] - 0s 600us/step - loss: 1.3657 - val_loss: 1.5699\n",
      "Epoch 41/201\n",
      "145/145 [==============================] - 0s 584us/step - loss: 1.3726 - val_loss: 1.4781\n",
      "Epoch 42/201\n",
      "145/145 [==============================] - 0s 581us/step - loss: 1.3713 - val_loss: 1.4895\n",
      "Epoch 43/201\n",
      "145/145 [==============================] - 0s 584us/step - loss: 1.3737 - val_loss: 1.5294\n",
      "Epoch 44/201\n",
      "145/145 [==============================] - 0s 580us/step - loss: 1.3762 - val_loss: 1.4644\n",
      "Epoch 45/201\n",
      "145/145 [==============================] - 0s 570us/step - loss: 1.3621 - val_loss: 1.4640\n",
      "Epoch 46/201\n",
      "145/145 [==============================] - 0s 589us/step - loss: 1.3717 - val_loss: 1.5277\n",
      "32/32 [==============================] - 0s 346us/step\n",
      "Epoch 1/201\n",
      "144/144 [==============================] - 0s 898us/step - loss: 18.4468 - val_loss: 8.2082\n",
      "Epoch 2/201\n",
      "144/144 [==============================] - 0s 598us/step - loss: 4.1400 - val_loss: 2.2276\n",
      "Epoch 3/201\n",
      "144/144 [==============================] - 0s 584us/step - loss: 2.1774 - val_loss: 2.0973\n",
      "Epoch 4/201\n",
      "144/144 [==============================] - 0s 589us/step - loss: 2.0872 - val_loss: 2.0250\n",
      "Epoch 5/201\n",
      "144/144 [==============================] - 0s 578us/step - loss: 2.0189 - val_loss: 1.9583\n",
      "Epoch 6/201\n",
      "144/144 [==============================] - 0s 578us/step - loss: 1.9511 - val_loss: 1.8903\n",
      "Epoch 7/201\n",
      "144/144 [==============================] - 0s 575us/step - loss: 1.8785 - val_loss: 1.8242\n",
      "Epoch 8/201\n",
      "144/144 [==============================] - 0s 589us/step - loss: 1.8178 - val_loss: 1.7585\n",
      "Epoch 9/201\n",
      "144/144 [==============================] - 0s 610us/step - loss: 1.7647 - val_loss: 1.7120\n",
      "Epoch 10/201\n",
      "144/144 [==============================] - 0s 588us/step - loss: 1.7245 - val_loss: 1.6664\n",
      "Epoch 11/201\n",
      "144/144 [==============================] - 0s 588us/step - loss: 1.6899 - val_loss: 1.6181\n",
      "Epoch 12/201\n",
      "144/144 [==============================] - 0s 589us/step - loss: 1.6683 - val_loss: 1.6082\n",
      "Epoch 13/201\n",
      "144/144 [==============================] - 0s 587us/step - loss: 1.6443 - val_loss: 1.6539\n",
      "Epoch 14/201\n",
      "144/144 [==============================] - 0s 587us/step - loss: 1.6308 - val_loss: 1.5753\n",
      "Epoch 15/201\n",
      "144/144 [==============================] - 0s 580us/step - loss: 1.6010 - val_loss: 1.5867\n",
      "Epoch 16/201\n",
      "144/144 [==============================] - 0s 589us/step - loss: 1.5972 - val_loss: 1.5545\n",
      "Epoch 17/201\n",
      "144/144 [==============================] - 0s 584us/step - loss: 1.5691 - val_loss: 1.5455\n",
      "Epoch 18/201\n",
      "144/144 [==============================] - 0s 585us/step - loss: 1.5583 - val_loss: 1.5205\n",
      "Epoch 19/201\n",
      "144/144 [==============================] - 0s 579us/step - loss: 1.5497 - val_loss: 1.5286\n",
      "Epoch 20/201\n",
      "144/144 [==============================] - 0s 590us/step - loss: 1.5307 - val_loss: 1.5535\n",
      "Epoch 21/201\n",
      "144/144 [==============================] - 0s 587us/step - loss: 1.5368 - val_loss: 1.5406\n",
      "Epoch 22/201\n",
      "144/144 [==============================] - 0s 582us/step - loss: 1.5093 - val_loss: 1.5142\n",
      "Epoch 23/201\n",
      "144/144 [==============================] - 0s 590us/step - loss: 1.5101 - val_loss: 1.5168\n",
      "Epoch 24/201\n",
      "144/144 [==============================] - 0s 578us/step - loss: 1.5090 - val_loss: 1.5201\n",
      "Epoch 25/201\n",
      "144/144 [==============================] - 0s 587us/step - loss: 1.4997 - val_loss: 1.4983\n",
      "Epoch 26/201\n",
      "144/144 [==============================] - 0s 589us/step - loss: 1.4943 - val_loss: 1.4621\n",
      "Epoch 27/201\n",
      "144/144 [==============================] - 0s 599us/step - loss: 1.4763 - val_loss: 1.5074\n",
      "Epoch 28/201\n",
      "144/144 [==============================] - 0s 580us/step - loss: 1.4690 - val_loss: 1.5060\n",
      "Epoch 29/201\n",
      "144/144 [==============================] - 0s 582us/step - loss: 1.4688 - val_loss: 1.5139\n",
      "Epoch 30/201\n",
      "144/144 [==============================] - 0s 595us/step - loss: 1.4672 - val_loss: 1.4722\n",
      "Epoch 31/201\n",
      "144/144 [==============================] - 0s 578us/step - loss: 1.4624 - val_loss: 1.4638\n",
      "Epoch 32/201\n",
      "144/144 [==============================] - 0s 600us/step - loss: 1.4471 - val_loss: 1.4903\n",
      "Epoch 33/201\n",
      "144/144 [==============================] - 0s 579us/step - loss: 1.4532 - val_loss: 1.4900\n",
      "Epoch 34/201\n",
      "144/144 [==============================] - 0s 584us/step - loss: 1.4433 - val_loss: 1.5053\n",
      "Epoch 35/201\n",
      "144/144 [==============================] - 0s 582us/step - loss: 1.4298 - val_loss: 1.5084\n",
      "Epoch 36/201\n",
      "144/144 [==============================] - 0s 685us/step - loss: 1.4290 - val_loss: 1.4888\n",
      "Epoch 37/201\n",
      "144/144 [==============================] - 0s 597us/step - loss: 1.4133 - val_loss: 1.4244\n",
      "Epoch 38/201\n",
      "144/144 [==============================] - 0s 581us/step - loss: 1.4221 - val_loss: 1.4183\n",
      "Epoch 39/201\n",
      "144/144 [==============================] - 0s 582us/step - loss: 1.4129 - val_loss: 1.4885\n",
      "Epoch 40/201\n",
      "144/144 [==============================] - 0s 582us/step - loss: 1.4145 - val_loss: 1.5289\n",
      "Epoch 41/201\n",
      "144/144 [==============================] - 0s 583us/step - loss: 1.4126 - val_loss: 1.4761\n",
      "Epoch 42/201\n",
      "144/144 [==============================] - 0s 581us/step - loss: 1.4056 - val_loss: 1.4728\n",
      "Epoch 43/201\n",
      "144/144 [==============================] - 0s 591us/step - loss: 1.4151 - val_loss: 1.5864\n",
      "Epoch 44/201\n",
      "144/144 [==============================] - 0s 574us/step - loss: 1.4102 - val_loss: 1.4948\n",
      "Epoch 45/201\n",
      "144/144 [==============================] - 0s 580us/step - loss: 1.3914 - val_loss: 1.5413\n",
      "Epoch 46/201\n",
      "144/144 [==============================] - 0s 594us/step - loss: 1.3945 - val_loss: 1.5317\n",
      "Epoch 47/201\n",
      "144/144 [==============================] - 0s 577us/step - loss: 1.3860 - val_loss: 1.4511\n",
      "Epoch 48/201\n",
      "144/144 [==============================] - 0s 576us/step - loss: 1.3858 - val_loss: 1.5171\n",
      "Epoch 49/201\n",
      "144/144 [==============================] - 0s 596us/step - loss: 1.3922 - val_loss: 1.4920\n",
      "Epoch 50/201\n",
      "144/144 [==============================] - 0s 586us/step - loss: 1.3834 - val_loss: 1.4578\n",
      "Epoch 51/201\n",
      "144/144 [==============================] - 0s 583us/step - loss: 1.3732 - val_loss: 1.4524\n",
      "Epoch 52/201\n",
      "144/144 [==============================] - 0s 582us/step - loss: 1.3755 - val_loss: 1.4377\n",
      "Epoch 53/201\n",
      "144/144 [==============================] - 0s 569us/step - loss: 1.3760 - val_loss: 1.4891\n",
      "32/32 [==============================] - 0s 326us/step\n",
      "Epoch 1/201\n",
      "142/142 [==============================] - 0s 922us/step - loss: 18.6720 - val_loss: 8.3090\n",
      "Epoch 2/201\n",
      "142/142 [==============================] - 0s 587us/step - loss: 4.2159 - val_loss: 2.2975\n",
      "Epoch 3/201\n",
      "142/142 [==============================] - 0s 584us/step - loss: 2.1959 - val_loss: 2.1221\n",
      "Epoch 4/201\n",
      "142/142 [==============================] - 0s 589us/step - loss: 2.0647 - val_loss: 2.0052\n",
      "Epoch 5/201\n",
      "142/142 [==============================] - 0s 586us/step - loss: 1.9824 - val_loss: 1.9339\n",
      "Epoch 6/201\n",
      "142/142 [==============================] - 0s 587us/step - loss: 1.9165 - val_loss: 1.8845\n",
      "Epoch 7/201\n",
      "142/142 [==============================] - 0s 583us/step - loss: 1.8710 - val_loss: 1.8377\n",
      "Epoch 8/201\n",
      "142/142 [==============================] - 0s 581us/step - loss: 1.8345 - val_loss: 1.8179\n",
      "Epoch 9/201\n",
      "142/142 [==============================] - 0s 585us/step - loss: 1.7997 - val_loss: 1.7634\n",
      "Epoch 10/201\n",
      "142/142 [==============================] - 0s 592us/step - loss: 1.7746 - val_loss: 1.7700\n",
      "Epoch 11/201\n",
      "142/142 [==============================] - 0s 596us/step - loss: 1.7463 - val_loss: 1.7105\n",
      "Epoch 12/201\n",
      "142/142 [==============================] - 0s 586us/step - loss: 1.7081 - val_loss: 1.6711\n",
      "Epoch 13/201\n",
      "142/142 [==============================] - 0s 587us/step - loss: 1.6795 - val_loss: 1.6653\n",
      "Epoch 14/201\n",
      "142/142 [==============================] - 0s 586us/step - loss: 1.6544 - val_loss: 1.6252\n",
      "Epoch 15/201\n",
      "142/142 [==============================] - 0s 577us/step - loss: 1.6460 - val_loss: 1.6343\n",
      "Epoch 16/201\n",
      "142/142 [==============================] - 0s 588us/step - loss: 1.6092 - val_loss: 1.5774\n",
      "Epoch 17/201\n",
      "142/142 [==============================] - 0s 586us/step - loss: 1.6018 - val_loss: 1.5749\n",
      "Epoch 18/201\n",
      "142/142 [==============================] - 0s 579us/step - loss: 1.5919 - val_loss: 1.5632\n",
      "Epoch 19/201\n",
      "142/142 [==============================] - 0s 583us/step - loss: 1.5585 - val_loss: 1.5354\n",
      "Epoch 20/201\n",
      "142/142 [==============================] - 0s 586us/step - loss: 1.5610 - val_loss: 1.5349\n",
      "Epoch 21/201\n",
      "142/142 [==============================] - 0s 661us/step - loss: 1.5444 - val_loss: 1.5381\n",
      "Epoch 22/201\n",
      "142/142 [==============================] - 0s 596us/step - loss: 1.5279 - val_loss: 1.6046\n",
      "Epoch 23/201\n",
      "142/142 [==============================] - 0s 592us/step - loss: 1.5278 - val_loss: 1.5537\n",
      "Epoch 24/201\n",
      "142/142 [==============================] - 0s 582us/step - loss: 1.5174 - val_loss: 1.5291\n",
      "Epoch 25/201\n",
      "142/142 [==============================] - 0s 581us/step - loss: 1.5224 - val_loss: 1.5125\n",
      "Epoch 26/201\n",
      "142/142 [==============================] - 0s 587us/step - loss: 1.4979 - val_loss: 1.5554\n",
      "Epoch 27/201\n",
      "142/142 [==============================] - 0s 586us/step - loss: 1.4885 - val_loss: 1.5324\n",
      "Epoch 28/201\n",
      "142/142 [==============================] - 0s 587us/step - loss: 1.4843 - val_loss: 1.4980\n",
      "Epoch 29/201\n",
      "142/142 [==============================] - 0s 591us/step - loss: 1.4673 - val_loss: 1.4951\n",
      "Epoch 30/201\n",
      "142/142 [==============================] - 0s 589us/step - loss: 1.4632 - val_loss: 1.4879\n",
      "Epoch 31/201\n",
      "142/142 [==============================] - 0s 592us/step - loss: 1.4516 - val_loss: 1.4491\n",
      "Epoch 32/201\n",
      "142/142 [==============================] - 0s 587us/step - loss: 1.4386 - val_loss: 1.4782\n",
      "Epoch 33/201\n",
      "142/142 [==============================] - 0s 587us/step - loss: 1.4427 - val_loss: 1.4325\n",
      "Epoch 34/201\n",
      "142/142 [==============================] - 0s 597us/step - loss: 1.4436 - val_loss: 1.4648\n",
      "Epoch 35/201\n",
      "142/142 [==============================] - 0s 590us/step - loss: 1.4158 - val_loss: 1.4449\n",
      "Epoch 36/201\n",
      "142/142 [==============================] - 0s 587us/step - loss: 1.4192 - val_loss: 1.4250\n",
      "Epoch 37/201\n",
      "142/142 [==============================] - 0s 590us/step - loss: 1.4170 - val_loss: 1.4163\n",
      "Epoch 38/201\n",
      "142/142 [==============================] - 0s 579us/step - loss: 1.4167 - val_loss: 1.4378\n",
      "Epoch 39/201\n",
      "142/142 [==============================] - 0s 601us/step - loss: 1.3945 - val_loss: 1.4471\n",
      "Epoch 40/201\n",
      "142/142 [==============================] - 0s 601us/step - loss: 1.3949 - val_loss: 1.4660\n",
      "Epoch 41/201\n",
      "142/142 [==============================] - 0s 584us/step - loss: 1.3953 - val_loss: 1.4026\n",
      "Epoch 42/201\n",
      "142/142 [==============================] - 0s 580us/step - loss: 1.3986 - val_loss: 1.4753\n",
      "Epoch 43/201\n",
      "142/142 [==============================] - 0s 593us/step - loss: 1.3701 - val_loss: 1.4232\n",
      "Epoch 44/201\n",
      "142/142 [==============================] - 0s 583us/step - loss: 1.3767 - val_loss: 1.4587\n",
      "Epoch 45/201\n",
      "142/142 [==============================] - 0s 594us/step - loss: 1.3756 - val_loss: 1.4697\n",
      "Epoch 46/201\n",
      "142/142 [==============================] - 0s 582us/step - loss: 1.3531 - val_loss: 1.4361\n",
      "Epoch 47/201\n",
      "142/142 [==============================] - 0s 582us/step - loss: 1.3747 - val_loss: 1.4022\n",
      "Epoch 48/201\n",
      "142/142 [==============================] - 0s 592us/step - loss: 1.3585 - val_loss: 1.4566\n",
      "Epoch 49/201\n",
      "142/142 [==============================] - 0s 579us/step - loss: 1.3623 - val_loss: 1.4581\n",
      "Epoch 50/201\n",
      "142/142 [==============================] - 0s 590us/step - loss: 1.3511 - val_loss: 1.3404\n",
      "Epoch 51/201\n",
      "142/142 [==============================] - 0s 592us/step - loss: 1.3453 - val_loss: 1.4293\n",
      "Epoch 52/201\n",
      "142/142 [==============================] - 0s 591us/step - loss: 1.3470 - val_loss: 1.3748\n",
      "Epoch 53/201\n",
      "142/142 [==============================] - 0s 588us/step - loss: 1.3472 - val_loss: 1.4558\n",
      "Epoch 54/201\n",
      "142/142 [==============================] - 0s 588us/step - loss: 1.3409 - val_loss: 1.3879\n",
      "Epoch 55/201\n",
      "142/142 [==============================] - 0s 581us/step - loss: 1.3305 - val_loss: 1.3245\n",
      "Epoch 56/201\n",
      "142/142 [==============================] - 0s 585us/step - loss: 1.3262 - val_loss: 1.4400\n",
      "Epoch 57/201\n",
      "142/142 [==============================] - 0s 598us/step - loss: 1.3408 - val_loss: 1.4397\n",
      "Epoch 58/201\n",
      "142/142 [==============================] - 0s 578us/step - loss: 1.3375 - val_loss: 1.3930\n",
      "Epoch 59/201\n",
      "142/142 [==============================] - 0s 582us/step - loss: 1.3367 - val_loss: 1.3704\n",
      "Epoch 60/201\n",
      "142/142 [==============================] - 0s 583us/step - loss: 1.3164 - val_loss: 1.3767\n",
      "Epoch 61/201\n",
      "142/142 [==============================] - 0s 586us/step - loss: 1.3183 - val_loss: 1.3955\n",
      "Epoch 62/201\n",
      "142/142 [==============================] - 0s 587us/step - loss: 1.3037 - val_loss: 1.4531\n",
      "Epoch 63/201\n",
      "142/142 [==============================] - 0s 594us/step - loss: 1.3335 - val_loss: 1.3802\n",
      "Epoch 64/201\n",
      "142/142 [==============================] - 0s 581us/step - loss: 1.3103 - val_loss: 1.4238\n",
      "Epoch 65/201\n",
      "142/142 [==============================] - 0s 588us/step - loss: 1.3149 - val_loss: 1.4079\n",
      "Epoch 66/201\n",
      "142/142 [==============================] - 0s 578us/step - loss: 1.3037 - val_loss: 1.4043\n",
      "Epoch 67/201\n",
      "142/142 [==============================] - 0s 582us/step - loss: 1.3061 - val_loss: 1.4013\n",
      "Epoch 68/201\n",
      "142/142 [==============================] - 0s 588us/step - loss: 1.2930 - val_loss: 1.3522\n",
      "Epoch 69/201\n",
      "142/142 [==============================] - 0s 588us/step - loss: 1.2964 - val_loss: 1.4057\n",
      "Epoch 70/201\n",
      "142/142 [==============================] - 0s 590us/step - loss: 1.2900 - val_loss: 1.3503\n",
      "32/32 [==============================] - 0s 341us/step\n",
      "\n",
      "Overall Average Accuracy: 0.5863\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "for fold, (train_index, val_index) in enumerate(stratified_kfold.split(range(len(all_labels)), all_labels)):\n",
    "    # Prepare training and validation datasets\n",
    "    X_train, y_train, X_val, y_val = prepare_datasets(fold)\n",
    "\n",
    "    # Build, compile, and train the model\n",
    "    model = build_and_train_model(X_train, y_train, X_val, y_val, num_epochs)\n",
    "\n",
    "    # Evaluate and store accuracy for this fold\n",
    "    fold_accuracy = evaluate_model(model, X_val, y_val)\n",
    "    cv_scores.append(fold_accuracy)\n",
    "\n",
    "# Calculate and store the average accuracy for these hyperparameters\n",
    "overall_average_accuracy = np.mean(cv_scores)\n",
    "print(f\"\\nOverall Average Accuracy: {overall_average_accuracy:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:12:02.873230Z",
     "start_time": "2023-11-27T23:11:10.412523Z"
    }
   },
   "id": "d93a9e73baae778"
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "### CNN\n",
    "# Reshape data for CNN\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1], 1))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train_onehot = to_categorical(y_train_encoded)\n",
    "y_test_onehot = to_categorical(y_test_encoded)\n",
    "# Define the CNN model with different activation functions for hidden layers\n",
    "activation_functions = ['tanh', 'relu', 'sigmoid']\n",
    "\n",
    "for activation1 in activation_functions:\n",
    "    for activation2 in activation_functions:\n",
    "        # Define the CNN model\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1, X_train_scaled.shape[1], 1)))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(64, (3, 3), activation=activation1))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(64, (3, 3), activation=activation2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64, activation=activation1))\n",
    "        model.add(Dense(y_train_onehot.shape[1], activation='sigmoid'))  # Sigmoid for the output layer\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train_onehot, epochs=10, validation_split=0.2)\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test_reshaped, y_test_onehot)\n",
    "print(f'Test \n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7b1d35b852f08d3"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:10:00.592544Z",
     "start_time": "2023-11-27T23:10:00.585565Z"
    }
   },
   "id": "55b1ea5c60f882ac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
