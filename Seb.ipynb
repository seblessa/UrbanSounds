{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "869bfaa48bc07b43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Input de DataSet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c4c1db19cb01c9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datasets = [pd.read_csv(f'datasets/urbansounds_features_{i}.csv') for i in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b44e345a051e112"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clean the DataSet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d210a4e9b159b459"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for df in datasets:\n",
    "    object_columns = df.select_dtypes(include=['object']).columns\n",
    "    print(object_columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e83bc63c16e41066"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_mean_from_string(string):\n",
    "    cleaned_string = string.replace('\\n', '')\n",
    "    numbers = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", cleaned_string)\n",
    "    array = np.array(numbers, dtype=float)\n",
    "    mean_value = np.mean(array)\n",
    "    return mean_value"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c658efd7620a805"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for df in datasets:\n",
    "    column_intervals = df.describe().loc[['min', 'max']]\n",
    "    print(column_intervals)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91f03a82f7eb7eb4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for df in datasets:\n",
    "    for column in df.columns:\n",
    "        if column != 'Label':\n",
    "            if df[column].dtype != float and df[column].dtype != int:\n",
    "                df[column] = df[column].apply(calculate_mean_from_string)\n",
    "            df[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())\n",
    "        else:\n",
    "            df[column] = df[column].str.split('-').str[1].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f5fcf8e7522bca0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fold = 0\n",
    "for df in datasets:\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    fold += 1\n",
    "    class_counts = df['Label'].value_counts()\n",
    "    class_labels = class_counts.index\n",
    "    class_values = class_counts.values\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(class_labels, class_values, color='skyblue')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Class Distribution')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76863a4fd276ac6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59f1fbbc0b0e99c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_learning_curve(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45870f8742979d5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_labels):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfcac10f9d44c870"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_datasets(fold):\n",
    "    test_data = datasets[fold]\n",
    "    test_labels = test_data['Label'].values\n",
    "    test_data = test_data.drop(columns=['Label']).values\n",
    "\n",
    "    train_datasets = datasets[:fold] + datasets[fold + 1:]\n",
    "\n",
    "    train_data = pd.concat(train_datasets)\n",
    "    train_labels = train_data['Label'].values\n",
    "    train_data = train_data.drop(columns=['Label']).values\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25885b3e3e64ba0f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_MLP(input_neurons, hidden_neurons, output_neurons, learning_rate, regulizer, dropout):\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=input_neurons, activation='relu', kernel_regularizer=tf.keras.regularizers.L1L2(l1=regulizer, l2=regulizer)),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(units=hidden_neurons, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(units=hidden_neurons, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(units=output_neurons, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ae637cec6904f59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_MLP(train_data, train_labels, test_data, test_labels, patience, batch_size, num_epochs):\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "    history = model.fit(train_data, train_labels,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks = [early_stopping],\n",
    "                        validation_data = (test_data,test_labels),\n",
    "                        verbose=0)\n",
    "    \n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fe63bfe5d07f9f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_CNN(input_shape, num_classes, learning_rate, dropout_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Reshape((input_shape[0], 1), input_shape=input_shape),\n",
    "        tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Conv1D(128, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e226c244ab30a6c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_CNN(train_data, train_labels, test_data, test_labels, patience, batch_size, num_epochs):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "    history = cnn_model.fit(train_data, train_labels,\n",
    "                            epochs=num_epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=[early_stopping],\n",
    "                            validation_data=(test_data, test_labels),\n",
    "                            verbose=0)\n",
    "\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6442eefdb5508611"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bfd368bffa4a2eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv_scores_mlp = []\n",
    "\n",
    "for fold in range(10):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    train_data, train_labels, test_data, test_labels = prepare_datasets(fold)\n",
    "\n",
    "    model = build_MLP(input_neurons=512,\n",
    "                      hidden_neurons=512,\n",
    "                      output_neurons=10,\n",
    "                      learning_rate=0.0005,\n",
    "                      regulizer=0.001,\n",
    "                      dropout=0.5)\n",
    "\n",
    "    history = train_MLP(train_data, train_labels, test_data, test_labels,\n",
    "                        patience=20,\n",
    "                        batch_size=128,\n",
    "                        num_epochs=50)\n",
    "    plot_learning_curve(history)  # Uncomment if you want to visualize the learning curve\n",
    "\n",
    "    predictions = model.predict(test_data)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    plot_confusion_matrix(test_labels, predicted_labels, class_labels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "    cv_scores_mlp.append(accuracy)\n",
    "\n",
    "overall_average_accuracy_mlp = np.mean(cv_scores_mlp)\n",
    "print(f\"\\nAverage Accuracy for MLP: {overall_average_accuracy_mlp:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d93a9e73baae778"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73859e78b1ea6fc0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv_scores_cnn = []\n",
    "for fold in range(10):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    train_data, train_labels, test_data, test_labels = prepare_datasets(fold)\n",
    "\n",
    "    cnn_model = build_CNN(input_shape=train_data.shape[1:],\n",
    "                          num_classes=10,\n",
    "                          learning_rate=0.0001,\n",
    "                          dropout_rate=0.5)\n",
    "\n",
    "    history = train_CNN(train_data, train_labels, test_data, test_labels,\n",
    "                        patience=5,\n",
    "                        batch_size=32,\n",
    "                        num_epochs=50)\n",
    "    #plot_learning_curve(history)  # Uncomment if you want to visualize the learning curve\n",
    "\n",
    "    predictions_cnn = cnn_model.predict(test_data)\n",
    "    predicted_labels_cnn = np.argmax(predictions_cnn, axis=1)\n",
    "    #plot_confusion_matrix(test_labels, predicted_labels, class_labels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels_cnn)\n",
    "    cv_scores_cnn.append(accuracy)\n",
    "\n",
    "overall_average_accuracy_cnn = np.mean(cv_scores_cnn)\n",
    "print(f\"\\nAccuracy for CNN: {overall_average_accuracy_cnn:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6993a01f2459e15f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4f81da8ca95d39d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
