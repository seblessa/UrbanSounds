{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Urban Sounds Project"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ae9e0fec09635db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Brief Description of the Classification Problem\n",
    "\n",
    "The classification problem addressed in this project involves urban sound data classification. The dataset used is the urbansound8k dataset, consisting of 8732 labeled sound excerpts categorized into ten classes. The objective is to develop deep learning classifiers capable of accurately identifying the class to which a given sound excerpt belongs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "339df1996ed9249c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e7060e7bdacd96b"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:27.227684500Z",
     "start_time": "2023-11-27T19:21:26.673896500Z"
    }
   },
   "id": "8d82c7c99b1ed9c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data pre-processing and preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6bc04232b48ba3d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtaining the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e67cd87072766a2e"
  },
  {
   "cell_type": "raw",
   "source": [
    "To obtain the input for our neural networks, we used Librosa to preprocess original raw sound data and extract the features. To adress the fact that the files had different durations and sampling rates, we standardized the netwok input. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d41f5703a737805"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We used the following python script:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44001d6163a9a761"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "# python features.py"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:27.290618500Z",
     "start_time": "2023-11-27T19:21:26.738235900Z"
    }
   },
   "id": "2d9a5a3e61f97ee8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Unifying the class labels with the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8eae2cb53400ed3b"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "datasets = [pd.read_csv(f'datasets/urbansounds_features_{i}.csv') for i in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:27.417619600Z",
     "start_time": "2023-11-27T19:21:26.794036400Z"
    }
   },
   "id": "6cdfbdc264834116"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "for df in datasets:\n",
    "    df['Label'] = df['Label'].str.split('-').str[1].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:27.421518400Z",
     "start_time": "2023-11-27T19:21:27.091344300Z"
    }
   },
   "id": "aafd04f9b469065f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check for object values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c034aea69a323224"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fourier_tempogram'], dtype='object')\n",
      "Index(['fourier_tempogram'], dtype='object')\n",
      "Index(['fourier_tempogram'], dtype='object')\n",
      "Index(['fourier_tempogram'], dtype='object')\n",
      "Index(['fourier_tempogram'], dtype='object')\n",
      "Index(['fourier_tempogram'], dtype='object')\n",
      "Index(['fourier_tempogram'], dtype='object')\n",
      "Index(['fourier_tempogram'], dtype='object')\n",
      "Index(['fourier_tempogram'], dtype='object')\n",
      "Index(['fourier_tempogram'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for df in datasets:\n",
    "    object_columns = df.select_dtypes(include=['object']).columns\n",
    "    print(object_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:27.424643600Z",
     "start_time": "2023-11-27T19:21:27.177680800Z"
    }
   },
   "id": "f65c804196328d09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert the columns with object values to numeric"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d48df21866757fa7"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def calculate_mean_from_string(string):\n",
    "    cleaned_string = string.replace('\\n', '')\n",
    "    numbers = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", cleaned_string)\n",
    "    array = np.array(numbers, dtype=float)\n",
    "    mean_value = np.mean(array)\n",
    "    return mean_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:27.496500800Z",
     "start_time": "2023-11-27T19:21:27.237437700Z"
    }
   },
   "id": "3544df71325d6bd2"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "for df in datasets:\n",
    "    df['Label'] = df['Label'].astype('int64')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:27.496500800Z",
     "start_time": "2023-11-27T19:21:27.293601100Z"
    }
   },
   "id": "ad2e3f46d1a4e11d"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "for df in datasets:\n",
    "    df['fourier_tempogram'] = df['fourier_tempogram'].apply(calculate_mean_from_string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:27.542626300Z",
     "start_time": "2023-11-27T19:21:27.345670300Z"
    }
   },
   "id": "ff62029e4b0d3140"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check interval of the values per column"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a100958047e33f6a"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     chroma_stft  chroma_cqt  chroma_cens  melspectogram       rms  \\\n",
      "min     0.009734    0.150077     0.126660       0.017318  0.001788   \n",
      "max     0.829676    0.768014     0.285653      30.430030  0.473862   \n",
      "\n",
      "         centroid    bandwidth   contrast      flatness       rolloff  ...  \\\n",
      "min     50.916749    71.255507   5.698971  6.211397e-07    106.979450  ...   \n",
      "max  10907.707763  7088.299210  24.957858  9.798845e-01  18628.717306  ...   \n",
      "\n",
      "      mcffs_32   mcffs_33   mcffs_34   mcffs_35  mcffs_36   mcffs_37  \\\n",
      "min -11.730761 -13.273888 -15.653493  -9.955764 -6.521128 -21.866919   \n",
      "max  11.225185   9.078557  15.806270  17.319443  9.707691  17.943160   \n",
      "\n",
      "      mcffs_38  mcffs_39   mcffs_40  Label  \n",
      "min -19.719917 -8.652861  -6.523879    0.0  \n",
      "max   7.872053  7.306795  16.392504    9.0  \n",
      "\n",
      "[2 rows x 54 columns]\n",
      "     chroma_stft  chroma_cqt  chroma_cens  melspectogram       rms  \\\n",
      "min     0.008760    0.191508     0.136980       0.056502  0.004293   \n",
      "max     0.841217    0.770370     0.285354      37.137154  0.429745   \n",
      "\n",
      "        centroid    bandwidth   contrast      flatness       rolloff  ...  \\\n",
      "min    49.252793    66.012024   6.835172  7.250020e-07     81.951002  ...   \n",
      "max  9649.628012  6210.199377  26.656439  9.769815e-01  16049.226817  ...   \n",
      "\n",
      "      mcffs_32   mcffs_33   mcffs_34   mcffs_35   mcffs_36   mcffs_37  \\\n",
      "min  -8.562698  -8.857742 -28.116508 -16.732386  -9.669321  -9.014714   \n",
      "max  19.055628  15.425904  19.032192   9.651651  13.605964  15.806260   \n",
      "\n",
      "      mcffs_38   mcffs_39   mcffs_40  Label  \n",
      "min -14.455148 -25.212177  -8.091895    0.0  \n",
      "max  12.007599  15.839479  10.384581    9.0  \n",
      "\n",
      "[2 rows x 54 columns]\n",
      "     chroma_stft  chroma_cqt  chroma_cens  melspectogram       rms  \\\n",
      "min     0.011193    0.246356     0.160398       0.141129  0.004323   \n",
      "max     0.815988    0.781397     0.286841      27.656479  0.371997   \n",
      "\n",
      "        centroid    bandwidth   contrast  flatness       rolloff  ...  \\\n",
      "min    72.032851    86.393303   6.121635  0.000003    106.667374  ...   \n",
      "max  9302.891833  6838.206659  28.447600  0.968717  16861.371858  ...   \n",
      "\n",
      "      mcffs_32   mcffs_33   mcffs_34  mcffs_35   mcffs_36  mcffs_37  \\\n",
      "min -10.224414 -12.514686 -18.301588  -9.72367  -9.881489 -36.00162   \n",
      "max  13.357989  11.498531  22.999128  20.50359  15.244874  13.54776   \n",
      "\n",
      "      mcffs_38   mcffs_39   mcffs_40  Label  \n",
      "min -23.080887 -15.502398 -10.775697    0.0  \n",
      "max  12.303746  15.874513  30.761436    9.0  \n",
      "\n",
      "[2 rows x 54 columns]\n",
      "     chroma_stft  chroma_cqt  chroma_cens  melspectogram       rms  \\\n",
      "min     0.018952    0.118011     0.135476       0.081580  0.004169   \n",
      "max     0.845297    0.768601     0.285287      60.948204  0.575854   \n",
      "\n",
      "        centroid    bandwidth   contrast  flatness       rolloff  ...  \\\n",
      "min    87.871842   160.802916   6.436099  0.000006    139.497707  ...   \n",
      "max  7774.931855  6041.312300  29.609336  0.936451  15006.145975  ...   \n",
      "\n",
      "      mcffs_32   mcffs_33   mcffs_34   mcffs_35   mcffs_36   mcffs_37  \\\n",
      "min -10.836937 -10.218656 -15.435268 -12.737843 -14.382623 -16.144730   \n",
      "max   9.309839  12.763174  11.433029  10.226897   7.719594   9.732591   \n",
      "\n",
      "      mcffs_38   mcffs_39   mcffs_40  Label  \n",
      "min  -8.723951 -11.227740  -9.708144    0.0  \n",
      "max  11.747471  11.973821  11.659305    9.0  \n",
      "\n",
      "[2 rows x 54 columns]\n",
      "     chroma_stft  chroma_cqt  chroma_cens  melspectogram       rms  \\\n",
      "min     0.018082    0.118594     0.129385       0.019171  0.007294   \n",
      "max     0.790057    0.757036     0.286403      41.873447  0.442878   \n",
      "\n",
      "        centroid    bandwidth   contrast  flatness       rolloff  ...  \\\n",
      "min   122.151257   140.431245   4.937569  0.000003    196.357846  ...   \n",
      "max  7494.248007  5995.662671  27.790652  0.948505  15087.909732  ...   \n",
      "\n",
      "      mcffs_32   mcffs_33   mcffs_34   mcffs_35   mcffs_36   mcffs_37  \\\n",
      "min -12.037837 -10.771301 -12.592191 -13.393154 -14.576315 -19.017796   \n",
      "max  17.188639   8.161142  13.814629  17.931572  12.500184  14.091709   \n",
      "\n",
      "      mcffs_38   mcffs_39   mcffs_40  Label  \n",
      "min -12.701076 -19.338745  -8.778230    0.0  \n",
      "max  12.863924  13.638488  13.752348    9.0  \n",
      "\n",
      "[2 rows x 54 columns]\n",
      "     chroma_stft  chroma_cqt  chroma_cens  melspectogram       rms  \\\n",
      "min     0.018636    0.161851     0.149377       0.081223  0.008652   \n",
      "max     0.838118    0.765177     0.286536      65.208150  0.579545   \n",
      "\n",
      "        centroid    bandwidth   contrast      flatness       rolloff  ...  \\\n",
      "min    66.627023   109.240932   7.307582  1.648695e-07    119.524881  ...   \n",
      "max  7725.235884  5763.110328  24.917774  9.653892e-01  13310.765115  ...   \n",
      "\n",
      "      mcffs_32   mcffs_33   mcffs_34   mcffs_35   mcffs_36   mcffs_37  \\\n",
      "min -10.039631 -11.110918 -20.384760 -16.987791 -10.798503 -11.089042   \n",
      "max  11.509049  15.133594  14.076449  12.679124  17.888403  16.002964   \n",
      "\n",
      "      mcffs_38   mcffs_39  mcffs_40  Label  \n",
      "min -11.267698 -12.050951 -8.334151    0.0  \n",
      "max  17.683758  17.977505  8.111068    9.0  \n",
      "\n",
      "[2 rows x 54 columns]\n",
      "     chroma_stft  chroma_cqt  chroma_cens  melspectogram       rms  \\\n",
      "min     0.011323    0.134700     0.141283       0.089403  0.004244   \n",
      "max     0.789111    0.780107     0.286375      40.989822  0.449012   \n",
      "\n",
      "        centroid    bandwidth   contrast  flatness       rolloff  ...  \\\n",
      "min    79.735291   115.307907   5.223736  0.000002    158.534307  ...   \n",
      "max  8220.148207  6335.742223  29.579527  0.968232  15116.433424  ...   \n",
      "\n",
      "      mcffs_32   mcffs_33   mcffs_34   mcffs_35   mcffs_36   mcffs_37  \\\n",
      "min -11.189391 -17.787052 -19.627250  -9.220816  -8.335374 -12.944612   \n",
      "max  12.392091   9.126044  13.542929  15.465391  26.710932  13.507866   \n",
      "\n",
      "     mcffs_38   mcffs_39   mcffs_40  Label  \n",
      "min -9.360201 -22.499403 -11.073814    0.0  \n",
      "max  9.924988  11.854188   7.270949    9.0  \n",
      "\n",
      "[2 rows x 54 columns]\n",
      "     chroma_stft  chroma_cqt  chroma_cens  melspectogram       rms  \\\n",
      "min     0.027624    0.209691     0.160501       0.047600  0.008129   \n",
      "max     0.776577    0.766370     0.286276      29.010012  0.383450   \n",
      "\n",
      "        centroid    bandwidth   contrast      flatness       rolloff  ...  \\\n",
      "min   171.176903   134.987998   3.938343  3.259748e-07    258.835343  ...   \n",
      "max  8610.982660  6463.559971  29.197910  9.247536e-01  14300.730724  ...   \n",
      "\n",
      "      mcffs_32   mcffs_33   mcffs_34   mcffs_35   mcffs_36   mcffs_37  \\\n",
      "min -12.144473 -10.587364 -10.570888  -8.224007 -11.478420 -21.858710   \n",
      "max   9.731817  10.857246  13.283563  14.792252  11.301182  13.440571   \n",
      "\n",
      "      mcffs_38   mcffs_39   mcffs_40  Label  \n",
      "min -17.118616 -12.516760  -8.378198    0.0  \n",
      "max   7.734037  11.476712  17.309792    9.0  \n",
      "\n",
      "[2 rows x 54 columns]\n",
      "     chroma_stft  chroma_cqt  chroma_cens  melspectogram       rms  \\\n",
      "min     0.012754    0.133887     0.132305       0.068265  0.007172   \n",
      "max     0.813969    0.796146     0.286581      42.074318  0.441603   \n",
      "\n",
      "        centroid   bandwidth   contrast  flatness       rolloff  ...  \\\n",
      "min    98.548347   155.68632   6.509426  0.000002    172.702531  ...   \n",
      "max  9381.349897  7532.17355  27.799336  0.950966  16029.066746  ...   \n",
      "\n",
      "      mcffs_32   mcffs_33   mcffs_34   mcffs_35   mcffs_36   mcffs_37  \\\n",
      "min -10.430635 -14.807711 -16.851736 -13.927504 -11.547859 -11.959375   \n",
      "max  14.930509   7.991449   7.569722  11.051983  13.134392  23.912758   \n",
      "\n",
      "      mcffs_38   mcffs_39   mcffs_40  Label  \n",
      "min -12.208859 -15.214489 -13.395362    0.0  \n",
      "max  16.751150   8.754570  10.377467    9.0  \n",
      "\n",
      "[2 rows x 54 columns]\n",
      "     chroma_stft  chroma_cqt  chroma_cens  melspectogram       rms  \\\n",
      "min     0.023939    0.256517     0.190044       0.019518  0.002765   \n",
      "max     0.790466    0.783527     0.284694      36.575670  0.450142   \n",
      "\n",
      "        centroid    bandwidth   contrast  flatness       rolloff  ...  \\\n",
      "min   111.006078   103.526108   5.143718  0.000004    139.809783  ...   \n",
      "max  8412.624246  6368.270229  25.370219  0.933467  13919.312160  ...   \n",
      "\n",
      "      mcffs_32   mcffs_33   mcffs_34   mcffs_35   mcffs_36   mcffs_37  \\\n",
      "min -12.059825 -19.343061 -18.082764 -13.520592 -12.394710 -23.289728   \n",
      "max  12.270103   9.016389  19.162848  15.465177  12.451557  10.335349   \n",
      "\n",
      "      mcffs_38   mcffs_39   mcffs_40  Label  \n",
      "min -18.298126 -13.195601  -7.200416    0.0  \n",
      "max  14.255067  10.949442  17.499722    9.0  \n",
      "\n",
      "[2 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "for df in datasets:\n",
    "    column_intervals = df.describe().loc[['min', 'max']]\n",
    "    print(column_intervals)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:28.150000900Z",
     "start_time": "2023-11-27T19:21:27.495496400Z"
    }
   },
   "id": "407fb27058a8d22b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check the distribution of the classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "148d274fee790231"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAAIjCAYAAAAZajMiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxdklEQVR4nO3de1RU9d7H8c9wGwi5KCaXQkGzRLwm6kF8Sos0U9OVXeyxMk9azxNoSFlS4oU0y46XvGer9PSUx8qOZlaWoemxUBHzVt41NQ2sDFAL9MB+/mg560yKyYhu+Pl+rTVrOXvv2fPdzNL1Xts9G4dlWZYAAAAAA3jZPQAAAABQVYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwBXjJiYGD388MN2j3HRRo8eLYfDcVneq1OnTurUqZPr+RdffCGHw6GFCxdelvd/+OGHFRMTc1neC4AZiFsANd7evXv12GOPqWHDhvL391dwcLCSkpL0yiuv6LfffrN7vPOaN2+eHA6H6+Hv76+oqCh17dpVU6dO1fHjx6vkfY4cOaLRo0dr06ZNVbK/qlSdZwNQ8/jYPQAAXIyPPvpI99xzj5xOpx566CE1a9ZMp06d0po1azRs2DB98803mjNnjt1j/qmsrCzFxsbq9OnTys/P1xdffKG0tDRNmjRJS5YsUYsWLVzbjhgxQsOHD6/U/o8cOaIxY8YoJiZGrVq1uuDXffbZZ5V6H0+cb7bXXntN5eXll3wGAOYgbgHUWPv371ffvn3VoEEDrVixQpGRka51KSkp2rNnjz766CMbJ7xw3bp1U0JCgut5RkaGVqxYoR49eujOO+/U9u3bFRAQIEny8fGRj8+l/ef7119/1VVXXSU/P79L+j5/xtfX19b3B1DzcFkCgBprwoQJOnHihF5//XW3sD3juuuu0xNPPFHh648dO6annnpKzZs3V61atRQcHKxu3bpp8+bNZ207bdo0xcfH66qrrlLt2rWVkJCg+fPnu9YfP35caWlpiomJkdPpVL169XTbbbdp48aNHh/fLbfcoszMTB04cEBvvfWWa/m5rrldvny5OnbsqNDQUNWqVUs33HCDnn32WUm/Xyfbtm1bSdKAAQNcl0DMmzdP0u/X1TZr1kx5eXm66aabdNVVV7le+8drbs8oKyvTs88+q4iICAUGBurOO+/UoUOH3Lap6Brn/9znn812rmtuT548qSeffFLR0dFyOp264YYb9Le//U2WZblt53A4lJqaqsWLF6tZs2ZyOp2Kj4/XsmXLzv0DB2AEztwCqLE+/PBDNWzYUB06dPDo9fv27dPixYt1zz33KDY2VgUFBXr11Vd1880369tvv1VUVJSk3/9rfMiQIbr77rv1xBNPqKSkRFu2bNG6dev03//935Kk//mf/9HChQuVmpqqpk2b6ueff9aaNWu0fft23XjjjR4f44MPPqhnn31Wn332mQYNGnTObb755hv16NFDLVq0UFZWlpxOp/bs2aMvv/xSkhQXF6esrCyNHDlSjz76qP7rv/5Lktx+bj///LO6deumvn376oEHHlB4ePh55xo3bpwcDoeeeeYZHT16VFOmTFFycrI2bdrkOsN8IS5ktv9kWZbuvPNOrVy5Uo888ohatWqlTz/9VMOGDdPhw4c1efJkt+3XrFmjf/7zn3r88ccVFBSkqVOnqk+fPjp48KDCwsIueE4ANYgFADVQUVGRJcnq1avXBb+mQYMGVv/+/V3PS0pKrLKyMrdt9u/fbzmdTisrK8u1rFevXlZ8fPx59x0SEmKlpKRc8CxnzJ0715Jk5ebmnnffrVu3dj0fNWqU9Z//fE+ePNmSZP34448V7iM3N9eSZM2dO/esdTfffLMlyZo9e/Y51918882u5ytXrrQkWddcc41VXFzsWv7uu+9akqxXXnnFteyPP++K9nm+2fr37281aNDA9Xzx4sWWJGvs2LFu2919992Ww+Gw9uzZ41omyfLz83NbtnnzZkuSNW3atLPeC4AZuCwBQI1UXFwsSQoKCvJ4H06nU15ev/8zWFZWpp9//tn1X/r/eTlBaGiovv/+e+Xm5la4r9DQUK1bt05HjhzxeJ6K1KpV67x3TQgNDZUkffDBBx5/+crpdGrAgAEXvP1DDz3k9rO/++67FRkZqY8//tij979QH3/8sby9vTVkyBC35U8++aQsy9Inn3zitjw5OVmNGjVyPW/RooWCg4O1b9++SzonAPsQtwBqpODgYEm6qFtllZeXa/LkyWrcuLGcTqfq1q2rq6++Wlu2bFFRUZFru2eeeUa1atVSu3bt1LhxY6WkpLj+y/+MCRMmaNu2bYqOjla7du00evToKguoEydOnDfi77vvPiUlJWngwIEKDw9X37599e6771YqdK+55ppKfXmscePGbs8dDoeuu+46fffddxe8D08cOHBAUVFRZ/084uLiXOv/U/369c/aR+3atfXLL79cuiEB2Iq4BVAjBQcHKyoqStu2bfN4Hy+88ILS09N100036a233tKnn36q5cuXKz4+3i0M4+LitHPnTi1YsEAdO3bU+++/r44dO2rUqFGube69917t27dP06ZNU1RUlF5++WXFx8efdSaxsr7//nsVFRXpuuuuq3CbgIAArV69Wp9//rkefPBBbdmyRffdd59uu+02lZWVXdD7VOY62QtV0S+auNCZqoK3t/c5l1t/+PIZAHMQtwBqrB49emjv3r3Kycnx6PULFy5U586d9frrr6tv377q0qWLkpOTVVhYeNa2gYGBuu+++zR37lwdPHhQ3bt317hx41RSUuLaJjIyUo8//rgWL16s/fv3KywsTOPGjfP08CRJ//d//ydJ6tq163m38/Ly0q233qpJkybp22+/1bhx47RixQqtXLlSUsWh6andu3e7PbcsS3v27HG7s0Ht2rXP+bP849nVyszWoEEDHTly5Kwz9jt27HCtB3BlI24B1FhPP/20AgMDNXDgQBUUFJy1fu/evXrllVcqfL23t/dZZ/Dee+89HT582G3Zzz//7Pbcz89PTZs2lWVZOn36tMrKytwuY5CkevXqKSoqSqWlpZU9LJcVK1bo+eefV2xsrPr161fhdseOHTtr2ZlfhnDm/QMDAyXpnLHpiTfffNMtMBcuXKgffvhB3bp1cy1r1KiR1q5dq1OnTrmWLV269KxbhlVmtjvuuENlZWWaPn262/LJkyfL4XC4vT+AKxO3AgNQYzVq1Ejz58/Xfffdp7i4OLffUPbVV1/pvffeO+d9Vs/o0aOHsrKyNGDAAHXo0EFbt27V22+/rYYNG7pt16VLF0VERCgpKUnh4eHavn27pk+fru7duysoKEiFhYW69tprdffdd6tly5aqVauWPv/8c+Xm5mrixIkXdCyffPKJduzYoX//+98qKCjQihUrtHz5cjVo0EBLliyRv79/ha/NysrS6tWr1b17dzVo0EBHjx7VzJkzde2116pjx46un1VoaKhmz56toKAgBQYGqn379oqNjb2g+f6oTp066tixowYMGKCCggJNmTJF1113ndvtygYOHKiFCxfq9ttv17333qu9e/fqrbfecvuCV2Vn69mzpzp37qznnntO3333nVq2bKnPPvtMH3zwgdLS0s7aN4ArkK33agCAKrBr1y5r0KBBVkxMjOXn52cFBQVZSUlJ1rRp06ySkhLXdue6FdiTTz5pRUZGWgEBAVZSUpKVk5Nz1q2qXn31Veumm26ywsLCLKfTaTVq1MgaNmyYVVRUZFmWZZWWllrDhg2zWrZsaQUFBVmBgYFWy5YtrZkzZ/7p7GduBXbm4efnZ0VERFi33Xab9corr7jdbuuMP94KLDs72+rVq5cVFRVl+fn5WVFRUdb9999v7dq1y+11H3zwgdW0aVPLx8fH7dZbN998c4W3OqvoVmD/+Mc/rIyMDKtevXpWQECA1b17d+vAgQNnvX7ixInWNddcYzmdTispKcnasGHDWfs832x/vBWYZVnW8ePHraFDh1pRUVGWr6+v1bhxY+vll1+2ysvL3baTdM7bs1V0izIAZnBYFlfVAwAAwAxccwsAAABjELcAAAAwBnELAAAAYxC3AAAAMAZxCwAAAGMQtwAAADAGv8RBUnl5uY4cOaKgoKAq/xWVAAAAuHiWZen48eOKioqSl1fF52eJW0lHjhxRdHS03WMAAADgTxw6dEjXXnttheuJW0lBQUGSfv9hBQcH2zwNAAAA/qi4uFjR0dGubqsIcSu5LkUIDg4mbgEAAKqxP7uElC+UAQAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBg+dg8AALh8Xvz6J7tH8Mjw1nXtHgFADcGZWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDFsjdvVq1erZ8+eioqKksPh0OLFi93WW5alkSNHKjIyUgEBAUpOTtbu3bvdtjl27Jj69eun4OBghYaG6pFHHtGJEycu41EAAACgurA1bk+ePKmWLVtqxowZ51w/YcIETZ06VbNnz9a6desUGBiorl27qqSkxLVNv3799M0332j58uVaunSpVq9erUcfffRyHQIAAACqEYdlWZbdQ0iSw+HQokWL1Lt3b0m/n7WNiorSk08+qaeeekqSVFRUpPDwcM2bN099+/bV9u3b1bRpU+Xm5iohIUGStGzZMt1xxx36/vvvFRUVdUHvXVxcrJCQEBUVFSk4OPiSHB8AVAcvfv2T3SN4ZHjrunaPAMBmF9pr1faa2/379ys/P1/JycmuZSEhIWrfvr1ycnIkSTk5OQoNDXWFrSQlJyfLy8tL69atq3DfpaWlKi4udnsAAACg5vOxe4CK5OfnS5LCw8PdloeHh7vW5efnq169em7rfXx8VKdOHdc25zJ+/HiNGTOmiieuHM6emONK+CyvhGOUrpzjBFC98G9P1aq2Z24vpYyMDBUVFbkehw4dsnskAAAAVIFqG7cRERGSpIKCArflBQUFrnURERE6evSo2/p///vfOnbsmGubc3E6nQoODnZ7AAAAoOartnEbGxuriIgIZWdnu5YVFxdr3bp1SkxMlCQlJiaqsLBQeXl5rm1WrFih8vJytW/f/rLPDAAAAHvZes3tiRMntGfPHtfz/fv3a9OmTapTp47q16+vtLQ0jR07Vo0bN1ZsbKwyMzMVFRXluqNCXFycbr/9dg0aNEizZ8/W6dOnlZqaqr59+17wnRIAAABgDlvjdsOGDercubPreXp6uiSpf//+mjdvnp5++mmdPHlSjz76qAoLC9WxY0ctW7ZM/v7+rte8/fbbSk1N1a233iovLy/16dNHU6dOvezHAgAAAPvZGredOnXS+W6z63A4lJWVpaysrAq3qVOnjubPn38pxgMAAEANU22vuQUAAAAqi7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABiDuAUAAIAxiFsAAAAYg7gFAACAMYhbAAAAGIO4BQAAgDGIWwAAABijWsdtWVmZMjMzFRsbq4CAADVq1EjPP/+8LMtybWNZlkaOHKnIyEgFBAQoOTlZu3fvtnFqAAAA2KVax+1LL72kWbNmafr06dq+fbteeuklTZgwQdOmTXNtM2HCBE2dOlWzZ8/WunXrFBgYqK5du6qkpMTGyQEAAGAHH7sHOJ+vvvpKvXr1Uvfu3SVJMTEx+sc//qH169dL+v2s7ZQpUzRixAj16tVLkvTmm28qPDxcixcvVt++fW2bHQAAAJdftT5z26FDB2VnZ2vXrl2SpM2bN2vNmjXq1q2bJGn//v3Kz89XcnKy6zUhISFq3769cnJyKtxvaWmpiouL3R4AAACo+ar1mdvhw4eruLhYTZo0kbe3t8rKyjRu3Dj169dPkpSfny9JCg8Pd3tdeHi4a925jB8/XmPGjLl0gwMAAMAW1frM7bvvvqu3335b8+fP18aNG/X3v/9df/vb3/T3v//9ovabkZGhoqIi1+PQoUNVNDEAAADsVK3P3A4bNkzDhw93XTvbvHlzHThwQOPHj1f//v0VEREhSSooKFBkZKTrdQUFBWrVqlWF+3U6nXI6nZd0dgAAAFx+1frM7a+//iovL/cRvb29VV5eLkmKjY1VRESEsrOzXeuLi4u1bt06JSYmXtZZAQAAYL9qfea2Z8+eGjdunOrXr6/4+Hh9/fXXmjRpkv76179KkhwOh9LS0jR27Fg1btxYsbGxyszMVFRUlHr37m3v8AAAALjsqnXcTps2TZmZmXr88cd19OhRRUVF6bHHHtPIkSNd2zz99NM6efKkHn30URUWFqpjx45atmyZ/P39bZwcAAAAdqjWcRsUFKQpU6ZoypQpFW7jcDiUlZWlrKysyzcYAAAAqqVqfc0tAAAAUBnELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGD52DwAAAFCRF7/+ye4RPDK8dV27R7hiceYWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDOIWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDOIWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDOIWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDB+7BwAAAJX34tc/2T2CR4a3rmv3CDAcZ24BAABgDOIWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDOIWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDOIWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDOIWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDOIWAAAAxiBuAQAAYAziFgAAAMao9nF7+PBhPfDAAwoLC1NAQICaN2+uDRs2uNZblqWRI0cqMjJSAQEBSk5O1u7du22cGAAAAHap1nH7yy+/KCkpSb6+vvrkk0/07bffauLEiapdu7ZrmwkTJmjq1KmaPXu21q1bp8DAQHXt2lUlJSU2Tg4AAAA7+HjyooYNGyo3N1dhYWFuywsLC3XjjTdq3759VTLcSy+9pOjoaM2dO9e1LDY21vVny7I0ZcoUjRgxQr169ZIkvfnmmwoPD9fixYvVt2/fKpkDAAAANYNHZ26/++47lZWVnbW8tLRUhw8fvuihzliyZIkSEhJ0zz33qF69emrdurVee+011/r9+/crPz9fycnJrmUhISFq3769cnJyKtxvaWmpiouL3R4AAACo+Sp15nbJkiWuP3/66acKCQlxPS8rK1N2drZiYmKqbLh9+/Zp1qxZSk9P17PPPqvc3FwNGTJEfn5+6t+/v/Lz8yVJ4eHhbq8LDw93rTuX8ePHa8yYMVU2JwAAAKqHSsVt7969JUkOh0P9+/d3W+fr66uYmBhNnDixyoYrLy9XQkKCXnjhBUlS69attW3bNs2ePfus96+MjIwMpaenu54XFxcrOjr6oucFAACAvSoVt+Xl5ZJ+v+41NzdXdevWvSRDnREZGammTZu6LYuLi9P7778vSYqIiJAkFRQUKDIy0rVNQUGBWrVqVeF+nU6nnE5n1Q8MAAAAW3l0ze3+/fsvedhKUlJSknbu3Om2bNeuXWrQoIGk3yM7IiJC2dnZrvXFxcVat26dEhMTL/l8AAAAqF48uluCJGVnZys7O1tHjx51ndE944033rjowSRp6NCh6tChg1544QXde++9Wr9+vebMmaM5c+ZI+v3yiLS0NI0dO1aNGzdWbGysMjMzFRUV5bqEAgAAAFcOj+J2zJgxysrKUkJCgiIjI+VwOKp6LklS27ZttWjRImVkZCgrK0uxsbGaMmWK+vXr59rm6aef1smTJ/Xoo4+qsLBQHTt21LJly+Tv739JZgIAAED15VHczp49W/PmzdODDz5Y1fOcpUePHurRo0eF6x0Oh7KyspSVlXXJZwEAAED15tE1t6dOnVKHDh2qehYAAADgongUtwMHDtT8+fOrehYAAADgonh0WUJJSYnmzJmjzz//XC1atJCvr6/b+kmTJlXJcAAAAEBleBS3W7Zscd1Hdtu2bW7rLtWXywAAAIA/41Hcrly5sqrnAAAAAC6aR9fcAgAAANWRR2duO3fufN7LD1asWOHxQAAAAICnPIrbM9fbnnH69Glt2rRJ27ZtU//+/atiLgAAAKDSPIrbyZMnn3P56NGjdeLEiYsaCAAAAPBUlV5z+8ADD+iNN96oyl0CAAAAF6xK4zYnJ0f+/v5VuUsAAADggnl0WcJdd93l9tyyLP3www/asGGDMjMzq2QwAAAAoLI8ituQkBC3515eXrrhhhuUlZWlLl26VMlgAAAAQGV5FLdz586t6jkAAACAi+ZR3J6Rl5en7du3S5Li4+PVunXrKhkKAAAA8IRHcXv06FH17dtXX3zxhUJDQyVJhYWF6ty5sxYsWKCrr766KmcEAAAALohHd0sYPHiwjh8/rm+++UbHjh3TsWPHtG3bNhUXF2vIkCFVPSMAAABwQTw6c7ts2TJ9/vnniouLcy1r2rSpZsyYwRfKAAAAYBuPztyWl5fL19f3rOW+vr4qLy+/6KEAAAAAT3gUt7fccoueeOIJHTlyxLXs8OHDGjp0qG699dYqGw4AAACoDI/idvr06SouLlZMTIwaNWqkRo0aKTY2VsXFxZo2bVpVzwgAAABcEI+uuY2OjtbGjRv1+eefa8eOHZKkuLg4JScnV+lwAAAAQGVU6sztihUr1LRpUxUXF8vhcOi2227T4MGDNXjwYLVt21bx8fH617/+dalmBQAAAM6rUnE7ZcoUDRo0SMHBwWetCwkJ0WOPPaZJkyZV2XAAAABAZVQqbjdv3qzbb7+9wvVdunRRXl7eRQ8FAAAAeKJScVtQUHDOW4Cd4ePjox9//PGihwIAAAA8Uam4veaaa7Rt27YK12/ZskWRkZEXPRQAAADgiUrF7R133KHMzEyVlJScte63337TqFGj1KNHjyobDgAAAKiMSt0KbMSIEfrnP/+p66+/XqmpqbrhhhskSTt27NCMGTNUVlam55577pIMCgAAAPyZSsVteHi4vvrqK/3v//6vMjIyZFmWJMnhcKhr166aMWOGwsPDL8mgAAAAwJ+p9C9xaNCggT7++GP98ssv2rNnjyzLUuPGjVW7du1LMR8AAABwwTz6DWWSVLt2bbVt27YqZwEAAAAuSqW+UAYAAABUZ8QtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGD52DwAAQFV78euf7B7BI8Nb17V7BKDG48wtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjFGj4vbFF1+Uw+FQWlqaa1lJSYlSUlIUFhamWrVqqU+fPiooKLBvSAAAANimxsRtbm6uXn31VbVo0cJt+dChQ/Xhhx/qvffe06pVq3TkyBHdddddNk0JAAAAO9WIuD1x4oT69eun1157TbVr13YtLyoq0uuvv65JkybplltuUZs2bTR37lx99dVXWrt2rY0TAwAAwA41Im5TUlLUvXt3JScnuy3Py8vT6dOn3ZY3adJE9evXV05OToX7Ky0tVXFxsdsDAAAANZ+P3QP8mQULFmjjxo3Kzc09a11+fr78/PwUGhrqtjw8PFz5+fkV7nP8+PEaM2ZMVY8KAAAAm1XrM7eHDh3SE088obffflv+/v5Vtt+MjAwVFRW5HocOHaqyfQMAAMA+1Tpu8/LydPToUd14443y8fGRj4+PVq1apalTp8rHx0fh4eE6deqUCgsL3V5XUFCgiIiICvfrdDoVHBzs9gAAAEDNV60vS7j11lu1detWt2UDBgxQkyZN9Mwzzyg6Olq+vr7Kzs5Wnz59JEk7d+7UwYMHlZiYaMfIAAAAsFG1jtugoCA1a9bMbVlgYKDCwsJcyx955BGlp6erTp06Cg4O1uDBg5WYmKi//OUvdowMAAAAG1XruL0QkydPlpeXl/r06aPS0lJ17dpVM2fOtHssAAAA2KDGxe0XX3zh9tzf318zZszQjBkz7BkIAAAA1Ua1/kIZAAAAUBnELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBg+dg8Ac7349U92j+CR4a3r2j0CAADwEGduAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDOIWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDOIWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDOIWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDOIWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGqNZxO378eLVt21ZBQUGqV6+eevfurZ07d7ptU1JSopSUFIWFhalWrVrq06ePCgoKbJoYAAAAdqrWcbtq1SqlpKRo7dq1Wr58uU6fPq0uXbro5MmTrm2GDh2qDz/8UO+9955WrVqlI0eO6K677rJxagAAANjFx+4BzmfZsmVuz+fNm6d69eopLy9PN910k4qKivT6669r/vz5uuWWWyRJc+fOVVxcnNauXau//OUv59xvaWmpSktLXc+Li4sv3UEAAADgsqnWZ27/qKioSJJUp04dSVJeXp5Onz6t5ORk1zZNmjRR/fr1lZOTU+F+xo8fr5CQENcjOjr60g4OAACAy6LGxG15ebnS0tKUlJSkZs2aSZLy8/Pl5+en0NBQt23Dw8OVn59f4b4yMjJUVFTkehw6dOhSjg4AAIDLpFpflvCfUlJStG3bNq1Zs+ai9+V0OuV0OqtgKgAAAFQnNeLMbWpqqpYuXaqVK1fq2muvdS2PiIjQqVOnVFhY6LZ9QUGBIiIiLvOUAAAAsFu1jlvLspSamqpFixZpxYoVio2NdVvfpk0b+fr6Kjs727Vs586dOnjwoBITEy/3uAAAALBZtb4sISUlRfPnz9cHH3ygoKAg13W0ISEhCggIUEhIiB555BGlp6erTp06Cg4O1uDBg5WYmFjhnRIAAABgrmodt7NmzZIkderUyW353Llz9fDDD0uSJk+eLC8vL/Xp00elpaXq2rWrZs6ceZknBQAAQHVQrePWsqw/3cbf318zZszQjBkzLsNEAAAAqM6q9TW3AAAAQGUQtwAAADAGcQsAAABjELcAAAAwBnELAAAAYxC3AAAAMAZxCwAAAGMQtwAAADAGcQsAAABjELcAAAAwBnELAAAAYxC3AAAAMAZxCwAAAGMQtwAAADAGcQsAAABjELcAAAAwBnELAAAAYxC3AAAAMAZxCwAAAGMQtwAAADAGcQsAAABjELcAAAAwBnELAAAAYxC3AAAAMAZxCwAAAGMQtwAAADAGcQsAAABjELcAAAAwBnELAAAAYxC3AAAAMAZxCwAAAGMQtwAAADAGcQsAAABjELcAAAAwBnELAAAAYxC3AAAAMAZxCwAAAGMQtwAAADAGcQsAAABjELcAAAAwBnELAAAAYxC3AAAAMAZxCwAAAGMQtwAAADAGcQsAAABjELcAAAAwBnELAAAAYxC3AAAAMAZxCwAAAGMQtwAAADAGcQsAAABjELcAAAAwBnELAAAAYxC3AAAAMAZxCwAAAGMQtwAAADAGcQsAAABjELcAAAAwBnELAAAAYxC3AAAAMAZxCwAAAGMQtwAAADAGcQsAAABjELcAAAAwBnELAAAAYxC3AAAAMAZxCwAAAGMQtwAAADAGcQsAAABjELcAAAAwBnELAAAAYxgTtzNmzFBMTIz8/f3Vvn17rV+/3u6RAAAAcJkZEbfvvPOO0tPTNWrUKG3cuFEtW7ZU165ddfToUbtHAwAAwGVkRNxOmjRJgwYN0oABA9S0aVPNnj1bV111ld544w27RwMAAMBl5GP3ABfr1KlTysvLU0ZGhmuZl5eXkpOTlZOTc87XlJaWqrS01PW8qKhIklRcXHxph/0PJSeOX7b3qkrFxX4XvO2VcIzSlXGcV8IxSlfGcV4JxyhdGcd5JRyjdGUc55VwjFXzfr93mmVZ59/QquEOHz5sSbK++uort+XDhg2z2rVrd87XjBo1ypLEgwcPHjx48ODBo4Y9Dh06dN42rPFnbj2RkZGh9PR01/Py8nIdO3ZMYWFhcjgcNk528YqLixUdHa1Dhw4pODjY7nFwEfgszcFnaQ4+S3PwWdY8lmXp+PHjioqKOu92NT5u69atK29vbxUUFLgtLygoUERExDlf43Q65XQ63ZaFhoZeqhFtERwczF9WQ/BZmoPP0hx8lubgs6xZQkJC/nSbGv+FMj8/P7Vp00bZ2dmuZeXl5crOzlZiYqKNkwEAAOByq/FnbiUpPT1d/fv3V0JCgtq1a6cpU6bo5MmTGjBggN2jAQAA4DIyIm7vu+8+/fjjjxo5cqTy8/PVqlUrLVu2TOHh4XaPdtk5nU6NGjXqrMsuUPPwWZqDz9IcfJbm4LM0l8Oy/ux+CgAAAEDNUOOvuQUAAADOIG4BAABgDOIWAAAAxiBuAQAAYAzi1iAzZsxQTEyM/P391b59e61fv97ukVBJ48ePV9u2bRUUFKR69eqpd+/e2rlzp91joQq8+OKLcjgcSktLs3sUeODw4cN64IEHFBYWpoCAADVv3lwbNmyweyx4oKysTJmZmYqNjVVAQIAaNWqk559/Xny/3hzErSHeeecdpaena9SoUdq4caNatmyprl276ujRo3aPhkpYtWqVUlJStHbtWi1fvlynT59Wly5ddPLkSbtHw0XIzc3Vq6++qhYtWtg9Cjzwyy+/KCkpSb6+vvrkk0/07bffauLEiapdu7bdo8EDL730kmbNmqXp06dr+/bteumllzRhwgRNmzbN7tFQRbgVmCHat2+vtm3bavr06ZJ+/y1t0dHRGjx4sIYPH27zdPDUjz/+qHr16mnVqlW66aab7B4HHjhx4oRuvPFGzZw5U2PHjlWrVq00ZcoUu8dCJQwfPlxffvml/vWvf9k9CqpAjx49FB4ertdff921rE+fPgoICNBbb71l42SoKpy5NcCpU6eUl5en5ORk1zIvLy8lJycrJyfHxslwsYqKiiRJderUsXkSeColJUXdu3d3+/uJmmXJkiVKSEjQPffco3r16ql169Z67bXX7B4LHurQoYOys7O1a9cuSdLmzZu1Zs0adevWzebJUFWM+A1lV7qffvpJZWVlZ/1GtvDwcO3YscOmqXCxysvLlZaWpqSkJDVr1szuceCBBQsWaOPGjcrNzbV7FFyEffv2adasWUpPT9ezzz6r3NxcDRkyRH5+furfv7/d46GShg8fruLiYjVp0kTe3t4qKyvTuHHj1K9fP7tHQxUhboFqKiUlRdu2bdOaNWvsHgUeOHTokJ544gktX75c/v7+do+Di1BeXq6EhAS98MILkqTWrVtr27Ztmj17NnFbA7377rt6++23NX/+fMXHx2vTpk1KS0tTVFQUn6chiFsD1K1bV97e3iooKHBbXlBQoIiICJumwsVITU3V0qVLtXr1al177bV2jwMP5OXl6ejRo7rxxhtdy8rKyrR69WpNnz5dpaWl8vb2tnFCXKjIyEg1bdrUbVlcXJzef/99mybCxRg2bJiGDx+uvn37SpKaN2+uAwcOaPz48cStIbjm1gB+fn5q06aNsrOzXcvKy8uVnZ2txMREGydDZVmWpdTUVC1atEgrVqxQbGys3SPBQ7feequ2bt2qTZs2uR4JCQnq16+fNm3aRNjWIElJSWfdkm/Xrl1q0KCBTRPhYvz666/y8nLPH29vb5WXl9s0EaoaZ24NkZ6erv79+yshIUHt2rXTlClTdPLkSQ0YMMDu0VAJKSkpmj9/vj744AMFBQUpPz9fkhQSEqKAgACbp0NlBAUFnXWtdGBgoMLCwriGuoYZOnSoOnTooBdeeEH33nuv1q9frzlz5mjOnDl2jwYP9OzZU+PGjVP9+vUVHx+vr7/+WpMmTdJf//pXu0dDFeFWYAaZPn26Xn75ZeXn56tVq1aaOnWq2rdvb/dYqASHw3HO5XPnztXDDz98eYdBlevUqRO3Aquhli5dqoyMDO3evVuxsbFKT0/XoEGD7B4LHjh+/LgyMzO1aNEiHT16VFFRUbr//vs1cuRI+fn52T0eqgBxCwAAAGNwzS0AAACMQdwCAADAGMQtAAAAjEHcAgAAwBjELQAAAIxB3AIAAMAYxC0AAACMQdwCAADAGMQtANRQDodDixcvtnsMAKhWiFsAqKby8/M1ePBgNWzYUE6nU9HR0erZs6eys7PtHg0Aqi0fuwcAAJztu+++U1JSkkJDQ/Xyyy+refPmOn36tD799FOlpKRox44ddo8IANUSZ24BoBp6/PHH5XA4tH79evXp00fXX3+94uPjlZ6errVr157zNc8884yuv/56XXXVVWrYsKEyMzN1+vRp1/rNmzerc+fOCgoKUnBwsNq0aaMNGzZIkg4cOKCePXuqdu3aCgwMVHx8vD7++OPLcqwAUJU4cwsA1cyxY8e0bNkyjRs3ToGBgWetDw0NPefrgoKCNG/ePEVFRWnr1q0aNGiQgoKC9PTTT0uS+vXrp9atW2vWrFny9vbWpk2b5OvrK0lKSUnRqVOntHr1agUGBurbb79VrVq1LtkxAsClQtwCQDWzZ88eWZalJk2aVOp1I0aMcP05JiZGTz31lBYsWOCK24MHD2rYsGGu/TZu3Ni1/cGDB9WnTx81b95cktSwYcOLPQwAsAWXJQBANWNZlkeve+edd5SUlKSIiAjVqlVLI0aM0MGDB13r09PTNXDgQCUnJ+vFF1/U3r17XeuGDBmisWPHKikpSaNGjdKWLVsu+jgAwA7ELQBUM40bN5bD4ajUl8ZycnLUr18/3XHHHVq6dKm+/vprPffcczp16pRrm9GjR+ubb75R9+7dtWLFCjVt2lSLFi2SJA0cOFD79u3Tgw8+qK1btyohIUHTpk2r8mMDgEvNYXl6igAAcMl069ZNW7du1c6dO8+67rawsFChoaFyOBxatGiRevfurYkTJ2rmzJluZ2MHDhyohQsXqrCw8Jzvcf/99+vkyZNasmTJWesyMjL00UcfcQYXQI3DmVsAqIZmzJihsrIytWvXTu+//752796t7du3a+rUqUpMTDxr+8aNG+vgwYNasGCB9u7dq6lTp7rOykrSb7/9ptTUVH3xxRc6cOCAvvzyS+Xm5iouLk6SlJaWpk8//VT79+/Xxo0btXLlStc6AKhJ+EIZAFRDDRs21MaNGzVu3Dg9+eST+uGHH3T11VerTZs2mjVr1lnb33nnnRo6dKhSU1NVWlqq7t27KzMzU6NHj5YkeXt76+eff9ZDDz2kgoIC1a1bV3fddZfGjBkjSSorK1NKSoq+//57BQcH6/bbb9fkyZMv5yEDQJXgsgQAAAAYg8sSAAAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgDOIWAAAAxiBuAQAAYAziFgAAAMYgbgEAAGAM4hYAAADGIG4BAABgjP8H7gXA2dfapsgAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in datasets:\n",
    "    class_counts = df['Label'].value_counts()\n",
    "    class_labels = class_counts.index\n",
    "    class_values = class_counts.values\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(class_labels, class_values, color='skyblue')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Class Distribution')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:30.970863Z",
     "start_time": "2023-11-27T19:21:28.157001100Z"
    }
   },
   "id": "5ed5f126fe71eadf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The classes are not balanced nor normalized, so we will need adress that in the training set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a97e2e2f2715a5de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model architecture definition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc7a2c096e8aeaaa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The classifiers we chose were the following: a classifier based on multilayer perceptron (MLP) and a convolutional neural network (CNN)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4949590adfe6c333"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MLP classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37b70ee9008af212"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the MLP classifier, we need to define the following parameters: number of layers, number of neurons\n",
    "per layer and the activation function for each layer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b5c84a611077f18"
  },
  {
   "cell_type": "raw",
   "source": [
    "    Number of layers - since one hidden layer is enough to represent an approximation of\n",
    "any function to an arbitrary degree of accuracy and since a shallow net tends to overfit more, we experimented with 2\n",
    "number of neurons per layer - there are several rules of thumb to determine the number of neurons per       Layer and we tested the following: 2/3 of the input layer + the number of output neurons, the mean of input neurons + the number of output neurons\n",
    "    Activation function for each layer - we tested the following: relu, sigmoid, exponential using grid \n",
    "search to determine the best combination and we got the best results with relu for the first and the second layer and sigmoid for the output\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd262ae433d79f87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training strategy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a0e95cb5ed8ca00"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We used the same training strategy for both models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9b1597ac1a82f3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to define the details for the training strategies, we ran a grid search over some hyperparameters.\n",
    "Choosing the best optimizer involves expererimenting and comparing the results of different optimizers to see what works best. We tested the following: SGD, Adam, and Adagrad.\n",
    "\n",
    "To determine a good learning rate value, we tested some between the tradicional interval of 0.1 to 0.01.\n",
    "\n",
    "Some common batch sizes of number of samples used in each iteration are 32, 64, 128 and we ended up testing all these values.\n",
    "\n",
    "Too few epochs may result in underfitting, while too many epochs may lead to overfitting, so we tried 300 and got good results.\n",
    "\n",
    "For early stopping, we tested patience levels of 3 and 6 and kept the rest of the parameters as default and for dropout rate we some in the range of 0 to 1.\n",
    "\n",
    "L1_L2 regularization was the technique choosen by us for weigth regularization and we tested some values between 0 and 0.1.\n",
    "\n",
    "For now we did not use any data augmentaion techniques neither transfer learning. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "708bfec49a6e352"
  },
  {
   "cell_type": "markdown",
   "source": [
    "After running the grid search, we found the best values for the parameters and proceeded to use them in the neural networks."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "737f4090d8c6b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performance evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26dfe82389bcfed1"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "learning_rate = '0.1'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:30.988712600Z",
     "start_time": "2023-11-27T19:21:30.973858Z"
    }
   },
   "id": "55725ebfb9357fc0"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "# Combine all labels from different datasets\n",
    "all_labels = np.concatenate([df['Label'].values for df in datasets])\n",
    "\n",
    "# Define the stratified k-fold\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:31.070400400Z",
     "start_time": "2023-11-27T19:21:30.990713300Z"
    }
   },
   "id": "f261fe2c9bbbeaf"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "# Hyperparameter Grid\n",
    "dropout_values = np.arange(0, 1, 0.01)\n",
    "patience_values = [3, 6]\n",
    "optimizers = ['adam', 'sgd', 'adagrad']\n",
    "regulizers_value = np.arange(0, 0.1, 0.01)\n",
    "batch_sizes = [32, 64, 128]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:31.071402600Z",
     "start_time": "2023-11-27T19:21:31.010322300Z"
    }
   },
   "id": "76452e0629bf294b"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "def grid_search_best_parameters():\n",
    "    # Best results tracker\n",
    "    best_result = {\n",
    "        'dropout': None,\n",
    "        'patience': None,\n",
    "        'optimizer': None,\n",
    "        'regulaizer': None,\n",
    "        'batch_size': None,\n",
    "        'average_accuracy': 0\n",
    "    }\n",
    "    \n",
    "    total_iterations = len(dropout_values) * len(regulizers_value) * len(optimizers) * len(patience_values) * len(batch_sizes)\n",
    "    \n",
    "    with tqdm(total=total_iterations, desc=\"Grid Search Progress\") as pbar:\n",
    "        # Grid Search Loop\n",
    "        for dropout in dropout_values:\n",
    "            for regulizer in regulizers_value:\n",
    "                for optimizer in optimizers:\n",
    "                    for patience in patience_values:\n",
    "                        for batch_size in batch_sizes:\n",
    "                            cv_scores = []\n",
    "    \n",
    "                            for fold, (train_index, val_index) in enumerate(stratified_kfold.split(range(len(all_labels)), all_labels)):\n",
    "                                # Use the current fold as the validation set\n",
    "                                validation_dataset = datasets[fold]\n",
    "    \n",
    "                                # Combine the remaining datasets as the training set\n",
    "                                training_datasets = [dataset for index, dataset in enumerate(datasets) if index != fold]\n",
    "                                combined_df = pd.concat(training_datasets, ignore_index=True)\n",
    "    \n",
    "                                # Classification\n",
    "                                X_train = combined_df.drop('Label', axis=1)\n",
    "                                y_train = combined_df['Label']\n",
    "    \n",
    "                                # Oversample the features values using SMOTE\n",
    "                                smote = SMOTE(random_state=42)\n",
    "                                X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "                                # Standardize the feature values\n",
    "                                scaler = StandardScaler()\n",
    "                                X_train_scaled = scaler.fit_transform(X_resampled)\n",
    "    \n",
    "                                # Classification for validation set\n",
    "                                X_val = validation_dataset.drop('Label', axis=1)\n",
    "                                y_val = validation_dataset['Label']\n",
    "    \n",
    "                                # Oversample the features values using SMOTE for validation set\n",
    "                                X_val_resampled, y_val_resampled = smote.fit_resample(X_val, y_val)\n",
    "                                X_val_scaled = scaler.transform(X_val_resampled)\n",
    "    \n",
    "                                mean_neurons = (X_train_scaled.shape[1] + len(np.unique(y_resampled))) // 2\n",
    "                                num_input_neurons = X_train_scaled.shape[1]\n",
    "                                num_output_neurons = len(np.unique(y_resampled))\n",
    "                                neurons_hidden_layer = int(2 / 3 * num_input_neurons + 1 / 3 * num_output_neurons)\n",
    "    \n",
    "                                # Define and compile the model with hyperparameters\n",
    "                                model = tf.keras.Sequential([\n",
    "                                    tf.keras.layers.Dense(units=neurons_hidden_layer, activation='relu',\n",
    "                                                          input_shape=(X_train_scaled.shape[1],),\n",
    "                                                          kernel_regularizer=tf.keras.regularizers.l1_l2(l1=regulizer, l2=regulizer)),\n",
    "                                    tf.keras.layers.Dropout(dropout),\n",
    "                                    tf.keras.layers.Dense(units=mean_neurons, activation='relu'),\n",
    "                                    tf.keras.layers.Dropout(dropout),\n",
    "                                    tf.keras.layers.Dense(units=len(np.unique(y_resampled)), activation='softmax')\n",
    "                                ])\n",
    "                                model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    \n",
    "                                early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "                                # Train the model\n",
    "                                model.fit(X_train_scaled, y_resampled, validation_data=(X_val_scaled, y_val_resampled),\n",
    "                                          batch_size=batch_size, callbacks=[early_stopping])\n",
    "    \n",
    "                                # Evaluate the model on the validation set\n",
    "                                y_val_pred_probs = model.predict(X_val_scaled)\n",
    "                                y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
    "    \n",
    "                                # Calculate and store accuracy for this fold\n",
    "                                fold_accuracy = accuracy_score(y_val_resampled, y_val_pred)\n",
    "                                cv_scores.append(fold_accuracy)\n",
    "    \n",
    "                                # Update progress bar\n",
    "                                pbar.update(1)\n",
    "    \n",
    "                            # Calculate and store the average accuracy for these hyperparameters\n",
    "                            overall_average_accuracy = np.mean(cv_scores)\n",
    "    \n",
    "                            # Check if the current set of hyperparameters is better than the best\n",
    "                            if overall_average_accuracy > best_result['average_accuracy']:\n",
    "                                best_result = {\n",
    "                                    'dropout': dropout,\n",
    "                                    'patience': patience,\n",
    "                                    'optimizer': optimizer,\n",
    "                                    'regulizer': regulizer,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'average_accuracy': overall_average_accuracy\n",
    "                                }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:21:31.134168200Z",
     "start_time": "2023-11-27T19:21:31.085398300Z"
    }
   },
   "id": "107cf6c884a1f1c0"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 0/18000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA30C5B7E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA30C5B7E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "266/283 [===========================>..] - ETA: 0s - loss: 1.6602WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3392F6A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3392F6A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "283/283 [==============================] - 2s 3ms/step - loss: 1.6320 - val_loss: 1.5243\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA349C76A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA349C76A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 1/18000 [00:03<18:15:43,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA34A7E660> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA34A7E660> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "264/282 [===========================>..] - ETA: 0s - loss: 1.6758WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C645120> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C645120> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "282/282 [==============================] - 5s 3ms/step - loss: 1.6400 - val_loss: 1.5036\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2C4D3880> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2C4D3880> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 2/18000 [00:08<23:02:10,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2B46CD60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2B46CD60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "274/282 [============================>.] - ETA: 0s - loss: 1.6304WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA349F3A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA349F3A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "282/282 [==============================] - 2s 3ms/step - loss: 1.6187 - val_loss: 1.3660\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2C44BBA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2C44BBA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 3/18000 [00:11<17:20:31,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2C4AE2A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2C4AE2A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "262/282 [==========================>...] - ETA: 0s - loss: 1.5797WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3009C7C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3009C7C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "282/282 [==============================] - 2s 3ms/step - loss: 1.5437 - val_loss: 1.3940\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA333AE980> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA333AE980> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "52/52 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 4/18000 [00:13<14:38:52,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA33979120> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA33979120> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "260/282 [==========================>...] - ETA: 0s - loss: 1.6210WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA32C4ACA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA32C4ACA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "282/282 [==============================] - 2s 3ms/step - loss: 1.5895 - val_loss: 1.2953\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA33921120> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA33921120> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 5/18000 [00:15<13:04:28,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32393C40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32393C40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "273/292 [===========================>..] - ETA: 0s - loss: 1.6046WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2F462840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2F462840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 1.5758 - val_loss: 1.3738\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2F54A0C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2F54A0C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 6/18000 [00:17<12:11:23,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA30A6E340> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA30A6E340> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "286/289 [============================>.] - ETA: 0s - loss: 1.5622WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA321D4EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA321D4EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "289/289 [==============================] - 2s 3ms/step - loss: 1.5582 - val_loss: 1.5798\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3227BC40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3227BC40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 7/18000 [00:19<11:45:59,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32417420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32417420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "267/289 [==========================>...] - ETA: 0s - loss: 1.6528WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3313B420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3313B420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "289/289 [==============================] - 2s 3ms/step - loss: 1.6201 - val_loss: 1.2947\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA331BEE80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA331BEE80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 8/18000 [00:21<11:18:31,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA331DC360> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA331DC360> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "271/287 [===========================>..] - ETA: 0s - loss: 1.6608WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA33023920> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA33023920> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "287/287 [==============================] - 2s 3ms/step - loss: 1.6298 - val_loss: 1.2938\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA334DB2E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA334DB2E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 9/18000 [00:23<10:53:05,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3354B9C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3354B9C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "270/284 [===========================>..] - ETA: 0s - loss: 1.7122WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA372BAC00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA372BAC00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "284/284 [==============================] - 2s 3ms/step - loss: 1.6875 - val_loss: 1.3483\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA395A7600> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA395A7600> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 10/18000 [00:25<10:39:54,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA39600680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA39600680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "129/142 [==========================>...] - ETA: 0s - loss: 1.8384WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AA43E20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AA43E20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 1.7998 - val_loss: 1.5095\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3AAFD620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3AAFD620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 11/18000 [00:27<10:11:18,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AB3E2A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AB3E2A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "132/141 [===========================>..] - ETA: 0s - loss: 1.9008WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3ACEBEC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3ACEBEC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8703 - val_loss: 1.6679\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3AD8B920> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3AD8B920> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 12/18000 [00:29<9:47:19,  1.96s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AE271A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AE271A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "125/141 [=========================>....] - ETA: 0s - loss: 1.9259WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C4AECA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C4AECA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "141/141 [==============================] - 2s 4ms/step - loss: 1.8750 - val_loss: 1.4989\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3AD8BF60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3AD8BF60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 13/18000 [00:31<10:10:32,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2C441300> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2C441300> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "125/141 [=========================>....] - ETA: 0s - loss: 1.9073WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2FB42AC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2FB42AC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8585 - val_loss: 1.5696\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2C4437E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2C4437E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "52/52 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 14/18000 [00:33<9:49:42,  1.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA396028E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA396028E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "128/141 [==========================>...] - ETA: 0s - loss: 1.8788WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C40E980> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C40E980> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8362 - val_loss: 1.4951\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2FC6FC40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2FC6FC40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 15/18000 [00:34<9:29:58,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2FC6F1A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2FC6F1A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "122/146 [========================>.....] - ETA: 0s - loss: 1.9248WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA32307C40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA32307C40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 1.8500 - val_loss: 1.5802\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA334B37E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA334B37E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 16/18000 [00:36<9:18:03,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA334FFCE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA334FFCE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "126/145 [=========================>....] - ETA: 0s - loss: 1.8493WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA32F7E520> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA32F7E520> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.7865 - val_loss: 1.5904\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA32F7FEC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA32F7FEC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 17/18000 [00:38<9:26:12,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AF11D00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AF11D00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "132/145 [==========================>...] - ETA: 0s - loss: 1.8935WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3222F420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3222F420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.8537 - val_loss: 1.3644\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA373867A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA373867A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 18/18000 [00:40<9:16:50,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA37386CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA37386CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "117/144 [=======================>......] - ETA: 0s - loss: 1.9025WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA33047F60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA33047F60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 1.8165 - val_loss: 1.4482\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA32B23600> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA32B23600> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 19/18000 [00:42<9:08:42,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32BCF1A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32BCF1A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "131/142 [==========================>...] - ETA: 0s - loss: 1.8573WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AD039C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AD039C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 1.8209 - val_loss: 1.4845\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA32A2BE20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA32A2BE20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 20/18000 [00:43<9:03:51,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32A45120> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32A45120> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "49/71 [===================>..........] - ETA: 0s - loss: 2.1181WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA37236FC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA37236FC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - 1s 5ms/step - loss: 2.0270 - val_loss: 1.9050\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C327240> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C327240> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 21/18000 [00:45<8:49:27,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3C39BE20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3C39BE20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "48/71 [===================>..........] - ETA: 0s - loss: 2.2561WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA36F06980> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA36F06980> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - 1s 5ms/step - loss: 2.1532 - val_loss: 2.0224\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3700DF80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3700DF80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 22/18000 [00:47<8:36:32,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA37024400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA37024400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "48/71 [===================>..........] - ETA: 0s - loss: 2.2188WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3C667E20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3C667E20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - 1s 5ms/step - loss: 2.1176 - val_loss: 1.7952\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C71FD80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C71FD80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 23/18000 [00:48<8:26:26,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3C78BC40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3C78BC40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "48/71 [===================>..........] - ETA: 0s - loss: 2.2076WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA34A5F600> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA34A5F600> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - 2s 5ms/step - loss: 2.0934 - val_loss: 1.9912\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C78B100> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C78B100> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "52/52 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 24/18000 [00:50<9:01:24,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2C4D0360> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2C4D0360> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "49/71 [===================>..........] - ETA: 0s - loss: 2.1933WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA30566160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA30566160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - 1s 5ms/step - loss: 2.0804 - val_loss: 1.7774\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2C4D20C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2C4D20C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 25/18000 [00:52<8:42:40,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA307580E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA307580E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "49/73 [===================>..........] - ETA: 0s - loss: 2.0466WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA31F5CF40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA31F5CF40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 1.9307 - val_loss: 1.7233\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA32B68AE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA32B68AE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 26/18000 [00:54<8:31:55,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3C325120> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3C325120> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "72/73 [============================>.] - ETA: 0s - loss: 2.0013WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C4AD1C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C4AD1C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 2.0009 - val_loss: 1.8612\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C3D2C00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C3D2C00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 27/18000 [00:55<8:24:31,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AED9DA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AED9DA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "49/73 [===================>..........] - ETA: 0s - loss: 2.1915WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA32FAB6A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA32FAB6A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 2.0651 - val_loss: 1.5994\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA329A6700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA329A6700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 28/18000 [00:57<8:14:43,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2FFEB380> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2FFEB380> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 2.1213WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AD63240> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AD63240> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "72/72 [==============================] - 1s 6ms/step - loss: 2.1081 - val_loss: 1.9180\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA36EAB920> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA36EAB920> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 29/18000 [00:59<8:17:06,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA31D822A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA31D822A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "51/71 [====================>.........] - ETA: 0s - loss: 2.1478WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AAA7560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AAA7560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - 1s 6ms/step - loss: 2.0535 - val_loss: 1.7686\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C68B7E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C68B7E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 30/18000 [01:00<8:32:07,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AD0C860> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AD0C860> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "270/283 [===========================>..] - ETA: 0s - loss: 1.6460WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA371C91C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA371C91C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "283/283 [==============================] - 2s 3ms/step - loss: 1.6237 - val_loss: 1.4751\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA37226E80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA37226E80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 31/18000 [01:03<9:32:15,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3361ED40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3361ED40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "261/282 [==========================>...] - ETA: 0s - loss: 1.5985WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3C19BCE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3C19BCE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 1.5676 - val_loss: 1.4082\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C22BBA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C22BBA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 32/18000 [01:05<10:43:37,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3C88B9C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3C88B9C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "260/282 [==========================>...] - ETA: 0s - loss: 1.6609WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3ECC3BA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3ECC3BA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "282/282 [==============================] - 2s 3ms/step - loss: 1.6236 - val_loss: 1.3844\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3ED216C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3ED216C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 33/18000 [01:08<11:13:13,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3ED9FB00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3ED9FB00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "257/282 [==========================>...] - ETA: 0s - loss: 1.7226WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA39602B60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA39602B60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "282/282 [==============================] - 2s 3ms/step - loss: 1.6745 - val_loss: 1.4965\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2C4400E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2C4400E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "52/52 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 34/18000 [01:11<11:55:33,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AE28360> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AE28360> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "282/282 [==============================] - ETA: 0s - loss: 1.6430WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C4EB4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C4EB4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "282/282 [==============================] - 2s 3ms/step - loss: 1.6430 - val_loss: 1.2162\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA395C89A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA395C89A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 35/18000 [01:13<11:40:46,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3065B1A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3065B1A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "270/292 [==========================>...] - ETA: 0s - loss: 1.6209WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA323922A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA323922A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "292/292 [==============================] - 2s 3ms/step - loss: 1.5849 - val_loss: 1.4866\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3AFF7CE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3AFF7CE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 36/18000 [01:15<11:37:39,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA37374CC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA37374CC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "277/289 [===========================>..] - ETA: 0s - loss: 1.6376WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C4AF600> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C4AF600> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "289/289 [==============================] - 2s 3ms/step - loss: 1.6153 - val_loss: 1.5080\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2FB9B4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA2FB9B4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 37/18000 [01:18<11:50:25,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2C646480> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2C646480> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "286/289 [============================>.] - ETA: 0s - loss: 1.6217WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA32303380> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA32303380> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "289/289 [==============================] - 2s 4ms/step - loss: 1.6168 - val_loss: 1.2050\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA32F7FC40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA32F7FC40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 38/18000 [01:21<12:31:38,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32F85300> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32F85300> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "279/287 [============================>.] - ETA: 0s - loss: 1.6151WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AA7AE80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AA7AE80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "287/287 [==============================] - 2s 3ms/step - loss: 1.6036 - val_loss: 1.3073\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA372167A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA372167A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 39/18000 [01:23<12:32:33,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3719BE20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3719BE20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "271/284 [===========================>..] - ETA: 0s - loss: 1.6614WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3C06FE20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3C06FE20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "284/284 [==============================] - 2s 3ms/step - loss: 1.6400 - val_loss: 1.2491\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3CA2AAC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3CA2AAC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 40/18000 [01:25<12:07:47,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3CA26700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3CA26700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "131/142 [==========================>...] - ETA: 0s - loss: 1.8874WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA373D7600> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA373D7600> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 1.8518 - val_loss: 1.5964\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C3FB920> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C3FB920> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 41/18000 [01:27<11:20:51,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3C3FBF60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3C3FBF60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "128/141 [==========================>...] - ETA: 0s - loss: 1.8163WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3F423420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3F423420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.7788 - val_loss: 1.5814\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3F477C40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3F477C40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 42/18000 [01:29<10:40:08,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3F4DF880> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3F4DF880> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "129/141 [==========================>...] - ETA: 0s - loss: 1.8808WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3F872340> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3F872340> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8449 - val_loss: 1.6701\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3F9BF920> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3F9BF920> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 43/18000 [01:31<10:18:50,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3FA1B4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3FA1B4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "134/141 [===========================>..] - ETA: 0s - loss: 1.8392WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3FBAAAC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3FBAAAC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8206 - val_loss: 1.7315\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA43DD1D00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA43DD1D00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "52/52 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 44/18000 [01:33<10:07:06,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA43E8F420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA43E8F420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "140/141 [============================>.] - ETA: 0s - loss: 1.8373WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA444EF2E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA444EF2E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "141/141 [==============================] - 2s 4ms/step - loss: 1.8357 - val_loss: 1.4608\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA445B3C40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA445B3C40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 45/18000 [01:35<10:18:10,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA446496C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA446496C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 1.8297WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3075B600> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3075B600> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "146/146 [==============================] - 2s 4ms/step - loss: 1.7677 - val_loss: 1.6530\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA304E20C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA304E20C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 46/18000 [01:37<10:49:27,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AC600E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AC600E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "119/145 [=======================>......] - ETA: 0s - loss: 1.9237WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3354AE80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3354AE80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 1.8363 - val_loss: 1.6655\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA370584A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA370584A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 47/18000 [01:39<10:19:52,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA31EF7880> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA31EF7880> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "122/145 [========================>.....] - ETA: 0s - loss: 1.9073WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA324251C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA324251C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "145/145 [==============================] - 2s 4ms/step - loss: 1.8379 - val_loss: 1.4503\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA29197420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA29197420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 48/18000 [01:41<10:30:34,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AD89120> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AD89120> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "123/144 [========================>.....] - ETA: 0s - loss: 1.9334WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2FC5D940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2FC5D940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 1.8720 - val_loss: 1.4848\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA445B11C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA445B11C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 49/18000 [01:43<10:21:42,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA43E8C9A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA43E8C9A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "126/142 [=========================>....] - ETA: 0s - loss: 1.8344WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2E66E2A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2E66E2A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 1.7857 - val_loss: 1.5225\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3ED9FEC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3ED9FEC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 50/18000 [01:45<10:10:25,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3EB33740> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3EB33740> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "51/71 [====================>.........] - ETA: 0s - loss: 1.9441WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3C9ED800> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3C9ED800> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - 1s 5ms/step - loss: 1.8554 - val_loss: 1.7844\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3F9B39C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3F9B39C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 51/18000 [01:47<9:54:06,  1.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AAC7380> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3AAC7380> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "50/71 [====================>.........] - ETA: 0s - loss: 2.1838WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3F0F34C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3F0F34C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - 1s 5ms/step - loss: 2.0822 - val_loss: 1.8038\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C142840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3C142840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 52/18000 [01:49<9:28:49,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3F487560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3F487560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "49/71 [===================>..........] - ETA: 0s - loss: 2.0703WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3FC477E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3FC477E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - 1s 5ms/step - loss: 1.9641 - val_loss: 1.6652\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA37476C00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA37476C00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 53/18000 [01:51<9:02:15,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA37477060> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA37477060> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "53/71 [=====================>........] - ETA: 0s - loss: 2.0888WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3F60B560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3F60B560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - 1s 5ms/step - loss: 1.9931 - val_loss: 1.8904\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3F669C60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3F669C60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "52/52 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 54/18000 [01:52<8:49:49,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3F6DDD00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3F6DDD00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.9888WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA42CAF7E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA42CAF7E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - 1s 5ms/step - loss: 1.9888 - val_loss: 1.6684\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA43F2B9C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA43F2B9C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 55/18000 [01:54<8:42:42,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA43F94F40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA43F94F40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "49/73 [===================>..........] - ETA: 0s - loss: 2.1757WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA45CD6E80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA45CD6E80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 2.0593 - val_loss: 1.7863\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA47D9E980> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA47D9E980> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 56/18000 [01:56<8:33:03,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA47D9F2E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA47D9F2E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "70/73 [===========================>..] - ETA: 0s - loss: 2.0743WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA45B6E700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA45B6E700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 2.0657 - val_loss: 1.9109\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA45BDFF60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA45BDFF60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "34/34 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 57/18000 [01:57<8:27:40,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA45C04680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA45C04680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "49/73 [===================>..........] - ETA: 0s - loss: 2.1120WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA495F37E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA495F37E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 2.0031 - val_loss: 1.6182\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA45BDFB00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA45BDFB00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 58/18000 [01:59<9:10:23,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA440239C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA440239C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "46/72 [==================>...........] - ETA: 0s - loss: 2.1442WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3F5145E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3F5145E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "72/72 [==============================] - 1s 5ms/step - loss: 2.0160 - val_loss: 1.7929\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA37214400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA37214400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 59/18000 [02:01<8:49:42,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32F7FBA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32F7FBA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "49/71 [===================>..........] - ETA: 0s - loss: 2.1777WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AFAD8A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AFAD8A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "71/71 [==============================] - 1s 5ms/step - loss: 2.0679 - val_loss: 1.7568\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3AFAE520> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3AFAE520> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 60/18000 [02:03<8:37:19,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2B46CAE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2B46CAE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "270/283 [===========================>..] - ETA: 0s - loss: 2.1258WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2ED3B740> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2ED3B740> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "283/283 [==============================] - 1s 3ms/step - loss: 2.1163 - val_loss: 1.8443\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3AB3F420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA3AB3F420> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 61/18000 [02:04<8:44:51,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32ECEC00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA32ECEC00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "266/282 [===========================>..] - ETA: 0s - loss: 2.1128WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AED27A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3AED27A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.1018 - val_loss: 2.0059\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA331ECCC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001AA331ECCC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 61/18000 [02:06<10:21:03,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 427, in converted_call\n",
      "    converted_f = _convert_actual(target_entity, program_ctx)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 269, in _convert_actual\n",
      "    transformed, module, source_map = _TRANSPILER.transform(entity, program_ctx)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py\", line 282, in transform\n",
      "    return self.transform_function(obj, user_context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py\", line 490, in transform_function\n",
      "    transformed_fn = factory.instantiate(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py\", line 201, in instantiate\n",
      "    raise ValueError(\n",
      "ValueError: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_6244\\4143756266.py\", line 1, in <module>\n",
      "    best_result = grid_search_best_parameters()\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_6244\\3604523343.py\", line 75, in grid_search_best_parameters\n",
      "    y_val_pred_probs = model.predict(X_val_scaled)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2631, in predict\n",
      "    )\n",
      "      \n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 831, in __call__\n",
      "    with OptionalXlaContext(self._jit_compile):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 887, in _call\n",
      "    initializers = []\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 694, in _initialize\n",
      "    # Force the definition of the function for these arguments\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\", line 178, in trace_function\n",
      "    concrete_function = _maybe_define_function(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\", line 284, in _maybe_define_function\n",
      "    target_func_type, lookup_func_context, func_graph, tracing_options\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\", line 308, in _create_concrete_function\n",
      "    attributes_lib.DISABLE_ACD, False\n",
      "                    ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1059, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 597, in wrapped_fn\n",
      "    with OptionalXlaContext(compile_with_xla):\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py\", line 41, in autograph_handler\n",
      "    return api.converted_call(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 434, in converted_call\n",
      "    return _fall_back_unconverted(f, args, kwargs, options, e)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 485, in _fall_back_unconverted\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 459, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function\n",
      "    model._predict_counter.assign_add(1)\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 1679, in run\n",
      "    fn = autograph.tf_convert(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 3269, in call_for_each_replica\n",
      "    kwargs = {}\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 4067, in _call_for_each_replica\n",
      "    def _call_for_each_replica(self, fn, args, kwargs):\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 690, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 377, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 459, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step\n",
      "    Typically, this method directly controls `tf.function` and\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n",
      "    test_function_runner = _TestFunction(self.test_function, callbacks)\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 589, in __call__\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 690, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 331, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options, False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 459, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n",
      "    return super().call(inputs, training=training, mask=mask)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n",
      "    return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n",
      "    outputs = node.layer(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 690, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 331, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options, False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 459, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 255, in call\n",
      "    outputs = self.activation(outputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1260, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\activations.py\", line 306, in relu\n",
      "    return backend.relu(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1260, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\backend.py\", line 5397, in relu\n",
      "    if clip_max:\n",
      "            ^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 12296, in relu\n",
      "    _dispatcher_for_softsign = softsign._tf_type_based_dispatcher.Dispatch\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 796, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 670, in _create_op_internal\n",
      "    return super()._create_op_internal(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2657, in _create_op_internal\n",
      "    control_inputs=control_inputs,\n",
      "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1161, in from_node_def\n",
      "    self = Operation(c_op, SymbolicTensor)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1018, in _create_c_op\n",
      "    except errors.InvalidArgumentError as e:\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\alexa\\anaconda3\\envs\\AC2\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "best_result = grid_search_best_parameters()\n",
    "dropout = best_result['dropout']\n",
    "patience = best_result['patience']\n",
    "optimizer = best_result['optimizer']\n",
    "regulizer = best_result['regulizer']\n",
    "batch_size = best_result['batch_size']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:23:44.444061100Z",
     "start_time": "2023-11-27T19:21:31.137166400Z"
    }
   },
   "id": "1dd3be12d76dab4b"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[117], line 7\u001B[0m\n\u001B[0;32m      1\u001B[0m best_result_strint \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest Hyperparameters and Accuracy:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \\\n\u001B[0;32m      2\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdropout: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdropout\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \\\n\u001B[0;32m      3\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpatience: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpatience\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \\\n\u001B[0;32m      4\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moptimizer\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \\\n\u001B[0;32m      5\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mregulizer: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mregulizer\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \\\n\u001B[0;32m      6\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatch_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \\\n\u001B[1;32m----> 7\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage_accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maverage_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(best_result_strint)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'best_result' is not defined"
     ]
    }
   ],
   "source": [
    "best_result_strint = f\"Best Hyperparameters and Accuracy:\\n\" \\\n",
    "                     f\"dropout: {dropout}\\n\" \\\n",
    "                     f\"patience: {patience}\\n\" \\\n",
    "                     f\"optimizer: {optimizer}\\n\" \\\n",
    "                     f\"regulizer: {regulizer}\\n\" \\\n",
    "                     f\"batch_size: {batch_size}\\n\" \\\n",
    "                     f\"average_accuracy: {best_result['average_accuracy']}\\n\"\n",
    "\n",
    "print(best_result_strint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:24:01.563849500Z",
     "start_time": "2023-11-27T19:24:01.432608300Z"
    }
   },
   "id": "14f50a533d3c3ba3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now lets test for the best epochs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8f4d5af6e71a918"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "def find_best_epochs():\n",
    "    epochs_range=(150, 350)\n",
    "    accuracy_threshold=0.1\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for num_epochs in range(epochs_range[0], epochs_range[1] + 1):\n",
    "        print(f\"Testing with {num_epochs} epochs...\")\n",
    "\n",
    "        for fold, (train_index, val_index) in enumerate(stratified_kfold.split(range(len(all_labels)), all_labels)):\n",
    "            # Use the current fold as the validation set\n",
    "            validation_dataset = datasets[fold]\n",
    "\n",
    "            # Combine the remaining datasets as the training set\n",
    "            training_datasets = [dataset for index, dataset in enumerate(datasets) if index != fold]\n",
    "            combined_df = pd.concat(training_datasets, ignore_index=True)\n",
    "\n",
    "            # Classification\n",
    "            X_train = combined_df.drop('Label', axis=1)\n",
    "            y_train = combined_df['Label']\n",
    "\n",
    "            # Oversample the features values using SMOTE\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "            # Standardize the feature values\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "            # Classification for validation set\n",
    "            X_val = validation_dataset.drop('Label', axis=1)\n",
    "            y_val = validation_dataset['Label']\n",
    "\n",
    "            # Oversample the features values using SMOTE for validation set\n",
    "            X_val_resampled, y_val_resampled = smote.fit_resample(X_val, y_val)\n",
    "            X_val_scaled = scaler.transform(X_val_resampled)\n",
    "\n",
    "            mean_neurons = (X_train_scaled.shape[1] + len(np.unique(y_resampled))) // 2\n",
    "            num_input_neurons = X_train_scaled.shape[1]\n",
    "            num_output_neurons = len(np.unique(y_resampled))\n",
    "            neurons_hidden_layer = int(2 / 3 * num_input_neurons + 1 / 3 * num_output_neurons)\n",
    "\n",
    "            # Define and compile the model with hyperparameters\n",
    "            model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(units=neurons_hidden_layer, activation='relu',\n",
    "                                      input_shape=(X_train_scaled.shape[1],),\n",
    "                                      kernel_regularizer=tf.keras.regularizers.l1_l2(l1=regulizer, l2=regulizer)),\n",
    "                tf.keras.layers.Dropout(dropout),\n",
    "                tf.keras.layers.Dense(units=mean_neurons, activation='relu'),\n",
    "                tf.keras.layers.Dropout(dropout),\n",
    "                tf.keras.layers.Dense(units=len(np.unique(y_resampled)), activation='softmax')\n",
    "            ])\n",
    "            model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "            early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train_scaled, y_resampled, validation_data=(X_val_scaled, y_val_resampled),\n",
    "                      batch_size=batch_size, epochs=num_epochs, callbacks=[early_stopping])\n",
    "\n",
    "            # Evaluate the model on the validation set\n",
    "            y_val_pred_probs = model.predict(X_val_scaled)\n",
    "            y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
    "\n",
    "            # Calculate and store accuracy for this fold\n",
    "            fold_accuracy = accuracy_score(y_val_resampled, y_val_pred)\n",
    "            cv_scores.append(fold_accuracy)\n",
    "\n",
    "        # Calculate and store the average accuracy for these hyperparameters\n",
    "        overall_average_accuracy = np.mean(cv_scores)\n",
    "\n",
    "        # Check if accuracy improvement is below the threshold\n",
    "        if num_epochs > epochs_range[0] and overall_average_accuracy - cv_scores[-5] < accuracy_threshold:\n",
    "            print(f\"Stopped testing at {num_epochs} epochs.\")\n",
    "            return num_epochs\n",
    "\n",
    "    print(\"Maximum number of epochs tested. Consider increasing the range.\")\n",
    "    return epochs_range[1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:24:08.538238Z",
     "start_time": "2023-11-27T19:24:08.476841100Z"
    }
   },
   "id": "892a599fb466fe13"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 150 epochs...\n",
      "Epoch 1/150\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2B4FD300> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA2B4FD300> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "276/283 [============================>.] - ETA: 0s - loss: 4.2335WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C4AD4E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA2C4AD4E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "283/283 [==============================] - 4s 4ms/step - loss: 4.2074 - val_loss: 2.9223\n",
      "Epoch 2/150\n",
      "283/283 [==============================] - 1s 3ms/step - loss: 2.4756 - val_loss: 1.8756\n",
      "Epoch 3/150\n",
      " 70/283 [======>.......................] - ETA: 0s - loss: 2.0708"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[119], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m best_epochs \u001B[38;5;241m=\u001B[39m find_best_epochs()\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe best number of epochs is: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[118], line 58\u001B[0m, in \u001B[0;36mfind_best_epochs\u001B[1;34m()\u001B[0m\n\u001B[0;32m     55\u001B[0m early_stopping \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39mpatience)\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 58\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train_scaled, y_resampled, validation_data\u001B[38;5;241m=\u001B[39m(X_val_scaled, y_val_resampled),\n\u001B[0;32m     59\u001B[0m           batch_size\u001B[38;5;241m=\u001B[39mbatch_size, epochs\u001B[38;5;241m=\u001B[39mnum_epochs, callbacks\u001B[38;5;241m=\u001B[39m[early_stopping])\n\u001B[0;32m     61\u001B[0m \u001B[38;5;66;03m# Evaluate the model on the validation set\u001B[39;00m\n\u001B[0;32m     62\u001B[0m y_val_pred_probs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_val_scaled)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\training.py:1774\u001B[0m, in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1763\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n\u001B[0;32m   1764\u001B[0m     callbacks \u001B[38;5;241m=\u001B[39m callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList(\n\u001B[0;32m   1765\u001B[0m         callbacks,\n\u001B[0;32m   1766\u001B[0m         add_history\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1771\u001B[0m         steps\u001B[38;5;241m=\u001B[39mdata_handler\u001B[38;5;241m.\u001B[39minferred_steps,\n\u001B[0;32m   1772\u001B[0m     )\n\u001B[1;32m-> 1774\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1775\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_train_function()\n\u001B[0;32m   1776\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_counter\u001B[38;5;241m.\u001B[39massign(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AC2\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1411\u001B[0m, in \u001B[0;36mDataHandler.steps\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1409\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insufficient_data:  \u001B[38;5;66;03m# Set by `catch_stop_iteration`.\u001B[39;00m\n\u001B[0;32m   1410\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m-> 1411\u001B[0m original_spe \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m   1412\u001B[0m can_run_full_execution \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1413\u001B[0m     original_spe \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1414\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inferred_steps \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1415\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inferred_steps \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m original_spe\n\u001B[0;32m   1416\u001B[0m )\n\u001B[0;32m   1418\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m can_run_full_execution:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:687\u001B[0m, in \u001B[0;36mnumpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    683\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis operation is not supported \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    684\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhen eager execution is enabled.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    685\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_graph_element\u001B[38;5;241m.\u001B[39meval(session\u001B[38;5;241m=\u001B[39msession)\n\u001B[1;32m--> 687\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnumpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    688\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m    689\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread_value()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:814\u001B[0m, in \u001B[0;36mread_value\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    811\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[0;32m    813\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_caching_device\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 814\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28;01mNone\u001B[39;00m, ignore_existing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m    815\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_caching_device):\n\u001B[0;32m    816\u001B[0m       result \u001B[38;5;241m=\u001B[39m read_and_set_handle(no_copy)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:793\u001B[0m, in \u001B[0;36m_read_variable_op\u001B[1;34m(self, no_copy)\u001B[0m\n\u001B[0;32m    791\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_variable_op\u001B[39m(\u001B[38;5;28mself\u001B[39m, no_copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    792\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Reads the value of the variable.\u001B[39;00m\n\u001B[1;32m--> 793\u001B[0m \n\u001B[0;32m    794\u001B[0m \u001B[38;5;124;03m  If the variable is in copy-on-read mode and `no_copy` is True, the variable\u001B[39;00m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;124;03m  is converted to copy-on-write mode before it is read.\u001B[39;00m\n\u001B[0;32m    796\u001B[0m \n\u001B[0;32m    797\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[0;32m    798\u001B[0m \u001B[38;5;124;03m    no_copy: Whether to prevent a copy of the variable.\u001B[39;00m\n\u001B[0;32m    799\u001B[0m \n\u001B[0;32m    800\u001B[0m \u001B[38;5;124;03m  Returns:\u001B[39;00m\n\u001B[0;32m    801\u001B[0m \u001B[38;5;124;03m    The value of the variable.\u001B[39;00m\n\u001B[0;32m    802\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m    803\u001B[0m   variable_accessed(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    805\u001B[0m   \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_and_set_handle\u001B[39m(no_copy):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:783\u001B[0m, in \u001B[0;36mread_and_set_handle\u001B[1;34m(no_copy)\u001B[0m\n\u001B[0;32m    779\u001B[0m restored_tensor \u001B[38;5;241m=\u001B[39m array_ops\u001B[38;5;241m.\u001B[39midentity(\n\u001B[0;32m    780\u001B[0m     restored_tensors[trackable\u001B[38;5;241m.\u001B[39mVARIABLE_VALUE_KEY])\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    782\u001B[0m   assigned_variable \u001B[38;5;241m=\u001B[39m shape_safe_assign_variable_handle(\n\u001B[1;32m--> 783\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape, restored_tensor)\n\u001B[0;32m    784\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    785\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    786\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived incompatible tensor with shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrestored_tensor\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    787\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhen attempting to restore variable with shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    788\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand name \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AC2\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:589\u001B[0m, in \u001B[0;36mread_variable_op\u001B[1;34m(resource, dtype, name)\u001B[0m\n\u001B[0;32m    580\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mresource_gather\u001B[39m(resource: Annotated[Any, _atypes\u001B[38;5;241m.\u001B[39mResource], indices: Annotated[Any, TV_ResourceGather_Tindices], dtype: TV_ResourceGather_dtype, batch_dims:\u001B[38;5;28mint\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, validate_indices:\u001B[38;5;28mbool\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Annotated[Any, TV_ResourceGather_dtype]:\n\u001B[0;32m    581\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Gather slices from the variable pointed to by `resource` according to `indices`.\u001B[39;00m\n\u001B[0;32m    582\u001B[0m \n\u001B[0;32m    583\u001B[0m \u001B[38;5;124;03m  `indices` must be an integer tensor of any dimension (usually 0-D or 1-D).\u001B[39;00m\n\u001B[0;32m    584\u001B[0m \u001B[38;5;124;03m  Produces an output tensor with shape `indices.shape + params.shape[1:]` where:\u001B[39;00m\n\u001B[0;32m    585\u001B[0m \u001B[38;5;124;03m  \u001B[39;00m\n\u001B[0;32m    586\u001B[0m \u001B[38;5;124;03m  ```python\u001B[39;00m\n\u001B[0;32m    587\u001B[0m \u001B[38;5;124;03m      # Scalar indices\u001B[39;00m\n\u001B[0;32m    588\u001B[0m \u001B[38;5;124;03m      output[:, ..., :] = params[indices, :, ... :]\u001B[39;00m\n\u001B[1;32m--> 589\u001B[0m \u001B[38;5;124;03m  \u001B[39;00m\n\u001B[0;32m    590\u001B[0m \u001B[38;5;124;03m      # Vector indices\u001B[39;00m\n\u001B[0;32m    591\u001B[0m \u001B[38;5;124;03m      output[i, :, ..., :] = params[indices[i], :, ... :]\u001B[39;00m\n\u001B[0;32m    592\u001B[0m \u001B[38;5;124;03m  \u001B[39;00m\n\u001B[0;32m    593\u001B[0m \u001B[38;5;124;03m      # Higher rank indices\u001B[39;00m\n\u001B[0;32m    594\u001B[0m \u001B[38;5;124;03m      output[i, ..., j, :, ... :] = params[indices[i, ..., j], :, ..., :]\u001B[39;00m\n\u001B[0;32m    595\u001B[0m \u001B[38;5;124;03m  ```\u001B[39;00m\n\u001B[0;32m    596\u001B[0m \n\u001B[0;32m    597\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[0;32m    598\u001B[0m \u001B[38;5;124;03m    resource: A `Tensor` of type `resource`.\u001B[39;00m\n\u001B[0;32m    599\u001B[0m \u001B[38;5;124;03m    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\u001B[39;00m\n\u001B[0;32m    600\u001B[0m \u001B[38;5;124;03m    dtype: A `tf.DType`.\u001B[39;00m\n\u001B[0;32m    601\u001B[0m \u001B[38;5;124;03m    batch_dims: An optional `int`. Defaults to `0`.\u001B[39;00m\n\u001B[0;32m    602\u001B[0m \u001B[38;5;124;03m    validate_indices: An optional `bool`. Defaults to `True`.\u001B[39;00m\n\u001B[0;32m    603\u001B[0m \u001B[38;5;124;03m    name: A name for the operation (optional).\u001B[39;00m\n\u001B[0;32m    604\u001B[0m \n\u001B[0;32m    605\u001B[0m \u001B[38;5;124;03m  Returns:\u001B[39;00m\n\u001B[0;32m    606\u001B[0m \u001B[38;5;124;03m    A `Tensor` of type `dtype`.\u001B[39;00m\n\u001B[0;32m    607\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m    608\u001B[0m   _ctx \u001B[38;5;241m=\u001B[39m _context\u001B[38;5;241m.\u001B[39m_context \u001B[38;5;129;01mor\u001B[39;00m _context\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m    609\u001B[0m   tld \u001B[38;5;241m=\u001B[39m _ctx\u001B[38;5;241m.\u001B[39m_thread_local_data\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "best_epochs = find_best_epochs()\n",
    "print(f\"The best number of epochs is: {best_epochs}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:24:18.657439300Z",
     "start_time": "2023-11-27T19:24:11.325052700Z"
    }
   },
   "id": "10e54646c98f3b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now lets train the model with the best parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9ab8e1dd94b9911"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3333FEC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001AA3333FEC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "264/283 [==========================>...] - ETA: 0s - loss: 4.1402WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3EA58680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001AA3EA58680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "283/283 [==============================] - 3s 3ms/step - loss: 4.0639 - val_loss: 2.8034\n",
      "Epoch 2/50\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 2.3843 - val_loss: 1.9282\n",
      "Epoch 3/50\n",
      "283/283 [==============================] - 1s 3ms/step - loss: 2.0049 - val_loss: 1.7297\n",
      "Epoch 4/50\n",
      "283/283 [==============================] - 1s 3ms/step - loss: 1.8978 - val_loss: 1.6726\n",
      "Epoch 5/50\n",
      "181/283 [==================>...........] - ETA: 0s - loss: 1.8456"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(stratified_kfold.split(range(len(all_labels)), all_labels)):\n",
    "    # Use the current fold as the validation set\n",
    "    validation_dataset = datasets[fold]\n",
    "\n",
    "    # Combine the remaining datasets as the training set\n",
    "    training_datasets = [dataset for index, dataset in enumerate(datasets) if index != fold]\n",
    "    combined_df = pd.concat(training_datasets, ignore_index=True)\n",
    "\n",
    "    # Classification\n",
    "    X_train = combined_df.drop('Label', axis=1)\n",
    "    y_train = combined_df['Label']\n",
    "\n",
    "    # Oversample the features values using SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Standardize the feature values\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "    # Classification for validation set\n",
    "    X_val = validation_dataset.drop('Label', axis=1)\n",
    "    y_val = validation_dataset['Label']\n",
    "\n",
    "    # Oversample the features values using SMOTE for validation set\n",
    "    X_val_resampled, y_val_resampled = smote.fit_resample(X_val, y_val)\n",
    "    X_val_scaled = scaler.transform(X_val_resampled)\n",
    "\n",
    "    mean_neurons = (X_train_scaled.shape[1] + len(np.unique(y_resampled))) // 2\n",
    "    num_input_neurons = X_train_scaled.shape[1]\n",
    "    num_output_neurons = len(np.unique(y_resampled))\n",
    "    neurons_hidden_layer = int(2 / 3 * num_input_neurons + 1 / 3 * num_output_neurons)\n",
    "\n",
    "    # Define and compile the model with hyperparameters\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=neurons_hidden_layer, activation='relu',\n",
    "                              input_shape=(X_train_scaled.shape[1],),\n",
    "                              kernel_regularizer=tf.keras.regularizers.l1_l2(l1=regulizer, l2=regulizer)),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(units=mean_neurons, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(units=len(np.unique(y_resampled)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_resampled, validation_data=(X_val_scaled, y_val_resampled),\n",
    "              batch_size=batch_size,epochs=best_epochs, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    y_val_pred_probs = model.predict(X_val_scaled)\n",
    "    y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
    "\n",
    "    # Calculate and store accuracy for this fold\n",
    "    fold_accuracy = accuracy_score(y_val_resampled, y_val_pred)\n",
    "    cv_scores.append(fold_accuracy)\n",
    "\n",
    "# Calculate and store the average accuracy for these hyperparameters\n",
    "overall_average_accuracy = np.mean(cv_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T19:24:28.643671600Z",
     "start_time": "2023-11-27T19:24:22.943525100Z"
    }
   },
   "id": "656608d3042ab793"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b98193a9d4634847"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "732789cc28f3d9f9"
  },
  {
   "cell_type": "raw",
   "source": [
    "Given the fact that some authors used 2D inputs and got good results, we decided to use the same approach, based on Mel-frequency cepstral coefficients (MFCCs).\n",
    "For the number of layers we maintained the same number of the MLP model, which was 2 and the type for all of them was Conv2D. \n",
    "The filter dimensions for all of them are (3,3).\n",
    "The number of feature maps starts at 32 and increases to 64 in the second layer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "233e36409e8cb351"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 54)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 488160 into shape (1200,54,1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[146], line 46\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28mprint\u001B[39m(X_val_scaled\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# Reshape data for 2D CNN (assuming X_train_scaled is 2D)\u001B[39;00m\n\u001B[1;32m---> 46\u001B[0m X_train_scaled \u001B[38;5;241m=\u001B[39m X_train_scaled\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1200\u001B[39m, \u001B[38;5;241m54\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     48\u001B[0m X_val_scaled \u001B[38;5;241m=\u001B[39m X_val_scaled\u001B[38;5;241m.\u001B[39mreshape(X_val_scaled\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m940\u001B[39m, \u001B[38;5;241m54\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     49\u001B[0m neurons_hidden_layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;241m*\u001B[39m (X_train_scaled\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlen\u001B[39m(np\u001B[38;5;241m.\u001B[39munique(y_resampled))))\n",
      "\u001B[1;31mValueError\u001B[0m: cannot reshape array of size 488160 into shape (1200,54,1)"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "regulizer = 0.01  # Example regularization strength\n",
    "dropout = 0.5  # Example dropout rate\n",
    "optimizer = 'adam'  # Example optimizer\n",
    "batch_size = 32  # Example batch size\n",
    "best_epochs = 50  # Example number of epochs\n",
    "patience = 5  # Example patience for early stopping\n",
    "mean_neurons = 31  # Example mean_neurons\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(stratified_kfold.split(range(len(all_labels)), all_labels)):\n",
    "    # Use the current fold as the validation set\n",
    "    validation_dataset = datasets[fold]\n",
    "\n",
    "    # Combine the remaining datasets as the training set\n",
    "    training_datasets = [dataset for index, dataset in enumerate(datasets) if index != fold]\n",
    "    combined_df = pd.concat(training_datasets, ignore_index=True)\n",
    "\n",
    "    # Keep only columns representing MFCCs\n",
    "    mcff = combined_df[13:]\n",
    "    mfcc_columns = mcff.columns\n",
    "    X_train = combined_df[mfcc_columns]\n",
    "    y_train = combined_df['Label']\n",
    "\n",
    "    # Oversample the features values using SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Standardize the feature values\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "    # Classification for validation set\n",
    "    X_val = validation_dataset[mfcc_columns]\n",
    "    y_val = validation_dataset['Label']\n",
    "\n",
    "    # Oversample the features values using SMOTE for validation set\n",
    "    X_val_resampled, y_val_resampled = smote.fit_resample(X_val, y_val)\n",
    "    X_val_scaled = scaler.transform(X_val_resampled)\n",
    "\n",
    "   # Assuming X_train_scaled and X_val_scaled are 2D with shape (None, 54, 1)\n",
    "\n",
    "    print(X_val_scaled.shape)\n",
    "    # Reshape data for 2D CNN (assuming X_train_scaled is 2D)\n",
    "    X_train_scaled = X_train_scaled.reshape(1200, 54, 1)\n",
    "\n",
    "    X_val_scaled = X_val_scaled.reshape(X_val_scaled.shape[0], 940, 54, 1)\n",
    "    neurons_hidden_layer = int(2 / 3 * (X_train_scaled.shape[1] + len(np.unique(y_resampled))))\n",
    "\n",
    "    # Define and compile the CNN model with hyperparameters\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\n",
    "                               input_shape=(940,54,1)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=neurons_hidden_layer, activation='relu',\n",
    "                              kernel_regularizer=tf.keras.regularizers.l1_l2(l1=regulizer, l2=regulizer)),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(units=mean_neurons, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(units=len(np.unique(y_resampled)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "\n",
    "    # Train the CNN model\n",
    "    model.fit(X_train_scaled, y_resampled, validation_data=(X_val_scaled, y_val_resampled),\n",
    "              batch_size=batch_size, epochs=best_epochs, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the CNN model on the validation set\n",
    "    y_val_pred_probs = model.predict(X_val_scaled)\n",
    "    y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
    "\n",
    "    # Calculate and store accuracy for this fold\n",
    "    fold_accuracy = accuracy_score(y_val_resampled, y_val_pred)\n",
    "    cv_scores.append(fold_accuracy)\n",
    "\n",
    "# Calculate and store the average accuracy for these hyperparameters\n",
    "overall_average_accuracy = np.mean(cv_scores)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T22:41:23.224157200Z",
     "start_time": "2023-11-27T22:41:22.918790200Z"
    }
   },
   "id": "5f944bf1d3ec22d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T19:23:44.456175500Z"
    }
   },
   "id": "fd38337cf5498bec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
